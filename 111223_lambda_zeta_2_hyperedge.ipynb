{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nancy-Shi/ICE_Manuscript/blob/main/111223_lambda_zeta_2_hyperedge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA_qQY-h8rAL"
      },
      "source": [
        "## 3-Layer Model with Informtion, Behavior, Disease"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AGpv6rhiGYO"
      },
      "outputs": [],
      "source": [
        "#!pip uninstall -y numpy\n",
        "#!pip uninstall -y setuptools\n",
        "#!pip install setuptools\n",
        "#!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvbMl01j8mD4",
        "outputId": "33b6bc67-4291-4ad2-a2d4-863fffb96f56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " No module named 'igraph'. If you need to use hypernetx.algorithms.hypergraph_modularity, please install additional packages by running the following command: pip install .['all']\n"
          ]
        }
      ],
      "source": [
        "#!pip install hypernetx\n",
        "import hypernetx as hnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fan2mZxpB3Up"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import random\n",
        "import math as math\n",
        "from math import log\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.ticker as ticker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUCtz8IJ8VkT"
      },
      "source": [
        "\n",
        "## Part 1: Hypergraph Generation\n",
        "The following steps generate a hyper graph using the XGI/HyperNetX python package,  following power-law degree distribution for predifined number of nodes n, number of hyperedges num_hyper_edges, degree exponent gamma, using a configuration model with data stored in a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qvT8MAI8VEs"
      },
      "outputs": [],
      "source": [
        "# Step 1: Generate Degree Sequence\n",
        "def generate_degree_sequence(n, gamma, kmin):\n",
        "    # Generate a random set from the power law distribution\n",
        "    u = np.random.uniform(size=n)\n",
        "    degrees = np.ceil((1.0 - u) ** (-1.0 / (gamma - 1.0)))\n",
        "\n",
        "    # Adjust degrees based on the minimum and maximum degree values\n",
        "    kmax = int(np.sqrt(n))\n",
        "    # kmax = int(1.5*n**(1/4)) # max degree allowed is 1.5*n^(1/4)\n",
        "    degrees = degrees[(degrees >= kmin) & (degrees <= kmax)].astype(int)\n",
        "\n",
        "    # Truncate or pad the sequence to match the length specified\n",
        "    if len(degrees) >= n:\n",
        "        degrees = degrees[:n]\n",
        "    else:\n",
        "        degrees = np.concatenate((degrees, np.full(n - len(degrees), kmin)))\n",
        "\n",
        "    return degrees.tolist()\n",
        "\n",
        "# Step 2: Generate Hyper Edge Size Sequence\n",
        "def generate_hyper_edge_sizes(degrees, num_hyper_edges):\n",
        "    total_degrees = sum(degrees)\n",
        "    hyper_edge_sizes = []\n",
        "\n",
        "    # Calculate the average size for each hyper edge\n",
        "    avg_size = total_degrees // num_hyper_edges\n",
        "    remainder = total_degrees % num_hyper_edges\n",
        "\n",
        "    # Define the range for the random distribution\n",
        "    min_size = 2  # Lower bound of the range\n",
        "    max_size = int(np.sqrt(total_degrees))  # Upper bound of the range\n",
        "    #max_size = len(degrees) - num_hyper_edges  # Upper bound of the range\n",
        "\n",
        "    # Generate hyper edge sizes\n",
        "    for _ in range(num_hyper_edges):\n",
        "        size = random.randint(min_size, max_size)\n",
        "        hyper_edge_sizes.append(size)\n",
        "\n",
        "    return hyper_edge_sizes\n",
        "\n",
        "\n",
        "# Step 3: Create Copies of Nodes\n",
        "def create_node_copies(degrees):\n",
        "    node_copies = []\n",
        "    for i, degree in enumerate(degrees):\n",
        "        for _ in range(degree):\n",
        "            node_copies.append(i)\n",
        "    return node_copies\n",
        "\n",
        "# Step 4: Create Copies of Hyper Edges\n",
        "def create_hyper_edge_copies(hyper_edge_sizes):\n",
        "    hyper_edge_copies = []\n",
        "    for i, size in enumerate(hyper_edge_sizes):\n",
        "        for _ in range(size):\n",
        "            hyper_edge_copies.append(i)\n",
        "    return hyper_edge_copies\n",
        "\n",
        "# Step 5: Randomly Pair Copies without Repeated Pairs\n",
        "def randomly_pair_copies(node_copies, hyper_edge_copies):\n",
        "    pairs = []\n",
        "    paired_hyper_edges = {} # Using a dictionary to track paired hyper-edges with nodes\n",
        "\n",
        "    for node_copy in node_copies:\n",
        "        available_hyper_edges = [h for h in hyper_edge_copies if (h, node_copy) not in paired_hyper_edges]\n",
        "\n",
        "        # If no available hyper-edges left, shuffle the paired hyper-edges and reset\n",
        "        if not available_hyper_edges:\n",
        "            paired_hyper_edges = {}\n",
        "            available_hyper_edges = [h for h in hyper_edge_copies if (h, node_copy) not in paired_hyper_edges]\n",
        "\n",
        "        # Randomly choose a hyper-edge that has not been paired yet with the current node\n",
        "        chosen_hyper_edge = random.choice(available_hyper_edges)\n",
        "        pairs.append((node_copy, chosen_hyper_edge))\n",
        "\n",
        "        # Add to paired_hyper_edges\n",
        "        paired_hyper_edges[(chosen_hyper_edge, node_copy)] = True\n",
        "        hyper_edge_copies.remove(chosen_hyper_edge)\n",
        "\n",
        "    return pairs\n",
        "\n",
        "# Step 6: Convert Bipartite Graph to A Hypergraph Dictionary\n",
        "def convert_to_hypergraph(pairs):\n",
        "    hypergraph = {}\n",
        "    for pair in pairs:\n",
        "        node, hyper_edge = pair\n",
        "        if hyper_edge in hypergraph:\n",
        "            hypergraph[hyper_edge].append(node)\n",
        "        else:\n",
        "            hypergraph[hyper_edge] = [node]\n",
        "    return hypergraph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b6c7yfU8hg8"
      },
      "outputs": [],
      "source": [
        "def build_hypergraph(n, gamma, kmin, num_hyper_edges):\n",
        "    # Step 1: Generate Degree Sequence\n",
        "    degrees = generate_degree_sequence(n, gamma, kmin)\n",
        "    print(\"Degree Sequence: \", degrees)\n",
        "\n",
        "    # Step 2: Generate Hyper Edge Size Sequence\n",
        "    hyper_edge_sizes = generate_hyper_edge_sizes(degrees, num_hyper_edges)\n",
        "    print(\"Hyper Edge Sizes: \", hyper_edge_sizes)\n",
        "\n",
        "    # Step 3: Create Copies of Nodes\n",
        "    node_copies = create_node_copies(degrees)\n",
        "\n",
        "    # Step 4: Create Copies of Hyper Edges\n",
        "    hyper_edge_copies = create_hyper_edge_copies(hyper_edge_sizes)\n",
        "\n",
        "    # Step 5: Randomly Pair Copies\n",
        "    pairs = randomly_pair_copies(node_copies, hyper_edge_copies)\n",
        "\n",
        "    # Step 6: Convert Bipartite Graph to Hypergraph\n",
        "    hyperedge_dict = convert_to_hypergraph(pairs)\n",
        "\n",
        "    # Print the resulting hypergraph\n",
        "    print(\"Hypergraph Dictionary: \", hyperedge_dict)\n",
        "\n",
        "    return degrees, hyperedge_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-tEXGpf819Y",
        "outputId": "5eea0555-162a-4eae-8f44-2dcdf4cf0d28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Degree Sequence:  [5, 3, 3, 3, 6, 3, 7, 10, 3, 4, 3, 3, 3, 6, 4, 3, 4, 3, 9, 4, 7, 3, 4, 3, 4, 3, 8, 8, 3, 4, 3, 3, 5, 3, 4, 5, 4, 3, 3, 3, 8, 3, 5, 3, 10, 3, 5, 3, 3, 7, 8, 8, 20, 3, 4, 3, 4, 7, 3, 3, 3, 3, 3, 4, 3, 3, 3, 4, 3, 4, 3, 6, 3, 11, 4, 4, 6, 11, 3, 3, 4, 5, 3, 3, 5, 3, 3, 4, 12, 3, 5, 3, 4, 3, 3, 3, 5, 4, 3, 3, 5, 5, 3, 5, 3, 4, 6, 5, 4, 3, 4, 5, 3, 3, 4, 3, 7, 4, 3, 4, 3, 5, 5, 4, 7, 3, 4, 3, 5, 5, 3, 5, 3, 3, 6, 11, 8, 4, 6, 10, 3, 3, 8, 3, 4, 4, 4, 3, 7, 17, 6, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
            "Hyper Edge Sizes:  [40, 20, 29, 32, 32, 28, 26, 36, 8, 27, 8, 34, 27, 17, 4, 20, 16, 5, 35, 7, 26, 5, 8, 10, 18, 12, 30, 6, 9, 10, 15, 3, 27, 4, 11, 30, 39, 11, 21, 30, 32, 37, 12, 26, 32, 12, 12, 3, 18, 23, 17, 23, 30, 41, 21, 2, 32, 30, 36, 25, 8, 8, 14, 9, 19, 21, 35, 10, 9, 21, 6, 37, 4, 21, 34, 22, 34, 38, 25, 15, 15, 5, 25, 18, 3, 13, 11, 26, 11, 5, 37, 33, 24, 7, 18, 4, 36, 31, 17, 17]\n",
            "Hypergraph Dictionary:  {92: [0, 66, 73, 76, 88, 128, 207, 221, 254, 255, 264, 305, 318, 342, 344, 368, 444, 465, 486, 492], 98: [0, 4, 27, 106, 125, 157, 163, 166, 228, 229, 292, 375, 392, 435], 16: [0, 82, 112, 126, 148, 250, 273, 321, 357, 387, 443, 446, 451, 461], 90: [0, 7, 10, 13, 17, 32, 46, 51, 52, 57, 71, 74, 92, 101, 103, 129, 138, 148, 156, 171, 177, 178, 183, 191, 215, 230, 346, 365, 370, 377, 405, 448, 466], 91: [0, 12, 23, 46, 49, 56, 62, 67, 68, 69, 75, 95, 98, 118, 119, 121, 138, 161, 253, 256, 265, 274, 293, 311, 331, 351, 368, 423, 442, 486], 2: [1, 20, 52, 96, 97, 122, 133, 170, 178, 189, 225, 247, 274, 282, 299, 304, 306, 342, 348, 368, 429, 455, 472, 495], 39: [1, 14, 22, 23, 41, 63, 77, 100, 103, 107, 109, 122, 127, 137, 153, 155, 158, 210, 219, 275, 282, 299, 328, 345, 397, 424], 74: [1, 27, 30, 46, 72, 73, 81, 94, 100, 102, 108, 117, 118, 125, 135, 187, 206, 227, 249, 260, 269, 308, 309, 314, 351, 372, 388, 409, 410, 470, 477], 26: [2, 18, 22, 32, 38, 47, 52, 69, 75, 85, 135, 193, 208, 251, 263, 276, 284, 285, 363, 364, 375, 388, 389, 390, 437, 483, 496], 32: [2, 21, 30, 39, 51, 52, 108, 117, 131, 142, 159, 160, 188, 232, 265, 275, 294, 318, 350, 364, 369, 399, 407, 414, 458], 96: [2, 10, 16, 17, 34, 39, 46, 49, 71, 81, 96, 103, 138, 153, 157, 213, 227, 234, 236, 244, 269, 333, 345, 354, 366, 413, 433, 441, 457, 461, 466, 494], 82: [3, 49, 69, 77, 107, 110, 113, 143, 193, 201, 258, 267, 279, 300, 308, 320, 359, 430, 432], 65: [3, 52, 74, 88, 91, 99, 216, 240, 326, 346, 366, 378, 408, 425, 439, 470], 29: [3, 42, 180, 248, 297, 369, 385, 402, 411, 438], 78: [4, 22, 52, 106, 135, 142, 148, 149, 158, 175, 182, 200, 235, 236, 242, 269, 283, 297, 299, 304, 317, 356, 383, 393, 481], 68: [4, 16, 88, 135, 221, 262, 295, 453], 41: [4, 24, 28, 36, 44, 46, 49, 51, 63, 73, 77, 83, 93, 102, 109, 110, 116, 121, 155, 170, 171, 196, 220, 275, 312, 313, 319, 321, 390, 404], 85: [4, 40, 44, 45, 66, 86, 191, 285, 302, 332, 404, 479, 487], 6: [4, 5, 19, 25, 33, 53, 70, 88, 114, 128, 139, 148, 149, 151, 160, 189, 218, 243, 343, 362, 404, 489], 40: [5, 18, 33, 40, 73, 77, 79, 81, 92, 101, 115, 124, 134, 136, 150, 176, 177, 210, 217, 255, 263, 385, 400, 401, 447, 458, 474, 482, 485], 53: [5, 11, 26, 29, 44, 64, 70, 87, 107, 119, 134, 136, 139, 140, 148, 149, 150, 169, 195, 212, 232, 246, 279, 280, 281, 298, 306, 324, 351, 369, 373, 386, 399, 408, 446, 484, 488], 77: [6, 31, 44, 52, 57, 73, 76, 107, 116, 130, 147, 149, 154, 182, 220, 229, 242, 273, 315, 320, 322, 336, 338, 349, 366, 380, 382, 384, 394, 430, 441, 469], 61: [6, 35, 75, 84, 180, 264, 319, 327], 58: [6, 18, 26, 31, 32, 42, 49, 52, 54, 55, 62, 100, 105, 116, 120, 130, 206, 217, 226, 252, 289, 292, 324, 327, 355, 358, 362, 372, 463, 488, 498], 25: [6, 41, 96, 119, 128, 172, 203, 350, 416, 447, 455], 36: [6, 37, 44, 51, 67, 112, 119, 145, 159, 169, 178, 199, 204, 231, 248, 249, 278, 287, 335, 367, 374, 397, 400, 409, 410, 418, 440, 459, 462, 465, 480, 485, 490, 499], 23: [6, 9, 124, 174, 175, 218, 259, 364, 384, 411], 76: [6, 18, 19, 29, 40, 57, 60, 102, 103, 121, 145, 149, 181, 202, 218, 230, 235, 265, 271, 290, 328, 335, 339, 355, 361, 363, 412, 418, 419, 432, 446, 476], 24: [7, 29, 68, 87, 124, 136, 154, 238, 290, 331, 341, 353, 374, 389, 490], 48: [7, 80, 81, 114, 151, 156, 198, 224, 280, 315, 403, 417, 488, 494], 95: [7, 16, 135, 267], 56: [7, 26, 27, 34, 50, 73, 80, 81, 103, 107, 120, 138, 139, 142, 153, 184, 199, 257, 267, 272, 286, 302, 321, 343, 386, 392, 410, 476, 478], 73: [7, 19, 20, 25, 38, 40, 77, 93, 96, 114, 139, 167, 185, 198, 303, 305, 383, 443, 459], 44: [7, 34, 44, 58, 59, 60, 83, 88, 89, 101, 104, 148, 155, 160, 163, 195, 196, 231, 277, 279, 294, 318, 346, 348, 370, 422, 454, 460, 468, 499], 71: [7, 18, 21, 43, 47, 50, 52, 63, 71, 72, 78, 80, 131, 149, 167, 213, 240, 241, 243, 256, 268, 300, 317, 325, 335, 339, 395, 406, 436, 442, 450, 462, 475, 481, 497], 99: [7, 62, 70, 130, 131, 136, 187, 199, 301, 371, 378, 391, 409, 421, 435, 452], 5: [7, 26, 69, 110, 116, 117, 122, 142, 146, 149, 221, 250, 268, 288, 338, 342, 353, 354, 381, 393, 456, 497], 93: [8, 24, 38, 52, 149, 272, 417], 4: [8, 13, 19, 33, 35, 59, 77, 80, 129, 131, 139, 149, 161, 162, 174, 175, 205, 211, 217, 233, 307, 316, 332, 340, 347, 352, 380, 454, 480, 491], 54: [8, 39, 73, 74, 76, 83, 86, 94, 122, 129, 251, 328, 352, 379, 398, 422, 423, 476, 481, 498], 43: [9, 26, 50, 64, 77, 82, 111, 113, 133, 162, 204, 208, 209, 240, 261, 270, 286, 314, 408, 428, 445, 459, 463, 485], 50: [9, 15, 76, 151, 181, 196, 225, 226, 238, 247, 316, 359, 428, 434, 469, 495], 35: [9, 15, 27, 55, 57, 88, 106, 149, 170, 173, 188, 197, 244, 291, 295, 305, 309, 311, 315, 333, 375, 383, 423, 443, 457, 484, 496], 69: [10, 44, 51, 57, 72, 95, 124, 134, 149, 162, 173, 179, 234, 239, 273, 307, 457, 460], 1: [11, 44, 54, 91, 111, 122, 132, 164, 198, 262, 313, 373, 421, 439, 442, 472, 478], 15: [11, 36, 52, 93, 188, 239, 243, 274, 300, 329, 331, 336, 400, 424, 489], 59: [12, 53, 61, 110, 116, 125, 139, 192, 223, 245, 252, 255, 283, 303, 325, 371, 373, 397, 402, 421, 460, 480], 57: [12, 42, 71, 73, 133, 138, 142, 150, 164, 165, 172, 241, 253, 260, 284, 312, 356, 365, 394, 396, 405, 418, 420, 454, 492], 37: [13, 37, 84, 169, 185, 247, 277, 295, 396, 451], 38: [13, 20, 36, 68, 87, 126, 127, 140, 182, 192, 211, 258, 281, 333, 385, 386, 393, 436, 470], 21: [13, 26, 116, 139], 75: [13, 45, 59, 73, 89, 92, 101, 105, 146, 212, 270, 271, 301, 312, 334, 362, 398, 425, 428, 447], 87: [14, 21, 27, 41, 45, 48, 58, 65, 71, 142, 147, 204, 211, 224, 241, 242, 293, 302, 361, 395, 407, 479], 45: [14, 67, 76, 150, 209, 220, 294, 301, 306, 399, 474], 18: [14, 34, 50, 52, 112, 121, 124, 142, 150, 163, 168, 174, 180, 186, 222, 257, 270, 303, 304, 314, 324, 326, 340, 360, 363, 379, 381, 396, 403, 430, 498], 64: [15, 20, 52, 84, 88, 128, 149, 264, 268, 311, 323, 390, 419, 436, 445, 453, 465], 79: [16, 35, 121, 128, 212, 231, 248, 367, 415, 445, 458, 493, 495], 0: [17, 28, 36, 54, 63, 66, 85, 106, 113, 123, 127, 139, 156, 164, 176, 194, 208, 215, 246, 287, 288, 309, 358, 367, 380, 392, 426, 427, 451, 453, 456, 464, 471, 473, 483], 46: [18, 85, 105, 111, 124, 138, 283, 381, 427, 431, 463], 8: [18, 96, 141, 276, 288, 334, 487], 11: [18, 40, 42, 52, 55, 57, 60, 91, 104, 105, 134, 135, 137, 144, 165, 184, 189, 200, 203, 228, 252, 281, 322, 377, 379, 416, 420, 450, 493], 7: [18, 27, 28, 61, 88, 90, 97, 123, 129, 143, 144, 151, 157, 158, 192, 207, 209, 216, 226, 230, 238, 340, 407, 411, 412, 427, 432, 437, 448, 489], 3: [20, 67, 76, 86, 101, 111, 136, 149, 181, 225, 278, 290, 350, 357, 377, 391, 403, 415, 431, 438, 462, 471, 473, 475, 479, 491, 494, 499], 97: [20, 24, 32, 35, 50, 73, 87, 99, 124, 132, 190, 200, 223, 233, 235, 237, 261, 323, 339, 356, 382, 405, 406, 434, 440, 468, 478, 487], 20: [20, 24, 29, 37, 44, 77, 123, 135, 139, 140, 179, 223, 266, 292, 332, 353, 360, 374, 376, 378, 416, 417, 426, 482], 19: [22, 73, 77, 173, 347, 440, 444], 49: [23, 27, 40, 48, 50, 90, 104, 106, 116, 126, 172, 197, 253, 298, 310, 347, 394, 437, 484, 496], 13: [25, 50, 190, 210, 249, 254, 266, 313, 337, 345, 376, 398, 414, 466, 482], 9: [26, 51, 52, 88, 136, 141, 142, 144, 149, 161, 214, 245, 260, 266, 272, 285, 293, 298, 310, 337, 365, 439, 441, 449], 63: [26, 61, 84, 123, 183, 239, 263, 330, 448], 94: [27, 35, 57, 82, 88, 135, 171, 228, 251, 308, 401, 449, 467, 469], 66: [30, 58, 74, 78, 90, 145, 147, 149, 159, 179, 183, 185, 186, 194, 271, 276, 297, 330, 334, 344, 371, 382, 388, 391, 419, 420, 429, 444, 456, 497], 42: [31, 77, 141, 205, 261, 352, 357, 422, 424, 433], 70: [32, 51, 146, 433, 435, 464], 52: [40, 52, 64, 75, 97, 98, 108, 120, 126, 134, 149, 152, 168, 224, 234, 245, 258, 286, 413, 438, 450, 452, 468, 471, 491], 51: [40, 48, 65, 90, 94, 97, 134, 203, 214, 215, 232, 257, 259, 262, 322, 327, 337, 349, 387, 395, 474], 28: [42, 56, 65, 99, 187, 236, 412, 483], 47: [43, 177, 349], 30: [43, 44, 77, 131, 190, 202, 219, 222, 329, 461, 492], 67: [47, 56, 95, 149, 213, 214, 227, 296, 326], 27: [49, 51, 114, 277, 280, 389], 88: [49, 53, 88, 115, 137, 152, 166, 205, 317, 338, 359], 22: [50, 108, 136, 184, 278, 291, 413, 467], 60: [52, 106, 166, 289, 296, 473], 80: [52, 56, 89, 92, 135, 136, 168, 193, 244, 291, 319, 372, 384, 402, 490], 72: [52, 132, 216], 12: [52, 90, 118, 176, 197, 201, 237, 250, 287, 344, 348, 358, 360, 370, 387, 401, 449, 477, 493], 34: [54, 79, 115, 146, 191, 206, 207, 307, 320], 10: [71, 152, 167, 246, 323, 341], 33: [78, 111, 296, 467], 62: [79, 84, 129, 139, 282, 325, 354, 406, 429, 475, 477, 486], 86: [88, 135, 143, 144, 154, 194, 229, 254, 256, 330, 336], 83: [98, 100, 137, 148, 150, 165, 186, 310, 355, 361, 415, 425, 434, 452, 455], 89: [100, 195, 222, 233], 84: [109, 414, 431], 31: [117, 343, 376], 81: [135, 202, 284, 341], 17: [145, 219, 237, 316, 329], 14: [201, 259, 289, 426], 55: [464, 472]}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  return np.find_common_type(types, [])\n"
          ]
        }
      ],
      "source": [
        "# Test 2\n",
        "n2 =500  # Number of nodes\n",
        "gamma2 = 2.5  # Power-law exponent\n",
        "kmin2 = 3  # Minimum degree\n",
        "num_hyper_edges2 = 100  # Desired number of hyper edges\n",
        "\n",
        "degrees2, hyperedge_dict2 = build_hypergraph(n2, gamma2, kmin2, num_hyper_edges2)\n",
        "H2 = hnx.Hypergraph(hyperedge_dict2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bbX083i9Htn"
      },
      "source": [
        "## Part 2: Assign Behavior Status\n",
        "NP represents the state of no protection, while P represents the state of with protection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elKpYEaU9HE1"
      },
      "outputs": [],
      "source": [
        "def assign_protection(hypergraph, fraction_protected):\n",
        "    # Get the list of nodes from the hypergraph\n",
        "    nodes = list(hypergraph.nodes())\n",
        "\n",
        "    # Calculate the number of nodes to protect\n",
        "    num_nodes_to_protect = int(len(nodes) * fraction_protected)\n",
        "\n",
        "    # Randomly choose nodes to protect\n",
        "    nodes_to_protect = random.sample(nodes, num_nodes_to_protect)\n",
        "\n",
        "    # Initialize the protection status dictionary\n",
        "    protection_status = {}\n",
        "\n",
        "    # Assign protection status to each node\n",
        "    for node in nodes:\n",
        "        if node in nodes_to_protect:\n",
        "            protection_status[node] = \"P\"  # Protected node\n",
        "        else:\n",
        "            protection_status[node] = \"N\"  # Non-protected node\n",
        "\n",
        "    print(protection_status)\n",
        "\n",
        "    return protection_status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxZAdvJR-TXv",
        "outputId": "88a56dcd-ee1d-4d1f-cf22-4d5cd4f6116c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'N', 1: 'N', 2: 'N', 3: 'N', 4: 'P', 5: 'N', 6: 'N', 7: 'P', 8: 'N', 9: 'N', 10: 'N', 11: 'N', 12: 'N', 13: 'N', 14: 'N', 15: 'N', 16: 'N', 17: 'N', 18: 'N', 19: 'N', 20: 'N', 21: 'P', 22: 'N', 23: 'N', 24: 'N', 25: 'N', 26: 'N', 27: 'P', 28: 'N', 29: 'N', 30: 'N', 31: 'N', 32: 'P', 33: 'N', 34: 'N', 35: 'N', 36: 'N', 37: 'N', 38: 'N', 39: 'N', 40: 'N', 41: 'N', 42: 'N', 43: 'N', 44: 'P', 45: 'N', 46: 'N', 47: 'N', 48: 'N', 49: 'N', 50: 'N', 51: 'N', 52: 'N', 53: 'N', 54: 'N', 55: 'N', 56: 'N', 57: 'N', 58: 'N', 59: 'N', 60: 'N', 61: 'P', 62: 'N', 63: 'N', 64: 'N', 65: 'N', 66: 'P', 67: 'N', 68: 'N', 69: 'N', 70: 'N', 71: 'N', 72: 'N', 73: 'N', 74: 'N', 75: 'N', 76: 'P', 77: 'N', 78: 'N', 79: 'N', 80: 'N', 81: 'N', 82: 'N', 83: 'N', 84: 'N', 85: 'P', 86: 'N', 87: 'N', 88: 'N', 89: 'N', 90: 'N', 91: 'N', 92: 'N', 93: 'N', 94: 'N', 95: 'N', 96: 'N', 97: 'N', 98: 'N', 99: 'N', 100: 'N', 101: 'N', 102: 'P', 103: 'N', 104: 'N', 105: 'N', 106: 'N', 107: 'N', 108: 'N', 109: 'N', 110: 'P', 111: 'N', 112: 'N', 113: 'N', 114: 'N', 115: 'N', 116: 'N', 117: 'N', 118: 'N', 119: 'N', 120: 'N', 121: 'N', 122: 'N', 123: 'N', 124: 'N', 125: 'N', 126: 'N', 127: 'N', 128: 'N', 129: 'N', 130: 'N', 131: 'N', 132: 'N', 133: 'N', 134: 'N', 135: 'N', 136: 'N', 137: 'N', 138: 'N', 139: 'N', 140: 'N', 141: 'N', 142: 'P', 143: 'N', 144: 'N', 145: 'N', 146: 'N', 147: 'N', 148: 'P', 149: 'N', 150: 'N', 151: 'N', 152: 'P', 153: 'N', 154: 'P', 155: 'P', 156: 'N', 157: 'N', 158: 'P', 159: 'N', 160: 'N', 161: 'N', 162: 'N', 163: 'N', 164: 'N', 165: 'N', 166: 'N', 167: 'P', 168: 'N', 169: 'N', 170: 'N', 171: 'N', 172: 'N', 173: 'N', 174: 'N', 175: 'N', 176: 'N', 177: 'P', 178: 'N', 179: 'N', 180: 'N', 181: 'N', 182: 'N', 183: 'N', 184: 'N', 185: 'N', 186: 'P', 187: 'N', 188: 'N', 189: 'N', 190: 'N', 191: 'N', 192: 'N', 193: 'N', 194: 'N', 195: 'N', 196: 'N', 197: 'N', 198: 'N', 199: 'N', 200: 'N', 201: 'N', 202: 'N', 203: 'P', 204: 'N', 205: 'N', 206: 'N', 207: 'N', 208: 'P', 209: 'N', 210: 'N', 211: 'N', 212: 'N', 213: 'N', 214: 'N', 215: 'N', 216: 'N', 217: 'N', 218: 'P', 219: 'N', 220: 'N', 221: 'N', 222: 'N', 223: 'N', 224: 'N', 225: 'N', 226: 'N', 227: 'N', 228: 'N', 229: 'N', 230: 'N', 231: 'P', 232: 'N', 233: 'N', 234: 'P', 235: 'N', 236: 'N', 237: 'N', 238: 'N', 239: 'N', 240: 'N', 241: 'N', 242: 'N', 243: 'N', 244: 'N', 245: 'N', 246: 'P', 247: 'N', 248: 'N', 249: 'N', 250: 'N', 251: 'N', 252: 'N', 253: 'N', 254: 'N', 255: 'N', 256: 'P', 257: 'N', 258: 'N', 259: 'N', 260: 'N', 261: 'N', 262: 'N', 263: 'P', 264: 'P', 265: 'N', 266: 'N', 267: 'N', 268: 'N', 269: 'N', 270: 'N', 271: 'N', 272: 'N', 273: 'N', 274: 'P', 275: 'N', 276: 'N', 277: 'N', 278: 'N', 279: 'N', 280: 'N', 281: 'N', 282: 'N', 283: 'P', 284: 'N', 285: 'N', 286: 'N', 287: 'N', 288: 'N', 289: 'N', 290: 'N', 291: 'N', 292: 'N', 293: 'N', 294: 'N', 295: 'N', 296: 'N', 297: 'N', 298: 'P', 299: 'N', 300: 'N', 301: 'N', 302: 'N', 303: 'N', 304: 'N', 305: 'N', 306: 'N', 307: 'N', 308: 'N', 309: 'P', 310: 'N', 311: 'N', 312: 'N', 313: 'N', 314: 'N', 315: 'N', 316: 'N', 317: 'N', 318: 'N', 319: 'N', 320: 'N', 321: 'P', 322: 'N', 323: 'N', 324: 'N', 325: 'N', 326: 'P', 327: 'N', 328: 'N', 329: 'N', 330: 'N', 331: 'N', 332: 'N', 333: 'N', 334: 'N', 335: 'N', 336: 'N', 337: 'N', 338: 'N', 339: 'N', 340: 'N', 341: 'N', 342: 'N', 343: 'N', 344: 'N', 345: 'N', 346: 'N', 347: 'P', 348: 'N', 349: 'N', 350: 'N', 351: 'N', 352: 'N', 353: 'N', 354: 'N', 355: 'P', 356: 'N', 357: 'N', 358: 'N', 359: 'N', 360: 'N', 361: 'N', 362: 'N', 363: 'N', 364: 'P', 365: 'N', 366: 'N', 367: 'N', 368: 'N', 369: 'P', 370: 'N', 371: 'N', 372: 'N', 373: 'N', 374: 'N', 375: 'N', 376: 'N', 377: 'N', 378: 'N', 379: 'N', 380: 'N', 381: 'N', 382: 'N', 383: 'N', 384: 'N', 385: 'P', 386: 'N', 387: 'N', 388: 'N', 389: 'N', 390: 'N', 391: 'N', 392: 'N', 393: 'N', 394: 'N', 395: 'N', 396: 'N', 397: 'N', 398: 'N', 399: 'N', 400: 'N', 401: 'N', 402: 'N', 403: 'N', 404: 'N', 405: 'N', 406: 'N', 407: 'P', 408: 'N', 409: 'N', 410: 'N', 411: 'N', 412: 'N', 413: 'N', 414: 'N', 415: 'N', 416: 'N', 417: 'N', 418: 'P', 419: 'N', 420: 'N', 421: 'N', 422: 'N', 423: 'N', 424: 'N', 425: 'N', 426: 'N', 427: 'N', 428: 'N', 429: 'N', 430: 'N', 431: 'N', 432: 'N', 433: 'P', 434: 'N', 435: 'N', 436: 'N', 437: 'N', 438: 'N', 439: 'N', 440: 'P', 441: 'N', 442: 'N', 443: 'N', 444: 'N', 445: 'N', 446: 'N', 447: 'N', 448: 'N', 449: 'N', 450: 'N', 451: 'N', 452: 'N', 453: 'N', 454: 'N', 455: 'N', 456: 'N', 457: 'N', 458: 'N', 459: 'P', 460: 'N', 461: 'N', 462: 'N', 463: 'N', 464: 'N', 465: 'N', 466: 'N', 467: 'N', 468: 'N', 469: 'N', 470: 'P', 471: 'N', 472: 'N', 473: 'N', 474: 'N', 475: 'N', 476: 'N', 477: 'N', 478: 'N', 479: 'P', 480: 'N', 481: 'N', 482: 'P', 483: 'N', 484: 'N', 485: 'N', 486: 'N', 487: 'N', 488: 'N', 489: 'P', 490: 'N', 491: 'N', 492: 'N', 493: 'N', 494: 'N', 495: 'N', 496: 'N', 497: 'N', 498: 'N', 499: 'N'}\n",
            "{0: 'N', 1: 'N', 2: 'N', 3: 'N', 4: 'P', 5: 'N', 6: 'N', 7: 'P', 8: 'N', 9: 'N', 10: 'N', 11: 'N', 12: 'N', 13: 'N', 14: 'N', 15: 'N', 16: 'N', 17: 'N', 18: 'N', 19: 'N', 20: 'N', 21: 'P', 22: 'N', 23: 'N', 24: 'N', 25: 'N', 26: 'N', 27: 'P', 28: 'N', 29: 'N', 30: 'N', 31: 'N', 32: 'P', 33: 'N', 34: 'N', 35: 'N', 36: 'N', 37: 'N', 38: 'N', 39: 'N', 40: 'N', 41: 'N', 42: 'N', 43: 'N', 44: 'P', 45: 'N', 46: 'N', 47: 'N', 48: 'N', 49: 'N', 50: 'N', 51: 'N', 52: 'N', 53: 'N', 54: 'N', 55: 'N', 56: 'N', 57: 'N', 58: 'N', 59: 'N', 60: 'N', 61: 'P', 62: 'N', 63: 'N', 64: 'N', 65: 'N', 66: 'P', 67: 'N', 68: 'N', 69: 'N', 70: 'N', 71: 'N', 72: 'N', 73: 'N', 74: 'N', 75: 'N', 76: 'P', 77: 'N', 78: 'N', 79: 'N', 80: 'N', 81: 'N', 82: 'N', 83: 'N', 84: 'N', 85: 'P', 86: 'N', 87: 'N', 88: 'N', 89: 'N', 90: 'N', 91: 'N', 92: 'N', 93: 'N', 94: 'N', 95: 'N', 96: 'N', 97: 'N', 98: 'N', 99: 'N', 100: 'N', 101: 'N', 102: 'P', 103: 'N', 104: 'N', 105: 'N', 106: 'N', 107: 'N', 108: 'N', 109: 'N', 110: 'P', 111: 'N', 112: 'N', 113: 'N', 114: 'N', 115: 'N', 116: 'N', 117: 'N', 118: 'N', 119: 'N', 120: 'N', 121: 'N', 122: 'N', 123: 'N', 124: 'N', 125: 'N', 126: 'N', 127: 'N', 128: 'N', 129: 'N', 130: 'N', 131: 'N', 132: 'N', 133: 'N', 134: 'N', 135: 'N', 136: 'N', 137: 'N', 138: 'N', 139: 'N', 140: 'N', 141: 'N', 142: 'P', 143: 'N', 144: 'N', 145: 'N', 146: 'N', 147: 'N', 148: 'P', 149: 'N', 150: 'N', 151: 'N', 152: 'P', 153: 'N', 154: 'P', 155: 'P', 156: 'N', 157: 'N', 158: 'P', 159: 'N', 160: 'N', 161: 'N', 162: 'N', 163: 'N', 164: 'N', 165: 'N', 166: 'N', 167: 'P', 168: 'N', 169: 'N', 170: 'N', 171: 'N', 172: 'N', 173: 'N', 174: 'N', 175: 'N', 176: 'N', 177: 'P', 178: 'N', 179: 'N', 180: 'N', 181: 'N', 182: 'N', 183: 'N', 184: 'N', 185: 'N', 186: 'P', 187: 'N', 188: 'N', 189: 'N', 190: 'N', 191: 'N', 192: 'N', 193: 'N', 194: 'N', 195: 'N', 196: 'N', 197: 'N', 198: 'N', 199: 'N', 200: 'N', 201: 'N', 202: 'N', 203: 'P', 204: 'N', 205: 'N', 206: 'N', 207: 'N', 208: 'P', 209: 'N', 210: 'N', 211: 'N', 212: 'N', 213: 'N', 214: 'N', 215: 'N', 216: 'N', 217: 'N', 218: 'P', 219: 'N', 220: 'N', 221: 'N', 222: 'N', 223: 'N', 224: 'N', 225: 'N', 226: 'N', 227: 'N', 228: 'N', 229: 'N', 230: 'N', 231: 'P', 232: 'N', 233: 'N', 234: 'P', 235: 'N', 236: 'N', 237: 'N', 238: 'N', 239: 'N', 240: 'N', 241: 'N', 242: 'N', 243: 'N', 244: 'N', 245: 'N', 246: 'P', 247: 'N', 248: 'N', 249: 'N', 250: 'N', 251: 'N', 252: 'N', 253: 'N', 254: 'N', 255: 'N', 256: 'P', 257: 'N', 258: 'N', 259: 'N', 260: 'N', 261: 'N', 262: 'N', 263: 'P', 264: 'P', 265: 'N', 266: 'N', 267: 'N', 268: 'N', 269: 'N', 270: 'N', 271: 'N', 272: 'N', 273: 'N', 274: 'P', 275: 'N', 276: 'N', 277: 'N', 278: 'N', 279: 'N', 280: 'N', 281: 'N', 282: 'N', 283: 'P', 284: 'N', 285: 'N', 286: 'N', 287: 'N', 288: 'N', 289: 'N', 290: 'N', 291: 'N', 292: 'N', 293: 'N', 294: 'N', 295: 'N', 296: 'N', 297: 'N', 298: 'P', 299: 'N', 300: 'N', 301: 'N', 302: 'N', 303: 'N', 304: 'N', 305: 'N', 306: 'N', 307: 'N', 308: 'N', 309: 'P', 310: 'N', 311: 'N', 312: 'N', 313: 'N', 314: 'N', 315: 'N', 316: 'N', 317: 'N', 318: 'N', 319: 'N', 320: 'N', 321: 'P', 322: 'N', 323: 'N', 324: 'N', 325: 'N', 326: 'P', 327: 'N', 328: 'N', 329: 'N', 330: 'N', 331: 'N', 332: 'N', 333: 'N', 334: 'N', 335: 'N', 336: 'N', 337: 'N', 338: 'N', 339: 'N', 340: 'N', 341: 'N', 342: 'N', 343: 'N', 344: 'N', 345: 'N', 346: 'N', 347: 'P', 348: 'N', 349: 'N', 350: 'N', 351: 'N', 352: 'N', 353: 'N', 354: 'N', 355: 'P', 356: 'N', 357: 'N', 358: 'N', 359: 'N', 360: 'N', 361: 'N', 362: 'N', 363: 'N', 364: 'P', 365: 'N', 366: 'N', 367: 'N', 368: 'N', 369: 'P', 370: 'N', 371: 'N', 372: 'N', 373: 'N', 374: 'N', 375: 'N', 376: 'N', 377: 'N', 378: 'N', 379: 'N', 380: 'N', 381: 'N', 382: 'N', 383: 'N', 384: 'N', 385: 'P', 386: 'N', 387: 'N', 388: 'N', 389: 'N', 390: 'N', 391: 'N', 392: 'N', 393: 'N', 394: 'N', 395: 'N', 396: 'N', 397: 'N', 398: 'N', 399: 'N', 400: 'N', 401: 'N', 402: 'N', 403: 'N', 404: 'N', 405: 'N', 406: 'N', 407: 'P', 408: 'N', 409: 'N', 410: 'N', 411: 'N', 412: 'N', 413: 'N', 414: 'N', 415: 'N', 416: 'N', 417: 'N', 418: 'P', 419: 'N', 420: 'N', 421: 'N', 422: 'N', 423: 'N', 424: 'N', 425: 'N', 426: 'N', 427: 'N', 428: 'N', 429: 'N', 430: 'N', 431: 'N', 432: 'N', 433: 'P', 434: 'N', 435: 'N', 436: 'N', 437: 'N', 438: 'N', 439: 'N', 440: 'P', 441: 'N', 442: 'N', 443: 'N', 444: 'N', 445: 'N', 446: 'N', 447: 'N', 448: 'N', 449: 'N', 450: 'N', 451: 'N', 452: 'N', 453: 'N', 454: 'N', 455: 'N', 456: 'N', 457: 'N', 458: 'N', 459: 'P', 460: 'N', 461: 'N', 462: 'N', 463: 'N', 464: 'N', 465: 'N', 466: 'N', 467: 'N', 468: 'N', 469: 'N', 470: 'P', 471: 'N', 472: 'N', 473: 'N', 474: 'N', 475: 'N', 476: 'N', 477: 'N', 478: 'N', 479: 'P', 480: 'N', 481: 'N', 482: 'P', 483: 'N', 484: 'N', 485: 'N', 486: 'N', 487: 'N', 488: 'N', 489: 'P', 490: 'N', 491: 'N', 492: 'N', 493: 'N', 494: 'N', 495: 'N', 496: 'N', 497: 'N', 498: 'N', 499: 'N'}\n"
          ]
        }
      ],
      "source": [
        "# Test:\n",
        "fraction_protected = 0.1  # 40% of nodes will be protected\n",
        "protection_status_dict = assign_protection(H2, fraction_protected)\n",
        "print(protection_status_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F71C7Qfa_b9I"
      },
      "source": [
        "\n",
        "## Part 3: Assign Threshold\n",
        "The following steps assigns a threshold value to each node in the network. The threshold follows a uniform or normal distribution with predefined mean (mu) and standard deviation (sigma)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ky4HFlQR_jBY"
      },
      "outputs": [],
      "source": [
        "# Defines the parameters to be used\n",
        "mu = 0.1\n",
        "sigma = 0.05\n",
        "\n",
        "# Function to assign thresholds to the individual nodes\n",
        "def assign_thresholds(hypergraph, mu, sigma):\n",
        "    NV = hypergraph.order()\n",
        "    Ltre = {}\n",
        "\n",
        "    for node in hypergraph.nodes():\n",
        "          # Uniform distribution: #\n",
        "          #Ltre[node] = np.random.uniform()\n",
        "          # Normal distrution\n",
        "          while True:\n",
        "              threshold = random.gauss(mu, sigma)\n",
        "              if 0 < threshold < 1:\n",
        "                  break\n",
        "          Ltre[node] = threshold\n",
        "\n",
        "    return Ltre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ11eyyS_o1O",
        "outputId": "5dc2f07f-51f1-4930-f76f-71c6a0482329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold List for Nodes:  {0: 0.08614693994887153, 1: 0.07163264965785941, 2: 0.11822510312150224, 3: 0.1091929703583276, 4: 0.19290352495059454, 5: 0.013468964191898108, 6: 0.08273506039222056, 7: 0.07849012988862682, 8: 0.007642489541886163, 9: 0.05725877677524296, 10: 0.21208291031025905, 11: 0.1677874975320915, 12: 0.0975937867209018, 13: 0.08691338830396862, 14: 0.12846932298230657, 15: 0.12207107054791944, 16: 0.1478402508136505, 17: 0.02284750779180174, 18: 0.09106837606579239, 19: 0.05231074781850554, 20: 0.1091552742841071, 21: 0.09855926276029434, 22: 0.08759003658805556, 23: 0.15638847457309424, 24: 0.022445959076666716, 25: 0.14362492123321494, 26: 0.11157481079423842, 27: 0.13933635811934153, 28: 0.09459374689748748, 29: 0.16026686990043312, 30: 0.1466264171056589, 31: 0.13962865584431852, 32: 0.08175200638051246, 33: 0.2012204455518007, 34: 0.09862838485907313, 35: 0.015564386166965608, 36: 0.14188032928705413, 37: 0.11127632022732842, 38: 0.09335500233318107, 39: 0.11114661733996056, 40: 0.19579049809160362, 41: 0.12098318725959155, 42: 0.15538538475966462, 43: 0.1012477215254898, 44: 0.06095099142434214, 45: 0.12981930477878545, 46: 0.18733417804277683, 47: 0.0641999357414364, 48: 0.1588610681022201, 49: 0.1481943952044294, 50: 0.10333836681078676, 51: 0.18586233488765724, 52: 0.1117133425406811, 53: 0.0824148995809143, 54: 0.09439906776211232, 55: 0.16458407678678466, 56: 0.08017605844431555, 57: 0.12161897535391157, 58: 0.1016616889013275, 59: 0.12708234077049455, 60: 0.05817796935275143, 61: 0.16842589527712498, 62: 0.10348208077790233, 63: 0.13464322184064847, 64: 0.13160242712191594, 65: 0.10415740592384291, 66: 0.00033511789283631466, 67: 0.09662754365322843, 68: 0.0649512168032389, 69: 0.06780822033124331, 70: 0.1329142389969184, 71: 0.13113577799263937, 72: 0.026702746551586234, 73: 0.08568291013767287, 74: 0.10239080002487626, 75: 0.09087040486887128, 76: 0.15887889530307875, 77: 0.10598030852950983, 78: 0.13509686816081584, 79: 0.1042147833010593, 80: 0.1171003993689952, 81: 0.19837859351418408, 82: 0.09189301761992133, 83: 0.09294483724637567, 84: 0.10591501529988548, 85: 0.13113394892921287, 86: 0.07133814336301221, 87: 0.1047313997767553, 88: 0.12489507070607478, 89: 0.09035786535559537, 90: 0.09819789677489091, 91: 0.10024103137362303, 92: 0.08023072968702295, 93: 0.05308828109096936, 94: 0.10382626238366088, 95: 0.05676752959570305, 96: 0.07252664457133552, 97: 0.1562657759046227, 98: 0.14429842404635077, 99: 0.08698623212613121, 100: 0.1344179513739245, 101: 0.16674709671667617, 102: 0.18321291571080356, 103: 0.09912127697275853, 104: 0.08074013410771312, 105: 0.1110109150352443, 106: 0.064507401577336, 107: 0.08624509862204356, 108: 0.0914438546606543, 109: 0.13142674492234932, 110: 0.09415792674232634, 111: 0.10920058021041129, 112: 0.13313967332011453, 113: 0.19884244160035297, 114: 0.10301717998024983, 115: 0.12568834796864342, 116: 0.1365535157142968, 117: 0.09763634024873252, 118: 0.1125753438568654, 119: 0.17703739230608287, 120: 0.05168875235382331, 121: 0.08265532231269251, 122: 0.10439368227720205, 123: 0.13302694310491847, 124: 0.07327802267316064, 125: 0.1011277356107576, 126: 0.13019773938345214, 127: 0.07007286543662351, 128: 0.06658505485151647, 129: 0.11053545189445513, 130: 0.1330844466752012, 131: 0.12572806049731206, 132: 0.10850010431408193, 133: 0.11687296356695187, 134: 0.15598286264133124, 135: 0.0629095232991227, 136: 0.052412019902360246, 137: 0.09734734994458615, 138: 0.1409442578948188, 139: 0.09945154686780286, 140: 0.07593516909730189, 141: 0.11271542279366004, 142: 0.11263525033791082, 143: 0.09257740614291415, 144: 0.05731443267300388, 145: 0.14841614015953372, 146: 0.13172179959440586, 147: 0.14225165125257203, 148: 0.11599649577682043, 149: 0.17906657923885244, 150: 0.14139273903645683, 151: 0.05732502264183986, 152: 0.1642176140642402, 153: 0.06810131524038693, 154: 0.18031030240875556, 155: 0.022005577545759686, 156: 0.14433037648674746, 157: 0.06253188143140193, 158: 0.12525597837316071, 159: 0.10810537033895919, 160: 0.0663280038451062, 161: 0.15252759325065793, 162: 0.03207278858416156, 163: 0.13549089903877004, 164: 0.12142595105728146, 165: 0.08981199658814563, 166: 0.05348660884455417, 167: 0.14433380640301907, 168: 0.10917801903571518, 169: 0.09800679779144368, 170: 0.1125352772975115, 171: 0.21139847048668536, 172: 0.11336504697282254, 173: 0.09770116875588715, 174: 0.05257294275550914, 175: 0.07954057831162462, 176: 0.13600119822455514, 177: 0.10003389357377557, 178: 0.137566581273607, 179: 0.11048958681990198, 180: 0.11298061953002927, 181: 0.2063101145327539, 182: 0.1500210737845706, 183: 0.1172431520362886, 184: 0.09444383585245635, 185: 0.0775385863224132, 186: 0.1439245180413257, 187: 0.03149050706354467, 188: 0.0010570970943463986, 189: 0.129004663708024, 190: 0.16591537320431993, 191: 0.0855563134435525, 192: 0.070478598449635, 193: 0.036929818549529786, 194: 0.06668415312564496, 195: 0.1406075141713934, 196: 0.11018588002421585, 197: 0.17374511288464312, 198: 0.039677663662880905, 199: 0.07856076611815638, 200: 0.11295761637180637, 201: 0.0949978321006016, 202: 0.16231668820261913, 203: 0.2145009416033502, 204: 0.03584927190160665, 205: 0.1145787678877097, 206: 0.14357696598276756, 207: 0.10493203915108099, 208: 0.10726529656989192, 209: 0.07968609374652831, 210: 0.037494436148771, 211: 0.0747679538094713, 212: 0.03514519954652305, 213: 0.10380203230238112, 214: 0.11975709166458406, 215: 0.07375688889873727, 216: 0.14111368222429185, 217: 0.12606146532591833, 218: 0.0009913783222267047, 219: 0.10793645906261741, 220: 0.112016053290944, 221: 0.1467215751755631, 222: 0.04288025936259862, 223: 0.08310173651817002, 224: 0.06527323547828821, 225: 0.1500336127778784, 226: 0.14656042031279437, 227: 0.03829157740185499, 228: 0.08836725877152236, 229: 0.11777042191140435, 230: 0.07312496324543802, 231: 0.03707637626001209, 232: 0.06175394837525387, 233: 0.026228337342055805, 234: 0.07378424518630634, 235: 0.033979281156451754, 236: 0.09141050956374844, 237: 0.019776915056988892, 238: 0.044437618159858465, 239: 0.0331659460020349, 240: 0.13309443045390473, 241: 0.08983205385790057, 242: 0.10981815539711925, 243: 0.12708893018123127, 244: 0.09856125074566585, 245: 0.11059429668329633, 246: 0.16279716474922748, 247: 0.19239167681697736, 248: 0.1094700130737655, 249: 0.19237289479046338, 250: 0.13505271193868562, 251: 0.02264904719935132, 252: 0.18721090631802076, 253: 0.04474354694029223, 254: 0.1823461424033832, 255: 0.07175216491654283, 256: 0.06354634508894808, 257: 0.15778157871975812, 258: 0.045750826339036155, 259: 0.13159308851397253, 260: 0.11159440358601297, 261: 0.03592816166572896, 262: 0.061788029579904785, 263: 0.1304450586501458, 264: 0.13685130405954693, 265: 0.15510886333090593, 266: 0.12470405793659592, 267: 0.02210600465312737, 268: 0.04758855007868551, 269: 0.06829434178100383, 270: 0.1052086625573908, 271: 0.08375783334308545, 272: 0.10930968539263294, 273: 0.15230937643991027, 274: 0.09173102668515704, 275: 0.11485906439080246, 276: 0.12768912613796707, 277: 0.18450525457290975, 278: 0.08849753279302702, 279: 0.04844482525081424, 280: 0.14798849580511525, 281: 0.0913303107251689, 282: 0.12424491616559873, 283: 0.08162184468921074, 284: 0.06778998786263897, 285: 0.11927138561191916, 286: 0.13488563797319747, 287: 0.10968999621159663, 288: 0.08916024787054154, 289: 0.08935970488191812, 290: 0.09118069818309642, 291: 0.06519722339935667, 292: 0.12232419883666559, 293: 0.12106176302022552, 294: 0.06923492508739748, 295: 0.08803212208466601, 296: 0.14379568352876415, 297: 0.1150961034043679, 298: 0.06236751230441617, 299: 0.17043196602376537, 300: 0.09229117877754504, 301: 0.03463867040706202, 302: 0.09649576113458443, 303: 0.042983377438549866, 304: 0.06957950900610842, 305: 0.14394298184197976, 306: 0.08927747921085707, 307: 0.06683484809088858, 308: 0.023380693543141234, 309: 0.049239100094206546, 310: 0.0933618447057862, 311: 0.18101216376972742, 312: 0.1233681572422908, 313: 0.08710318857852871, 314: 0.05737604333056837, 315: 0.1868618674758959, 316: 0.11696084476063143, 317: 0.06502503752416106, 318: 0.0632403241737963, 319: 0.12222704500323735, 320: 0.07539578307609762, 321: 0.061873558958379954, 322: 0.02983289263980668, 323: 0.0775552930745119, 324: 0.0490005742527238, 325: 0.031080170737088283, 326: 0.07884011226209732, 327: 0.07787528664777044, 328: 0.10688880521484805, 329: 0.09670577086772769, 330: 0.06000987548495615, 331: 0.16584918562947548, 332: 0.14550980531607624, 333: 0.07947160882250837, 334: 0.10696527249124849, 335: 0.1491345545276015, 336: 0.07948331701596331, 337: 0.09240008546268348, 338: 0.15122330204744275, 339: 0.12205414078758284, 340: 0.04033819046407026, 341: 0.16132624646313753, 342: 0.1335200332637353, 343: 0.13463723583912918, 344: 0.04081375782789896, 345: 0.04807394637796393, 346: 0.07634732419777175, 347: 0.06691888255980377, 348: 0.06499745651290799, 349: 0.16022924600704272, 350: 0.037963455009712745, 351: 0.19315604977296583, 352: 0.06285625174836743, 353: 0.17640357054798889, 354: 0.07944870092482285, 355: 0.07410789670394717, 356: 0.05193934723645215, 357: 0.10422736914387369, 358: 0.02828971691376833, 359: 0.17889933571241368, 360: 0.10094496374474803, 361: 0.1648198474153557, 362: 0.08613140370596636, 363: 0.06694743071770617, 364: 0.1617288956337806, 365: 0.09408536660090588, 366: 0.12480658280340193, 367: 0.09629805288006968, 368: 0.11331737558348462, 369: 0.11726248138955, 370: 0.07567698177138911, 371: 0.13627335388677164, 372: 0.029242996525853757, 373: 0.15412453683914606, 374: 0.10484464241355856, 375: 0.05297659692778106, 376: 0.060310475712944324, 377: 0.17086307336024847, 378: 0.0930922614172101, 379: 0.0470430987303327, 380: 0.06382496951201438, 381: 0.18133171198517345, 382: 0.1364870639963384, 383: 0.05871730878430043, 384: 0.14453039377279814, 385: 0.1521628080094364, 386: 0.08509551434959142, 387: 0.11625581198386095, 388: 0.05139706578057208, 389: 0.1079008318151284, 390: 0.10472003897002788, 391: 0.07577411868397088, 392: 0.1080288759567988, 393: 0.07132621272031853, 394: 0.09521442114115117, 395: 0.08279138258443117, 396: 0.14728000087569185, 397: 0.08597587801801063, 398: 0.1393370711073291, 399: 0.13507430777899992, 400: 0.1286034087948832, 401: 0.11220734429687157, 402: 0.1321298793877932, 403: 0.06697631511114835, 404: 0.16962293220593272, 405: 0.0913721838510369, 406: 0.06071719750016426, 407: 0.1669096556882258, 408: 0.1476350359245197, 409: 0.00024585168139543145, 410: 0.08629210529364927, 411: 0.0604545034272459, 412: 0.1406552024357959, 413: 0.06853889378361006, 414: 0.040985763101574535, 415: 0.10119277081927583, 416: 0.11650049023784682, 417: 0.08896378630285252, 418: 0.06651665194745093, 419: 0.12626998279874976, 420: 0.04532178586292451, 421: 0.03165831140443193, 422: 0.06558549736014058, 423: 0.10088538008382521, 424: 0.14098466965132578, 425: 0.054141526346397566, 426: 0.0975591717494436, 427: 0.10426068633893942, 428: 0.12882718034524482, 429: 0.12670688593360405, 430: 0.1213379428963272, 431: 0.12754700452525908, 432: 0.026815039958288128, 433: 0.04123177444617476, 434: 0.15391789656870664, 435: 0.14991307682862812, 436: 0.14767288392959055, 437: 0.05879436070615601, 438: 0.07197752461840944, 439: 0.12879895849493136, 440: 0.08030566016458286, 441: 0.14986604794702515, 442: 0.1179606170545386, 443: 0.08480966171691043, 444: 0.06154944383037991, 445: 0.22373515255288778, 446: 0.06791183438742615, 447: 0.07497127090486287, 448: 0.12033166137377758, 449: 0.061606980350471297, 450: 0.14206042809254044, 451: 0.17079531619832672, 452: 0.08355110549316695, 453: 0.06633506186472585, 454: 0.19619500238763538, 455: 0.06663219916370888, 456: 0.07795855115331626, 457: 0.07385738551765289, 458: 0.20588927295301587, 459: 0.041200386590366636, 460: 0.023555133870206385, 461: 0.07882252134638947, 462: 0.07474308963984339, 463: 0.048960986731241884, 464: 0.11674630077986461, 465: 0.016646560768083213, 466: 0.1222587669280113, 467: 0.1102744547831453, 468: 0.18969311075292547, 469: 0.11802487173037697, 470: 0.0326797334740483, 471: 0.044389024494782575, 472: 0.06162365833142892, 473: 0.1361416485310953, 474: 0.0712118423467342, 475: 0.07679199480556828, 476: 0.20160177296787787, 477: 0.09151330119041359, 478: 0.08245149195937548, 479: 0.10965779713927142, 480: 0.16648348672470525, 481: 0.12135730201036626, 482: 0.08656611014009057, 483: 0.06447758307022111, 484: 0.14189524424709626, 485: 0.13749304157137654, 486: 0.1622354463148785, 487: 0.09584211528285423, 488: 0.12230983987229192, 489: 0.07788032498435367, 490: 0.1317730409470327, 491: 0.04355034177156957, 492: 0.02290843305654286, 493: 0.07720660386709802, 494: 0.10624063388206234, 495: 0.021924918990659736, 496: 0.0668237456462093, 497: 0.0910788581646842, 498: 0.14209862757505087, 499: 0.14388133755360455}\n"
          ]
        }
      ],
      "source": [
        "Ltre2 = assign_thresholds(H2, mu, sigma)\n",
        "\n",
        "print(\"Threshold List for Nodes: \", Ltre2 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSmz7Gj6AA9m"
      },
      "source": [
        "# Part 4: The ICE Model (The Information Cognition Epidemics Model)\n",
        "## Information Layer\n",
        "The misinformation spread occurs on a hyperedge network involving group spreading. The three stages are U(unaware), G(gossip/spreader), and C(stifler/corrected).  \n",
        "\n",
        "## Cognition Layer\n",
        "In the cognitive behavioral layer, P is protected, and N is not protected. The rate of transition from state P to N, p, depends on the information layer. The rate from NP to P is 1-p. The transition rate of a node is also affected by the number of active spreader/stiflers. The bigger number of active neighbors, the faster the rate. Another way behavior may change is based on the fraction of protected neighbors.\n",
        "\n",
        "## Epidemics Layer\n",
        "In the epidemics layer, the possible disease states are S(susceptible), I(infected), and R(recovered). The illness spreading is pairwise. The disease propagation rate depends on the fraction of protected individuals $\\rho_P$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3rNTHw7F-6v"
      },
      "outputs": [],
      "source": [
        "def ICE_model(inw, ldeg_i, ltre, cnw, ldeg_c, lprot, enw, ldeg_e, lam, alp, zeta_1, zeta_2, zeta_3, zeta_4, beta_PP, beta_NP, beta_PN, beta_NN, mu, n_sample):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "      inw - information hyperedge network\n",
        "      ltre - list of thresholds for informaiton spread\n",
        "      ldeg_i - degree sequence of information layer\n",
        "\n",
        "      cnw - cognitive network\n",
        "      lprot - list of protection status\n",
        "      ldeg_c - degree sequence of cognition layer\n",
        "\n",
        "      enw - epidemic pairwise network\n",
        "      ldeg_e - degree sequence of epidemic layer\n",
        "\n",
        "      lambda - information spreading rate\n",
        "      alp - informaiton stifling rate\n",
        "\n",
        "      zeta_1 - removing protection rate based on information\n",
        "      zeta_2 - removing protection rate based on neighborhood behavior\n",
        "      zeta_1 - adopting protection rate based on information\n",
        "      zeta_2 - adopting protection rate based on neighborhood behavior\n",
        "\n",
        "      beta_PP - disease transmission rate between protected S and protected I\n",
        "      beta_NP - disease transmission rate between not protected S and protected I\n",
        "      beta_PN - disease transmission rate between protected S and not protected I\n",
        "      beta_NN - disease transmission rate between not protected S and not protected I\n",
        "\n",
        "      mu - disease recovery rate\n",
        "\n",
        "      n_sample - number of samples\n",
        "  \"\"\"\n",
        "\n",
        "  t_max = 1000      # Set maximum time\n",
        "  kmax_i = max (ldeg_i)     # Get maximum hyperedge degree in information layer\n",
        "  kmax_c = max (ldeg_c)     # Get maximum hyperedge degree in cognition layer\n",
        "  kmax_e = max (ldeg_e)     # Get maximum degree in epidemic layer\n",
        "  N = inw.order()  # Get the network size\n",
        "\n",
        "  rho_C = []   # Keep track of fraction of corrected in information layer\n",
        "  rho_P = []   # Keep track of fraction of protected in cognition layer\n",
        "  rho_R = []   # Keep track of fraction of recovered in epidemic layer\n",
        "\n",
        "  for i_samp in range(1, n_sample + 1):\n",
        "      t = 0                 # Initialize time, number of corrected, number of recovered\n",
        "      N_corrected = 0\n",
        "      N_recovered = 0\n",
        "\n",
        "      info_states = {j: \"U\" for j in inw.nodes()}   # Initialize information and disease states\n",
        "      disease_states = {k: \"S\" for k in enw.nodes()}\n",
        "\n",
        "      protected = list(filter(lambda node: lprot[node] == \"P\", lprot))\n",
        "      N_protected = len(protected)\n",
        "      not_protected = list(filter(lambda node: lprot[node] == \"N\", lprot))\n",
        "\n",
        "\n",
        "      gossip = []     # Create lists to store gossip and corrected individuals in information layer\n",
        "      corrected = []\n",
        "\n",
        "      rumor_node_0 = np.random.choice(list(inw.nodes()))   # Pick a random person to start misinformaiton spreading\n",
        "      info_states[rumor_node_0] = \"G\"\n",
        "      gossip.append(rumor_node_0)\n",
        "      N_gossip = 1\n",
        "      N_e_i = inw.degree(rumor_node_0)\n",
        "\n",
        "      infected = []     # Create lists to store infected and recovered individuals in epidemic layer\n",
        "      recovered = []\n",
        "\n",
        "      ill_node_0 = np.random.choice(list(enw.nodes()))   # Pick a random person to start disease spreading\n",
        "      disease_states[ill_node_0] = \"I\"\n",
        "      infected.append(ill_node_0)\n",
        "      N_infected = 1\n",
        "      N_e_e = enw.degree(ill_node_0)\n",
        "\n",
        "      while N_gossip > 0:   # We stop when there is no infection and no gossip\n",
        "          total_rate = lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected + zeta_1 * N_protected + zeta_2 * (N-N_protected) + zeta_3 * N_protected + zeta_4 * (N-N_protected)\n",
        "          tau = -np.log(np.random.uniform(1e-6, 1)) / total_rate\n",
        "          t += tau\n",
        "\n",
        "          if t >= t_max:\n",
        "                break\n",
        "\n",
        "          # Determine which event occurs\n",
        "          event = np.random.uniform()\n",
        "          p1 = (lam * N_e_i) / total_rate     # rumor spreading\n",
        "          p2 = (lam * N_e_i + alp * N_e_i) / total_rate  # rumor stifling (by meeting stifling neighbor threshold)\n",
        "          p3 = (lam * N_e_i + 2 * alp * N_e_i) / total_rate  # rumor stifling (by meeting gossip neighbor threshold)\n",
        "\n",
        "          p4 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e) / total_rate  # disease propagation\n",
        "          p5 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected) / total_rate  # disease recovery\n",
        "\n",
        "          p6 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected + zeta_1 * N_protected) / total_rate # change to not adopting protection by information\n",
        "          p7 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected + zeta_1 * N_protected + zeta_2 * (N-N_protected) ) / total_rate # change to adopting protection by information\n",
        "          p8 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected + zeta_1 * N_protected + zeta_2 * (N-N_protected)  + zeta_3 * N_protected) / total_rate # change to not adopting protection by neighborhood behavior\n",
        "          # > p8 # change to adopting protection by neighborhood behavior\n",
        "          #print(p1, p2, p3, p4, p5, p6, p7, p8)\n",
        "\n",
        "          # Determine if accept selected individual based on degree distribution\n",
        "          q_deg_i = np.random.uniform()\n",
        "          q_deg_c = np.random.uniform()\n",
        "          q_deg_e = np.random.uniform()\n",
        "\n",
        "          # Case 1: Rumor spreading\n",
        "          if event < p1:\n",
        "                gossip_node = random.choice(gossip)\n",
        "                if q_deg_i < inw.degree(gossip_node) / kmax_i:\n",
        "                    rumor_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                    neighbors = inw[rumor_hyper_edge]\n",
        "                    \"\"\"\n",
        "                    while gossip_node not in neighbors:\n",
        "                        rumor_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                        neighbors = inw[rumor_hyper_edge]\n",
        "                    \"\"\"\n",
        "                    MAX_ITERATIONS = 20 # Set a reasonable limit based on your specific case\n",
        "                    iterations = 0\n",
        "                    while gossip_node not in neighbors:\n",
        "                        if iterations > MAX_ITERATIONS:\n",
        "                           break\n",
        "                        rumor_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                        neighbors = inw[rumor_hyper_edge]\n",
        "                        iterations += 1\n",
        "\n",
        "                    for neighbor in neighbors:\n",
        "                            if info_states[neighbor] == \"U\":\n",
        "                                count_gossip_neighbors = sum(1 for node in inw.neighbors(neighbor) if info_states[node] == \"G\")\n",
        "                                if count_gossip_neighbors / len(inw.neighbors(neighbor)) >= ltre[neighbor]:\n",
        "                                    info_states[neighbor] = \"G\"  # uninformed neighbor becomes gossip spreader\n",
        "                                    gossip.append(neighbor)\n",
        "                                    N_gossip += 1\n",
        "\n",
        "\n",
        "\n",
        "          # Case 2: Rumor stifling (by meeting stifling neighbor threshold)\n",
        "          elif event < p2:\n",
        "            #if N_gossip > 0:\n",
        "                stifler_node = np.random.choice(gossip)\n",
        "                if q_deg_i < inw.degree(stifler_node)  / kmax_i:\n",
        "                    stifler_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                    neighbors = inw[stifler_hyper_edge]\n",
        "                    count_stifler_neighbors = sum(1 for node in inw.neighbors(stifler_node) if info_states[node] == \"C\")\n",
        "                    if count_stifler_neighbors / len(neighbors) >= 0.3: # New rule #2 for recovery\n",
        "                    #neighbor = np.random.choice(neighbors) # New rule for recovery\n",
        "                    #if info_states[neighbor==\"C\"]:\n",
        "                            info_states[stifler_node] = \"C\"\n",
        "                            N_gossip -= 1\n",
        "                            gossip.remove(stifler_node)\n",
        "                            corrected.append(stifler_node)\n",
        "                            N_corrected += 1\n",
        "\n",
        "          # Case 3: Rumor stifling (by meeting gossip neighbor threshold)\n",
        "          elif event < p3:\n",
        "            #if N_gossip > 0:\n",
        "                stifler_node = np.random.choice(gossip)\n",
        "                if q_deg_i < inw.degree(stifler_node) / kmax_i:\n",
        "                    stifler_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                    neighbors = inw[stifler_hyper_edge]\n",
        "                    count_gossip_neighbors = sum(1 for node in inw.neighbors(stifler_node) if info_states[node] == \"G\")\n",
        "                    if count_gossip_neighbors / len(neighbors) >= 0.3: # New rule #2 for recovery\n",
        "                    #neighbor = np.random.choice(neighbors) # New rule for recovery\n",
        "                    #if info_states[neighbor==\"G\"]:\n",
        "                            info_states[stifler_node] = \"C\"\n",
        "                            N_gossip -= 1\n",
        "                            gossip.remove(stifler_node)\n",
        "                            corrected.append(stifler_node)\n",
        "                            N_corrected += 1\n",
        "\n",
        "          # Case 4: Disease propagation\n",
        "          elif event < p4:\n",
        "            if N_infected > 0:\n",
        "              infected_node = np.random.choice(infected)\n",
        "              infected_protected = lprot[infected_node]\n",
        "              neighbors = list(enw.neighbors(infected_node))\n",
        "              susceptible_neighbors = [n for n in neighbors if disease_states[n] == \"S\"]\n",
        "\n",
        "              if len(susceptible_neighbors) > 0:\n",
        "                  neighbor = np.random.choice(susceptible_neighbors)\n",
        "                  neighbor_protected = lprot[neighbor]\n",
        "\n",
        "                  # Determine the appropriate transmission rate based on protection status\n",
        "                  if neighbor_protected == \"P\" and infected_protected == \"P\":\n",
        "                            transmission_rate = beta_PP/beta_NN\n",
        "                  elif neighbor_protected == \"N\" and infected_protected == \"P\":\n",
        "                            transmission_rate = beta_NP/beta_NN\n",
        "                  elif neighbor_protected == \"P\" and infected_protected == \"N\":\n",
        "                            transmission_rate = beta_PN/beta_NN\n",
        "                  else:\n",
        "                            transmission_rate = beta_NN/beta_NN\n",
        "\n",
        "                  if np.random.uniform() < transmission_rate:\n",
        "                      disease_states[neighbor] = \"I\"\n",
        "                      infected.append(neighbor)\n",
        "                      N_infected += 1\n",
        "                      N_e_e += enw.degree(neighbor)\n",
        "\n",
        "          # Case 5: Disease recovery\n",
        "          elif event < p5:\n",
        "            if N_infected > 0:\n",
        "                recovered_node = np.random.choice(infected)\n",
        "                if q_deg_e < ldeg_e[recovered_node]/kmax_e:\n",
        "                    disease_states[recovered_node] = \"R\"\n",
        "                    infected.remove(recovered_node)\n",
        "                    recovered.append(recovered_node)\n",
        "                    N_infected -= 1\n",
        "                    N_recovered += 1\n",
        "                    N_e_e -= enw.degree(recovered_node)\n",
        "\n",
        "\n",
        "          # Case 6: # Change to not adopting protection based on information layer\n",
        "          # rate = zeta_1 * n_G / k_info\n",
        "          # n_G is the total spreader neighbors on the information layer,\n",
        "          # while k_info is the total neighbor count on the information layer\n",
        "          elif event < p6:\n",
        "            if len(protected) > 0:\n",
        "              node_to_not_protect = np.random.choice(protected)\n",
        "              n_G = sum(1 for node in filter(lambda x: info_states[x] == \"G\", inw.neighbors(node_to_not_protect)))\n",
        "              k_info = len(list(inw.neighbors(node_to_not_protect)))\n",
        "              if np.random.uniform() < zeta_1 * n_G / k_info:\n",
        "                    lprot[node_to_not_protect] = \"N\"\n",
        "                    protected.remove(node_to_not_protect)\n",
        "                    not_protected.append(node_to_not_protect)\n",
        "                    N_protected -= 1\n",
        "\n",
        "          # Case 7: Change to adopting protection based on information layer\n",
        "          # rate = zeta_2 * (1 - n_G / k_info)\n",
        "          elif event < p7:\n",
        "            if len(not_protected) > 0:\n",
        "                node_to_protect = np.random.choice(not_protected)\n",
        "                n_G = sum(1 for node in filter(lambda x: info_states[x] == \"G\", inw.neighbors(node_to_protect)))\n",
        "                k_info = len(list(inw.neighbors(node_to_protect)))\n",
        "                if np.random.uniform() < zeta_2 * (1 - n_G / k_info):\n",
        "                        lprot[node_to_protect] = \"P\"\n",
        "                        not_protected.remove(node_to_protect)\n",
        "                        protected.append(node_to_protect)\n",
        "                        N_protected += 1\n",
        "\n",
        "\n",
        "          # Case 8: # Change to not adopting protection based on neighborhood behavior in cognition layer\n",
        "          # rate = zeta_3 * (1 - n_P / k_cog)\n",
        "          # n_P is the total protected neighbors on the cognition layer,\n",
        "          # while k_cog is the total neighbor count on the cognition layer\n",
        "          elif event < p8:\n",
        "            if len(protected) > 0:\n",
        "                node_to_not_protect = np.random.choice(protected)\n",
        "                n_P = sum(1 for node in filter(lambda x: lprot[x] == \"P\", cnw.neighbors(node_to_not_protect)))\n",
        "                k_cog = len(list(cnw.neighbors(node_to_not_protect)))\n",
        "                if np.random.uniform() < zeta_3 * (1 - n_P / k_cog):\n",
        "                        lprot[node_to_not_protect] = \"N\"\n",
        "                        protected.remove(node_to_not_protect)\n",
        "                        not_protected.append(node_to_not_protect)\n",
        "                        N_protected -= 1\n",
        "\n",
        "\n",
        "          # Case 9: # Change to adopting protection based on neighborhood behavior in cognition layer\n",
        "          # rate = zeta_4 * n_P / k_cog\n",
        "          else:\n",
        "            if len(not_protected) > 0:\n",
        "                node_to_protect = np.random.choice(not_protected)\n",
        "                n_P = sum(1 for node in filter(lambda x: lprot[x] == \"P\", cnw.neighbors(node_to_protect)))\n",
        "                k_cog = len(list(cnw.neighbors(node_to_protect)))\n",
        "                if np.random.uniform() < zeta_4 * n_P / k_cog:\n",
        "                        lprot[node_to_protect] = \"P\"\n",
        "                        not_protected.remove(node_to_protect)\n",
        "                        protected.append(node_to_protect)\n",
        "                        N_protected += 1\n",
        "\n",
        "      #print(\"N_infected\", N_infected, \"N_gossip\", N_gossip)\n",
        "      if N_infected == 0:\n",
        "          corrected_frac = N_corrected / N\n",
        "          protected_frac = N_protected / N\n",
        "          recovered_frac = N_recovered / N\n",
        "          rho_C.append(corrected_frac)\n",
        "          rho_P.append(protected_frac)\n",
        "          rho_R.append(recovered_frac)\n",
        "          #print(\"corrected_frac\", corrected_frac, \"recovered_frac\", recovered_frac)\n",
        "\n",
        "  avg_rho_C = sum(rho_C) / len(rho_C)\n",
        "  avg_rho_P = sum(rho_P) / len(rho_P)\n",
        "  avg_rho_R = sum(rho_R) / len(rho_R)\n",
        "\n",
        "  return avg_rho_C, avg_rho_P, avg_rho_R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_NnnBI-BZpo",
        "outputId": "78b4cea2-a7ca-4072-d80a-97eb0710aea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Degree Sequence:  [5, 7, 3, 3, 3, 3, 22, 3, 3, 4, 3, 3, 3, 6, 3, 5, 4, 3, 3, 14, 3, 18, 3, 11, 20, 7, 4, 3, 5, 9, 4, 8, 4, 3, 3, 5, 4, 6, 3, 9, 3, 4, 4, 5, 5, 4, 4, 12, 5, 3, 3, 8, 4, 3, 5, 3, 3, 3, 8, 3, 3, 4, 11, 6, 3, 5, 3, 3, 4, 3, 17, 3, 3, 3, 3, 21, 7, 5, 4, 3, 4, 5, 6, 4, 3, 3, 4, 13, 3, 3, 3, 7, 4, 5, 4, 5, 4, 3, 4, 3, 3, 3, 7, 3, 3, 4, 10, 3, 3, 3, 3, 3, 5, 5, 3, 4, 4, 3, 7, 6, 9, 4, 5, 4, 10, 4, 3, 6, 3, 3, 5, 4, 3, 6, 4, 4, 5, 3, 5, 18, 3, 3, 4, 4, 3, 5, 6, 3, 3, 3, 3, 4, 7, 21, 4, 6, 3, 3, 6, 4, 3, 5, 3, 5, 3, 6, 3, 3, 6, 3, 13, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
            "Hyper Edge Sizes:  [11, 5, 12, 6, 32, 19, 40, 30, 25, 25, 7, 10, 35, 13, 35, 21, 29, 24, 8, 8, 38, 11, 23, 38, 6, 16, 33, 12, 42, 19, 8, 2, 41, 43, 5, 3, 17, 42, 24, 43, 43, 18, 9, 15, 9, 24, 16, 30, 6, 41, 10, 20, 30, 8, 14, 13, 17, 35, 27, 37, 24, 33, 11, 38, 29, 7, 18, 24, 39, 35, 5, 2, 32, 11, 38, 26, 9, 24, 39, 33, 3, 2, 42, 16, 6, 21, 10, 6, 40, 11, 34, 15, 27, 8, 30, 38, 6, 6, 11, 12]\n",
            "Hypergraph Dictionary:  {89: [0, 120, 142, 202, 226, 250, 260, 297, 390], 20: [0, 6, 24, 26, 69, 70, 93, 106, 145, 148, 151, 153, 161, 220, 237, 270, 271, 326, 350, 369, 376, 390, 398, 403, 404, 410, 414, 421, 440, 464, 484, 490], 79: [0, 12, 24, 47, 62, 84, 88, 94, 105, 109, 139, 143, 147, 159, 175, 176, 186, 194, 203, 227, 248, 279, 286, 327, 330, 393, 399, 409, 433, 494], 7: [0, 6, 21, 30, 70, 87, 88, 105, 115, 153, 195, 267, 288, 291, 293, 303, 320, 324, 337, 363, 368, 374, 438, 459, 465, 495], 52: [0, 3, 6, 52, 81, 112, 121, 128, 215, 227, 228, 229, 236, 241, 246, 297, 325, 338, 367, 376, 377, 385, 395, 419, 476, 496], 12: [1, 28, 36, 41, 47, 50, 65, 72, 75, 86, 97, 124, 137, 138, 178, 180, 201, 206, 239, 317, 325, 359, 407, 431, 447, 459, 468, 477], 88: [1, 15, 19, 22, 29, 35, 42, 59, 64, 75, 95, 108, 112, 118, 163, 164, 170, 176, 181, 207, 250, 267, 275, 304, 308, 353, 356, 371, 399, 407, 419, 427, 428, 433, 461, 467, 494, 495], 25: [1, 34, 35, 37, 119, 120, 139, 159, 177, 204, 215, 331, 390, 488], 82: [1, 6, 19, 39, 40, 52, 61, 70, 100, 106, 107, 108, 122, 128, 138, 145, 153, 166, 215, 234, 238, 256, 267, 268, 294, 299, 310, 324, 330, 331, 341, 346, 386, 402, 460, 472, 479], 5: [1, 21, 33, 50, 62, 76, 120, 162, 172, 192, 291, 338, 352, 412, 427, 439, 483], 47: [1, 11, 15, 29, 38, 45, 51, 62, 68, 75, 77, 82, 91, 129, 155, 184, 195, 223, 230, 259, 301, 316, 434, 435, 474, 489, 498], 57: [1, 20, 21, 28, 42, 62, 75, 83, 96, 108, 117, 122, 133, 151, 165, 177, 181, 306, 324, 342, 353, 362, 382, 389, 393, 436, 439, 441, 442, 450, 491], 68: [2, 6, 19, 24, 30, 31, 58, 62, 87, 88, 113, 115, 121, 124, 157, 170, 206, 216, 268, 274, 294, 306, 309, 314, 322, 323, 345, 366, 396, 403, 419, 428, 452, 478], 59: [2, 6, 7, 9, 21, 48, 53, 54, 58, 67, 72, 75, 77, 106, 130, 160, 209, 241, 259, 263, 266, 273, 274, 349, 352, 384, 412, 413, 417, 445, 477, 485], 63: [2, 7, 12, 39, 62, 63, 64, 80, 87, 93, 101, 105, 106, 114, 130, 139, 146, 153, 155, 199, 216, 222, 237, 240, 242, 244, 258, 262, 310, 334, 385, 395, 404, 434, 436, 464], 94: [3, 6, 19, 23, 24, 36, 39, 57, 70, 120, 136, 158, 249, 275, 298, 328, 338, 401, 425, 435, 468, 472, 473, 488, 493], 49: [3, 6, 32, 43, 45, 51, 60, 63, 64, 65, 87, 91, 109, 110, 111, 129, 131, 139, 164, 197, 199, 200, 203, 210, 216, 329, 335, 343, 351, 382, 403, 448, 451, 474, 486, 498], 33: [4, 6, 8, 18, 21, 32, 46, 49, 61, 71, 76, 77, 81, 87, 91, 93, 103, 119, 123, 135, 168, 182, 184, 228, 260, 265, 269, 333, 372, 381, 393, 415, 421, 430, 448, 454, 456, 465, 487, 499], 0: [4, 24, 29, 87, 153, 196, 278, 318, 363, 461], 92: [4, 21, 23, 31, 43, 106, 117, 125, 142, 155, 160, 212, 312, 350, 355, 378, 394, 400, 422, 435, 442, 446, 466, 473, 486], 38: [5, 6, 31, 37, 44, 57, 123, 131, 138, 155, 175, 225, 276, 285, 297, 345, 399, 418, 451, 453], 54: [5, 6, 21, 37, 43, 54, 78, 187, 197, 233, 244, 245, 313], 78: [5, 6, 24, 25, 26, 29, 33, 41, 52, 72, 98, 100, 118, 124, 134, 146, 153, 160, 166, 174, 213, 251, 253, 275, 289, 319, 333, 341, 344, 365, 391, 411, 458, 491], 14: [6, 10, 13, 23, 48, 51, 59, 63, 66, 75, 95, 102, 115, 116, 120, 139, 146, 153, 157, 192, 219, 246, 263, 287, 292, 308, 321, 356, 423, 444, 452, 479, 480], 66: [6, 21, 46, 62, 85, 119, 163, 214, 217, 234, 355, 389, 416, 424, 468], 86: [6, 41, 44, 94, 135, 221, 383, 425, 485], 29: [6, 75, 80, 105, 110, 122, 126, 127, 149, 225, 312, 319, 320, 329, 358, 458], 61: [6, 19, 30, 50, 89, 121, 145, 147, 152, 153, 173, 186, 220, 235, 269, 277, 332, 349, 354, 377, 396, 415, 417, 429, 432, 433, 492], 40: [6, 10, 15, 19, 20, 39, 41, 56, 70, 87, 91, 102, 127, 140, 143, 153, 157, 170, 178, 181, 198, 231, 236, 247, 261, 285, 289, 295, 303, 313, 315, 332, 336, 348, 374, 395, 408, 457, 493], 65: [6, 133, 156, 173, 377, 455], 53: [6, 20, 198, 257, 466], 60: [6, 8, 18, 21, 28, 47, 53, 63, 70, 82, 87, 92, 125, 170, 185, 212, 217, 265, 307, 378, 381, 452], 69: [6, 24, 61, 63, 70, 75, 78, 96, 102, 110, 135, 144, 165, 170, 178, 204, 208, 231, 232, 239, 257, 290, 291, 296, 437, 457, 482, 484, 488, 496], 22: [7, 15, 73, 76, 83, 112, 156, 161, 179, 198, 200, 201, 229, 245, 255, 278, 380, 404, 413, 431], 39: [8, 38, 47, 54, 58, 75, 78, 101, 109, 122, 126, 153, 154, 176, 188, 195, 201, 219, 223, 258, 264, 270, 289, 298, 315, 330, 349, 357, 362, 364, 418, 432, 469, 492, 499], 58: [9, 16, 29, 66, 75, 86, 124, 134, 139, 151, 169, 190, 197, 254, 284, 295, 302, 326, 346, 383, 440, 450, 470, 493, 496, 497], 16: [9, 17, 19, 26, 48, 58, 61, 70, 84, 87, 142, 145, 163, 192, 211, 214, 261, 315, 319, 340, 367, 405, 430, 445, 462, 469], 2: [9, 23, 38, 69, 93, 151, 193, 367], 97: [10, 43, 155, 339, 441, 471], 77: [11, 13, 16, 21, 31, 69, 96, 119, 152, 153, 162, 253, 298, 300, 307, 314, 317, 357, 455, 461], 26: [11, 24, 29, 34, 54, 57, 76, 83, 86, 87, 91, 104, 120, 133, 158, 170, 226, 242, 260, 263, 265, 272, 294, 300, 325, 391, 414, 420, 438, 456], 36: [12, 39, 58, 103, 104, 118, 119, 143, 179, 222, 264, 314, 380, 439], 44: [13, 32, 98, 116, 139, 223, 478], 74: [13, 15, 23, 24, 47, 51, 54, 60, 62, 90, 99, 113, 124, 146, 150, 153, 159, 170, 230, 246, 268, 278, 279, 283, 287, 322, 337, 370, 373, 385, 401, 409, 454, 456, 483], 62: [13, 21, 27, 37, 103, 196, 233, 251, 430, 475], 6: [13, 21, 24, 39, 40, 44, 45, 55, 56, 68, 75, 106, 117, 124, 126, 139, 150, 153, 171, 187, 199, 206, 210, 227, 235, 269, 311, 336, 354, 360, 371, 375, 394, 411, 414, 425, 429, 432, 465], 13: [14, 21, 47, 48, 95, 118, 120, 170, 172, 185, 437, 495], 32: [14, 21, 23, 24, 35, 39, 55, 75, 99, 102, 113, 116, 128, 154, 165, 183, 202, 214, 232, 249, 255, 266, 272, 284, 288, 290, 299, 357, 387, 392, 400, 410, 412, 415, 460, 464, 497], 41: [14, 56, 70, 81, 93, 112, 139, 145, 252, 311, 316, 343, 359, 471, 482], 85: [16, 28, 47, 85, 149, 168, 189, 255, 276, 277, 283, 285, 286, 293, 318, 406, 424, 443, 455], 95: [16, 17, 18, 37, 81, 82, 106, 136, 138, 144, 161, 170, 180, 182, 190, 207, 213, 248, 273, 279, 296, 310, 318, 327, 353, 355, 370, 382, 387, 401, 448, 481, 490], 72: [17, 35, 68, 71, 78, 86, 102, 115, 139, 141, 161, 200, 243, 256, 282, 295, 305, 373, 383, 386, 405, 437, 453, 466, 470, 489, 492], 91: [19, 23, 70, 77, 140, 163, 235, 239, 259, 272, 356, 368, 375, 460], 45: [19, 27, 65, 70, 77, 134, 136, 152, 205, 221, 280, 296, 302, 326, 336, 339, 361, 374, 423, 486], 15: [19, 22, 24, 39, 42, 45, 87, 98, 114, 155, 168, 202, 211, 241, 341, 365, 427, 473, 498], 90: [19, 47, 75, 82, 106, 107, 118, 119, 121, 123, 127, 130, 170, 189, 191, 258, 273, 274, 280, 282, 290, 309, 334, 344, 348, 379, 394, 417], 67: [19, 25, 29, 70, 74, 76, 91, 132, 133, 170, 175, 183, 194, 244, 261, 335, 345, 360, 442, 446], 31: [19, 52], 75: [19, 21, 24, 47, 62, 75, 76, 131, 144, 169, 174, 193, 203, 213, 222, 224, 247, 293, 350, 384, 388, 397, 406, 413, 443], 56: [21, 79, 118, 139, 150, 153, 174, 180, 207, 323, 340, 366, 421, 446], 37: [21, 25, 31, 49, 58, 62, 74, 82, 106, 124, 125, 127, 136, 152, 170, 183, 186, 191, 204, 218, 257, 262, 292, 307, 358, 376, 379, 389, 397, 431, 463, 467, 479, 480, 481], 17: [21, 24, 32, 39, 55, 67, 95, 113, 184, 217, 234, 236, 303, 306, 329, 387, 459, 491, 497], 64: [22, 25, 28, 42, 44, 46, 49, 51, 75, 79, 113, 116, 118, 123, 139, 208, 313, 334, 351, 354, 392, 398, 423, 449, 475, 482], 83: [23, 24, 40, 60, 90, 102, 152, 154, 205, 231, 264, 305, 308, 311, 369, 418], 71: [23], 18: [23, 47, 51, 247, 304, 337, 481], 48: [23, 124, 139, 474], 4: [24, 29, 63, 83, 94, 111, 132, 158, 165, 167, 173, 221, 229, 242, 245, 305, 331, 332, 342, 344, 347, 365, 370, 381, 408, 422, 426, 441, 458], 8: [24, 29, 35, 70, 75, 98, 100, 112, 125, 139, 141, 158, 163, 165, 168, 233, 243, 266, 283, 347, 378, 409, 424, 470], 21: [24, 25, 43, 67, 102, 139, 166, 205, 281, 327], 30: [24, 139, 167, 179, 276, 411, 416], 84: [24, 161, 219, 270, 392], 27: [25, 73, 97, 107, 148, 153, 220, 271, 375, 445], 24: [25, 75, 152, 379, 476], 98: [26, 58, 75, 80, 240, 286, 364, 386], 9: [27, 31, 65, 68, 73, 87, 94, 120, 124, 127, 132, 134, 162, 167, 168, 232, 243, 262, 309, 321, 359, 369, 494, 499], 99: [30, 89, 130, 153, 187, 209, 250, 281, 400, 416, 462], 1: [31, 152, 252, 467, 484], 93: [31, 99, 133, 212, 342, 489], 28: [33, 37, 53, 62, 66, 70, 75, 80, 84, 96, 111, 120, 124, 131, 137, 143, 146, 148, 153, 168, 171, 190, 210, 230, 284, 299, 322, 333, 335, 347, 360, 366, 372, 397, 405, 434, 436, 444, 451, 477], 23: [34, 47, 51, 75, 87, 140, 146, 149, 170, 225, 249, 252, 254, 277, 280, 312, 316, 321, 340, 352, 358, 361, 362, 371, 372, 388, 402, 406, 408, 410, 428, 438, 453, 457, 462, 487], 10: [36, 71, 282, 288, 343, 363, 490], 73: [36, 130, 158, 194, 238, 323, 348, 402, 449, 463], 43: [44, 95, 129, 141, 153, 154, 158, 240, 396, 407, 422, 429, 447, 476], 42: [46, 70, 74, 81, 114, 137, 171, 193, 373], 96: [47, 133, 224, 328, 472], 87: [48, 92, 165, 228, 304, 475], 76: [51, 153, 188, 237, 256, 346, 388, 420], 55: [58, 92, 142, 156, 211, 301, 317, 361, 398, 444, 454], 51: [59, 65, 70, 75, 91, 92, 101, 147, 189, 218, 253, 271, 300, 391, 426, 471, 478, 485, 487], 46: [70, 104, 135, 139, 164, 185, 188, 208, 302, 351, 364, 368, 384, 447, 469], 50: [76, 89, 106, 122, 136, 139, 420, 450, 463], 19: [79, 85, 153, 182, 209, 238, 254, 281], 34: [82, 172, 224, 339], 70: [90, 97, 191, 251, 480], 11: [127, 138, 153, 159, 169, 196, 248, 320, 380, 443], 3: [177, 226, 426, 440, 449], 80: [218, 301], 35: [287, 292, 328], 81: [483]}\n",
            "Acceptance Threshold Sequence:  {0: 0.287265505624195, 1: 0.2814129830306698, 2: 0.12875804411374506, 3: 0.23473353137793282, 4: 0.2329645024703632, 5: 0.376707340803796, 6: 0.30024947845452105, 7: 0.016436844119398553, 8: 0.2499320202249939, 9: 0.1524661216612578, 10: 0.22318875971531515, 11: 0.11852214403318631, 12: 0.21511668458469235, 13: 0.26360528236322317, 14: 0.09443040639979955, 15: 0.18815467153019413, 16: 0.1252725352924201, 17: 0.2811888525854468, 18: 0.10408913651023471, 19: 0.20528759820551692, 20: 0.07495829269027712, 21: 0.26501646852150773, 22: 0.2979169762404682, 23: 0.36910445947567017, 24: 0.2822576709652481, 25: 0.05776783927931875, 26: 0.3050638695417362, 27: 0.27809199806847135, 28: 0.19405708478759987, 29: 0.0793685430436537, 30: 0.06799123501163981, 31: 0.046454240559277216, 32: 0.21833475389404788, 33: 0.31740184368933677, 34: 0.38473188512680223, 35: 0.23283166610801, 36: 0.28859827860270526, 37: 0.08694794998450842, 38: 0.24370021069347705, 39: 0.22659867763293018, 40: 0.3489562569192496, 41: 0.36112769890332025, 42: 0.007492645402825404, 43: 0.17123799147268112, 44: 0.1992536136290317, 45: 0.2730007121686185, 46: 0.28793714746367244, 47: 0.2075769917368628, 48: 0.20516588141423905, 49: 0.24597739267367905, 50: 0.14662551261101844, 51: 0.09232630802907907, 52: 0.19609429429095845, 53: 0.13506969300519167, 54: 0.22355714232445212, 55: 0.30384511601451525, 56: 0.28254586940614623, 57: 0.10424914104282135, 58: 0.3121882710157932, 59: 0.21356064147750808, 60: 0.20806058270613467, 61: 0.28335885489972645, 62: 0.20986942143872767, 63: 0.014147403786743118, 64: 0.35218279824817195, 65: 0.02622018472579868, 66: 0.2717425748458696, 67: 0.17354394786364755, 68: 0.21893157171635547, 69: 0.12832609731995048, 70: 0.233823805838825, 71: 0.13566876149649926, 72: 0.14270073313369674, 73: 0.24864177646571048, 74: 0.15343184369393728, 75: 0.36341451838127725, 76: 0.2604046363240924, 77: 0.31565541350767473, 78: 0.12605535344440677, 79: 0.19374049168831162, 80: 0.17623028110013836, 81: 0.3340016788437469, 82: 0.17480661279325352, 83: 0.2730072669548874, 84: 0.04100521145666955, 85: 0.2568483144125595, 86: 0.16996149106364106, 87: 0.0650430663363386, 88: 0.0600977909004721, 89: 0.045085599096443996, 90: 0.15860506806037378, 91: 0.20141572811642802, 92: 0.06075544150569798, 93: 0.2284212674998627, 94: 0.4199856378985477, 95: 0.21260023762378966, 96: 0.09277638520270709, 97: 0.2572393934051985, 98: 0.14223970712854775, 99: 0.24763054174852603, 100: 0.09192570112831062, 101: 0.31898441433652847, 102: 0.1207754099180471, 103: 0.14659041348295415, 104: 0.07618330094651043, 105: 0.19636113744889402, 106: 0.24339158862598398, 107: 0.3377155787464129, 108: 0.3800487330395953, 109: 0.25081918271837056, 110: 0.06980603625877033, 111: 0.25768911120043253, 112: 0.2689749664406211, 113: 0.07890393834137832, 114: 0.29925804501524195, 115: 0.07090725743438095, 116: 0.07363669068959994, 117: 0.1038574974838544, 118: 0.26822360951778934, 119: 0.2590053289557842, 120: 0.1561661568063189, 121: 0.1915588582634384, 122: 0.11392784681313663, 123: 0.19953847910996286, 124: 0.2821669939791854, 125: 0.17187932799194733, 126: 0.17587262426717404, 127: 0.3297129170338184, 128: 0.40192010713135823, 129: 0.2583944874233869, 130: 0.2633744548577701, 131: 0.2426192190228347, 132: 0.3318167132439397, 133: 0.3253207896816474, 134: 0.09973317829491385, 135: 0.3748708022872707, 136: 0.09682347191041028, 137: 0.3737654249703166, 138: 0.38820002481436783, 139: 0.14219489298734472, 140: 0.13291839767053043, 141: 0.22168220664287092, 142: 0.19554187007902119, 143: 0.22047923997164656, 144: 0.2848093659921009, 145: 0.15040811671343252, 146: 0.3971984849934998, 147: 0.23624649732011269, 148: 0.3840403329625873, 149: 0.028013540917392277, 150: 0.45826303405074964, 151: 0.07227673996363462, 152: 0.18173433092424074, 153: 0.24470378090787517, 154: 0.156144766127403, 155: 0.20211020418868772, 156: 0.18629816566365381, 157: 0.25202755548653616, 158: 0.2551060647730156, 159: 0.45456902419185774, 160: 0.3160031590587876, 161: 0.23043166832104398, 162: 0.26735385360274005, 163: 0.1868137410640907, 164: 0.3130974238867167, 165: 0.24333652230150138, 166: 0.3063255099578979, 167: 0.2187641876798166, 168: 0.19895919366454468, 169: 0.2167466777690044, 170: 0.23038663645833557, 171: 0.14680399465223934, 172: 0.2727286562714352, 173: 0.1385282835772483, 174: 0.18385587885250154, 175: 0.18069223531278472, 176: 0.28306360949180687, 177: 0.16971525863884582, 178: 0.017826990637490686, 179: 0.2724306738967503, 180: 0.2495474289846996, 181: 0.09643469641699101, 182: 0.2585313295054997, 183: 0.1912613516204949, 184: 0.3256907146637166, 185: 0.1454400583632388, 186: 0.02048940252222406, 187: 0.23156843964243304, 188: 0.32340823505293353, 189: 0.14871231013713143, 190: 0.08227513820923538, 191: 0.20801426694837544, 192: 0.11979379670473604, 193: 0.20660339484134954, 194: 0.2074431774515563, 195: 0.24633212961729392, 196: 0.2645008767126322, 197: 0.19220884511823455, 198: 0.12799891829698629, 199: 0.09238653940320432, 200: 0.1970980894136329, 201: 0.2768073330059386, 202: 0.041477408053891274, 203: 0.1894233368764814, 204: 0.11502764483981061, 205: 0.05781358035199577, 206: 0.052065068514293905, 207: 0.2436105270809281, 208: 0.19118964576339362, 209: 0.1561401987400677, 210: 0.14414705995022667, 211: 0.33967860847458897, 212: 0.2960452946169857, 213: 0.2910239911266284, 214: 0.26200700918491004, 215: 0.12618589922223183, 216: 0.13367153625538647, 217: 0.22819167835646142, 218: 0.2229102237516951, 219: 0.2525789361966161, 220: 0.19713376181953834, 221: 0.1402731128115272, 222: 0.21305413333767545, 223: 0.25402234569965654, 224: 0.10345329295765682, 225: 0.3267296862582241, 226: 0.002657158110284663, 227: 0.20302883105723624, 228: 0.15777492012774802, 229: 0.34605342573105374, 230: 0.14662975420943794, 231: 0.17287736963755151, 232: 0.30581166294220163, 233: 0.2407290371256719, 234: 0.27971312065773146, 235: 0.34138567035526707, 236: 0.29473744808747515, 237: 0.29802963739233107, 238: 0.2880476655269605, 239: 0.05879217386440133, 240: 0.30765196863560107, 241: 0.09332319117534127, 242: 0.28967154807335405, 243: 0.1927210978975002, 244: 0.35313136893338287, 245: 0.14872871708964366, 246: 0.27262663557451683, 247: 0.25176562939619296, 248: 0.05743645501139574, 249: 0.005874170435144849, 250: 0.09671625153976914, 251: 0.3008565568584653, 252: 0.15500099019372515, 253: 0.31900630765990606, 254: 0.09360315191438706, 255: 0.06061149879634406, 256: 0.29869961211813845, 257: 0.26292485157343093, 258: 0.11018213858557199, 259: 0.23556014719859278, 260: 0.248752450302008, 261: 0.20747622387122658, 262: 0.2429901309280112, 263: 0.16082683137203713, 264: 0.3570727825379275, 265: 0.09001994796620519, 266: 0.33865123077258275, 267: 0.14240603060975898, 268: 0.23486954365092122, 269: 0.04918352832705822, 270: 0.0875807915395359, 271: 0.2793564801620074, 272: 0.04962450789198461, 273: 0.3776737379690104, 274: 0.09027789181447406, 275: 0.2664370291106773, 276: 0.3027503036852973, 277: 0.12260395342057029, 278: 0.1397164846722475, 279: 0.25825611347751126, 280: 0.28501758496595814, 281: 0.19215261334297318, 282: 0.22845530699362904, 283: 0.13813233693378207, 284: 0.2023693998732297, 285: 0.20226365974403668, 286: 0.1428038847910682, 287: 0.3134324123679758, 288: 0.1732185482575594, 289: 0.3483629687512136, 290: 0.4671366900378357, 291: 0.2586589852345971, 292: 0.2047207026408871, 293: 0.13729456135117407, 294: 0.040911441276037463, 295: 0.16231822159222065, 296: 0.05407131378259375, 297: 0.27920457722535075, 298: 0.16076229786959545, 299: 0.2543981726110971, 300: 0.2604030217083971, 301: 0.09706403101785022, 302: 0.19601832384692583, 303: 0.3218773528576534, 304: 0.08014771825373733, 305: 0.39399504388974893, 306: 0.2338586072425628, 307: 0.02961916962440317, 308: 0.050700420042718436, 309: 0.21093938469579254, 310: 0.22802101126039948, 311: 0.2964546990606167, 312: 0.1755001298836862, 313: 0.18793191846856544, 314: 0.18393638931833403, 315: 0.10130060454907186, 316: 0.09202402294761168, 317: 0.19859325362358204, 318: 0.14870552359296324, 319: 0.24735141419567305, 320: 0.2587406434026229, 321: 0.2355318791423536, 322: 0.22851865594581994, 323: 0.27182363384627173, 324: 0.29557620252535094, 325: 0.3536426970521669, 326: 0.27410644150458957, 327: 0.18768039413641383, 328: 0.09423493078459062, 329: 0.061640861799015345, 330: 0.47336019376088423, 331: 0.10896627423200327, 332: 0.043483474179349835, 333: 0.27664217526151663, 334: 0.20131781581985025, 335: 0.18556362704934037, 336: 0.163658624619857, 337: 0.14237364386810356, 338: 0.31875965093497843, 339: 0.18285388997161126, 340: 0.27041227254823463, 341: 0.020132560723076898, 342: 0.3058242457692036, 343: 0.16814438809171312, 344: 0.1284994092922111, 345: 0.19595371988027704, 346: 0.20823278203868092, 347: 0.2955991357496221, 348: 0.3207597021787208, 349: 0.12890018941631592, 350: 0.12912248274491037, 351: 0.1895459293152328, 352: 0.19899945145321798, 353: 0.15999187432161077, 354: 0.4092716203634634, 355: 0.15223749800721548, 356: 0.20168228958594686, 357: 0.035106505498597784, 358: 0.312350735216845, 359: 0.22093109510118916, 360: 0.20170397471355725, 361: 0.24213854193693457, 362: 0.250841679867869, 363: 0.3023917402684013, 364: 0.14453078024388036, 365: 0.36151102323814915, 366: 0.272941178002557, 367: 0.29389301588484995, 368: 0.19317621289652512, 369: 0.19200463125294642, 370: 0.05085259018737223, 371: 0.1986249952592802, 372: 0.037577387955681274, 373: 0.1237083136014381, 374: 0.3665091333432159, 375: 0.24317385231844152, 376: 0.30367710303746726, 377: 0.13047282045846903, 378: 0.2260177402088947, 379: 0.19343088740904157, 380: 0.33410934204610687, 381: 0.19456086871762504, 382: 0.2633861974462982, 383: 0.2615415485673991, 384: 0.3113939324911936, 385: 0.14569139157201064, 386: 0.13996835609832023, 387: 0.1307314103019672, 388: 0.05181595999250602, 389: 0.2538283587496952, 390: 0.08178330303570797, 391: 0.1652910675341267, 392: 0.13432495093380292, 393: 0.22938459116422827, 394: 0.27056557720103414, 395: 0.3223413762028179, 396: 0.061200877920872726, 397: 0.06817069980040513, 398: 0.27417378873664133, 399: 0.13850472873683542, 400: 0.2650852175148168, 401: 0.0505908580138093, 402: 0.13542148353530598, 403: 0.17069680100255413, 404: 0.3170888798441684, 405: 0.18997943312330834, 406: 0.4295198175114756, 407: 0.16139101965204916, 408: 0.27055409792177404, 409: 0.1473239447023481, 410: 0.06868288792324814, 411: 0.05719700488570656, 412: 0.2286177556135073, 413: 0.23616709070956882, 414: 0.2507287750215639, 415: 0.12605550432688756, 416: 0.2784917912666951, 417: 0.10132906568198857, 418: 0.27563145976286296, 419: 0.0778505797248828, 420: 0.17793175688229013, 421: 0.17100619991599175, 422: 0.44336674580788915, 423: 0.322494404658761, 424: 0.19323677268267697, 425: 0.052910118007165385, 426: 0.3272254518504759, 427: 0.2912316110889643, 428: 0.3748506017550888, 429: 0.02250822576913597, 430: 0.1302008580045679, 431: 0.2491590961909888, 432: 0.25319102232969026, 433: 0.003479290842681948, 434: 0.050453805153382575, 435: 0.13110181153344813, 436: 0.28260342270861627, 437: 0.2839553896061065, 438: 0.1670739471246121, 439: 0.13363767105214153, 440: 0.06595829268658143, 441: 0.14841832933701027, 442: 0.2515293113993179, 443: 0.10404930400745706, 444: 0.01548103918302332, 445: 0.282623030368851, 446: 0.31227612509491437, 447: 0.25808567638191215, 448: 0.11281659571221292, 449: 0.26506645390617606, 450: 0.18947353246205834, 451: 0.1810978927855952, 452: 0.24624207461799474, 453: 0.3420347523054874, 454: 0.09987111255602532, 455: 0.19472586338815295, 456: 0.2386474239463984, 457: 0.17706822966983818, 458: 0.23504191670203006, 459: 0.09021981051538148, 460: 0.2579120821789428, 461: 0.26419278559558634, 462: 0.10851418436661787, 463: 0.1442071680458279, 464: 0.2820972583819811, 465: 0.37280719702680254, 466: 0.33375429850046356, 467: 0.27703680864419583, 468: 0.020218615537617307, 469: 0.29920870955377066, 470: 0.23189145224873114, 471: 0.1432277036409365, 472: 0.22025915181937433, 473: 0.279852885384693, 474: 0.1820594527346234, 475: 0.16106128155140148, 476: 0.30820837890685193, 477: 0.3209168348461201, 478: 0.2362320073651274, 479: 0.14727954345838548, 480: 0.24454133455568636, 481: 0.2066592042438203, 482: 0.20761518506571588, 483: 0.23445181151822397, 484: 0.18128257073993498, 485: 0.1885978672421839, 486: 0.2423250589303092, 487: 0.28039001323017954, 488: 0.14165354197411245, 489: 0.025024520857406807, 490: 0.16836950488001523, 491: 0.4003930357296293, 492: 0.21667273953667004, 493: 0.2377745366088654, 494: 0.07817762192257037, 495: 0.031215154036934256, 496: 0.2622711368280814, 497: 0.12970252271563004, 498: 0.10649005160654679, 499: 0.18093314675852784}\n",
            "Behavior Degree Sequence:  [7, 3, 9, 3, 4, 3, 12, 3, 3, 3, 3, 3, 3, 3, 5, 4, 3, 3, 3, 3, 3, 12, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 15, 7, 5, 7, 4, 8, 3, 7, 3, 3, 4, 3, 4, 21, 3, 3, 3, 3, 3, 4, 3, 4, 3, 3, 6, 3, 6, 3, 3, 17, 3, 3, 3, 3, 4, 3, 3, 8, 3, 3, 3, 4, 3, 4, 4, 3, 5, 8, 3, 3, 3, 3, 3, 13, 7, 3, 5, 3, 9, 3, 3, 3, 3, 9, 3, 4, 4, 8, 4, 3, 3, 3, 3, 7, 3, 5, 3, 4, 3, 3, 4, 5, 5, 8, 3, 6, 3, 3, 3, 3, 3, 6, 5, 3, 5, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
            "{0: 'N', 1: 'N', 2: 'N', 3: 'N', 4: 'P', 5: 'P', 6: 'N', 7: 'P', 8: 'N', 9: 'N', 10: 'N', 11: 'P', 12: 'N', 13: 'P', 14: 'N', 15: 'N', 16: 'N', 17: 'P', 18: 'N', 19: 'N', 20: 'N', 21: 'N', 22: 'N', 23: 'P', 24: 'N', 25: 'N', 26: 'N', 27: 'N', 28: 'N', 29: 'N', 30: 'N', 31: 'P', 32: 'P', 33: 'N', 34: 'P', 35: 'P', 36: 'N', 37: 'N', 38: 'P', 39: 'P', 40: 'P', 41: 'N', 42: 'N', 43: 'N', 44: 'N', 45: 'N', 46: 'N', 47: 'N', 48: 'P', 49: 'P', 50: 'N', 51: 'N', 52: 'P', 53: 'N', 54: 'N', 55: 'P', 56: 'P', 57: 'P', 58: 'P', 59: 'N', 60: 'N', 61: 'N', 62: 'N', 63: 'P', 64: 'N', 65: 'N', 66: 'N', 67: 'P', 68: 'P', 69: 'N', 70: 'N', 71: 'P', 72: 'N', 73: 'N', 74: 'N', 75: 'N', 76: 'N', 77: 'P', 78: 'P', 79: 'N', 80: 'N', 81: 'P', 82: 'N', 83: 'N', 84: 'N', 85: 'N', 86: 'N', 87: 'N', 88: 'N', 89: 'P', 90: 'P', 91: 'N', 92: 'N', 93: 'P', 94: 'N', 95: 'N', 96: 'N', 97: 'P', 98: 'N', 99: 'N', 100: 'N', 101: 'N', 102: 'P', 103: 'N', 104: 'N', 105: 'N', 106: 'N', 107: 'N', 108: 'N', 109: 'P', 110: 'P', 111: 'N', 112: 'N', 113: 'P', 114: 'P', 115: 'N', 116: 'N', 117: 'N', 118: 'P', 119: 'N', 120: 'N', 121: 'N', 122: 'N', 123: 'N', 124: 'P', 125: 'N', 126: 'N', 127: 'N', 128: 'P', 129: 'P', 130: 'P', 131: 'P', 132: 'P', 133: 'N', 134: 'N', 135: 'N', 136: 'P', 137: 'N', 138: 'N', 139: 'P', 140: 'P', 141: 'P', 142: 'N', 143: 'N', 144: 'N', 145: 'N', 146: 'N', 147: 'P', 148: 'P', 149: 'N', 150: 'P', 151: 'P', 152: 'P', 153: 'N', 154: 'N', 155: 'P', 156: 'N', 157: 'P', 158: 'N', 159: 'N', 160: 'N', 161: 'N', 162: 'N', 163: 'N', 164: 'N', 165: 'N', 166: 'N', 167: 'N', 168: 'N', 169: 'N', 170: 'P', 171: 'N', 172: 'N', 173: 'N', 174: 'P', 175: 'P', 176: 'N', 177: 'P', 178: 'N', 179: 'P', 180: 'N', 181: 'N', 182: 'P', 183: 'P', 184: 'N', 185: 'N', 186: 'N', 187: 'N', 188: 'N', 189: 'N', 190: 'P', 191: 'N', 192: 'N', 193: 'N', 194: 'P', 195: 'N', 196: 'P', 197: 'P', 198: 'N', 199: 'N', 200: 'P', 201: 'N', 202: 'P', 203: 'N', 204: 'N', 205: 'N', 206: 'N', 207: 'N', 208: 'N', 209: 'N', 210: 'N', 211: 'N', 212: 'N', 213: 'N', 214: 'N', 215: 'N', 216: 'N', 217: 'P', 218: 'N', 219: 'N', 220: 'N', 221: 'N', 222: 'N', 223: 'N', 224: 'N', 225: 'N', 226: 'P', 227: 'N', 228: 'N', 229: 'N', 230: 'N', 231: 'N', 232: 'N', 233: 'N', 234: 'P', 235: 'P', 236: 'N', 237: 'N', 238: 'N', 239: 'N', 240: 'N', 241: 'P', 242: 'N', 243: 'N', 244: 'N', 245: 'P', 246: 'N', 247: 'N', 248: 'N', 249: 'N', 250: 'P', 251: 'P', 252: 'P', 253: 'N', 254: 'P', 255: 'P', 256: 'N', 257: 'N', 258: 'P', 259: 'P', 260: 'N', 261: 'N', 262: 'N', 263: 'P', 264: 'P', 265: 'N', 266: 'P', 267: 'N', 268: 'N', 269: 'N', 270: 'P', 271: 'N', 272: 'P', 273: 'P', 274: 'P', 275: 'P', 276: 'N', 277: 'N', 278: 'N', 279: 'P', 280: 'P', 281: 'N', 282: 'N', 283: 'N', 284: 'N', 285: 'N', 286: 'N', 287: 'N', 288: 'N', 289: 'N', 290: 'N', 291: 'N', 292: 'N', 293: 'P', 294: 'N', 295: 'P', 296: 'P', 297: 'N', 298: 'N', 299: 'P', 300: 'N', 301: 'N', 302: 'N', 303: 'N', 304: 'P', 305: 'N', 306: 'N', 307: 'P', 308: 'N', 309: 'N', 310: 'N', 311: 'N', 312: 'N', 313: 'N', 314: 'N', 315: 'N', 316: 'N', 317: 'N', 318: 'P', 319: 'N', 320: 'N', 321: 'P', 322: 'N', 323: 'N', 324: 'N', 325: 'N', 326: 'N', 327: 'N', 328: 'P', 329: 'P', 330: 'P', 331: 'N', 332: 'N', 333: 'N', 334: 'P', 335: 'P', 336: 'N', 337: 'N', 338: 'N', 339: 'N', 340: 'P', 341: 'N', 342: 'N', 343: 'N', 344: 'P', 345: 'N', 346: 'N', 347: 'N', 348: 'P', 349: 'N', 350: 'P', 351: 'N', 352: 'N', 353: 'P', 354: 'N', 355: 'N', 356: 'N', 357: 'N', 358: 'P', 359: 'P', 360: 'P', 361: 'P', 362: 'N', 363: 'P', 364: 'P', 365: 'N', 366: 'N', 367: 'N', 368: 'P', 369: 'P', 370: 'N', 371: 'N', 372: 'N', 373: 'N', 374: 'P', 375: 'P', 376: 'N', 377: 'N', 378: 'N', 379: 'N', 380: 'N', 381: 'P', 382: 'N', 383: 'N', 384: 'N', 385: 'N', 386: 'N', 387: 'P', 388: 'N', 389: 'N', 390: 'P', 391: 'N', 392: 'N', 393: 'N', 394: 'P', 395: 'N', 396: 'P', 397: 'N', 398: 'N', 399: 'N', 400: 'N', 401: 'P', 402: 'P', 403: 'N', 404: 'P', 405: 'N', 406: 'N', 407: 'N', 408: 'N', 409: 'N', 410: 'N', 411: 'N', 412: 'N', 413: 'N', 414: 'N', 415: 'N', 416: 'N', 417: 'N', 418: 'N', 419: 'N', 420: 'N', 421: 'P', 422: 'N', 423: 'P', 424: 'N', 425: 'P', 426: 'N', 427: 'P', 428: 'P', 429: 'N', 430: 'N', 431: 'N', 432: 'N', 433: 'N', 434: 'N', 435: 'N', 436: 'N', 437: 'P', 438: 'N', 439: 'P', 440: 'N', 441: 'N', 442: 'P', 443: 'N', 444: 'N', 445: 'N', 446: 'P', 447: 'N', 448: 'P', 449: 'P', 450: 'P', 451: 'N', 452: 'N', 453: 'N', 454: 'N', 455: 'N', 456: 'N', 457: 'N', 458: 'N', 459: 'P', 460: 'N', 461: 'N', 462: 'N', 463: 'P', 464: 'N', 465: 'P', 466: 'N', 467: 'N', 468: 'N', 469: 'P', 470: 'N', 471: 'N', 472: 'N', 473: 'N', 474: 'P', 475: 'N', 476: 'P', 477: 'N', 478: 'P', 479: 'N', 480: 'N', 481: 'N', 482: 'P', 483: 'N', 484: 'N', 485: 'N', 486: 'N', 487: 'N', 488: 'P', 489: 'N', 490: 'N', 491: 'N', 492: 'N', 493: 'N', 494: 'N', 495: 'P', 496: 'N', 497: 'N', 498: 'N', 499: 'P'}\n",
            "Degree Sequence:  [3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 5, 4, 3, 15, 3, 3, 6, 3, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 5, 4, 4, 3, 3, 6, 5, 3, 3, 3, 3, 3, 3, 3, 8, 3, 3, 3, 3, 3, 3, 3, 3, 3, 9, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  return np.find_common_type(types, [])\n"
          ]
        }
      ],
      "source": [
        "n = 500  # Number of nodes\n",
        "\n",
        "# Information Layer\n",
        "gamma_i = 2.5  # Power-law exponent\n",
        "kmin_i = 3  # Minimum degree\n",
        "num_hyper_edges_i = 100  # Desired number of hyper edges\n",
        "ldeg_i, hyperedge_dict_i = build_hypergraph(n, gamma_i, kmin_i, num_hyper_edges_i)\n",
        "inw = hnx.Hypergraph(hyperedge_dict_i)\n",
        "ltre = assign_thresholds(inw, 0.2, 0.1)\n",
        "print(\"Acceptance Threshold Sequence: \", ltre)\n",
        "\n",
        "# Cognition Layer\n",
        "gamma_c = 3.0  # Power-law exponent\n",
        "kmin_c = 3  # Minimum degree\n",
        "ldeg_c = generate_degree_sequence(n, gamma_c, kmin_c)\n",
        "print(\"Behavior Degree Sequence: \", ldeg_c)\n",
        "cnw = nx.configuration_model(ldeg_c)\n",
        "frac_prot = 0.3\n",
        "lprot = assign_protection(cnw, frac_prot)\n",
        "\n",
        "# Epidemic Layer\n",
        "gamma_e = 4.0\n",
        "kmin_e = 3\n",
        "ldeg_e = generate_degree_sequence(n, gamma_e, kmin_e)\n",
        "print(\"Degree Sequence: \", ldeg_e)\n",
        "enw = nx.configuration_model(ldeg_e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfhtiV0xOHEK",
        "outputId": "fc6f3935-9917-4617-dee6-f6bfd7f1769b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pexpect/popen_spawn.py:60: DeprecationWarning: setDaemon() is deprecated, set the daemon attribute instead\n",
            "  self._read_thread.setDaemon(True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHNE_G2MAuhZ",
        "outputId": "a039b53e-e467-4c4a-b997-444ef15a3a50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lam: 0.0 zeta_2: 0.0 rho_C: 0.0 rho_P: 0.0 rho_R: 0.7719199999999996\n",
            "lam: 0.0 zeta_2: 0.05 rho_C: 0.0 rho_P: 0.93896 rho_R: 0.75688\n",
            "lam: 0.0 zeta_2: 0.1 rho_C: 0.0 rho_P: 0.9801999999999998 rho_R: 0.6802000000000001\n",
            "lam: 0.0 zeta_2: 0.15000000000000002 rho_C: 0.0 rho_P: 0.9899999999999998 rho_R: 0.71556\n",
            "lam: 0.0 zeta_2: 0.2 rho_C: 0.0 rho_P: 0.9945999999999998 rho_R: 0.8731200000000002\n",
            "lam: 0.0 zeta_2: 0.25 rho_C: 0.0 rho_P: 0.9979199999999997 rho_R: 0.8527600000000003\n",
            "lam: 0.0 zeta_2: 0.30000000000000004 rho_C: 0.0 rho_P: 0.9975199999999999 rho_R: 0.7740800000000001\n",
            "lam: 0.5 zeta_2: 0.0 rho_C: 0.16943999999999998 rho_P: 0.027759999999999996 rho_R: 0.8116799999999996\n",
            "lam: 0.5 zeta_2: 0.05 rho_C: 0.12724 rho_P: 0.7997999999999998 rho_R: 0.7206799999999997\n",
            "lam: 0.5 zeta_2: 0.1 rho_C: 0.19512000000000002 rho_P: 0.8634 rho_R: 0.79904\n",
            "lam: 0.5 zeta_2: 0.15000000000000002 rho_C: 0.16240000000000002 rho_P: 0.9362799999999997 rho_R: 0.7791999999999999\n",
            "lam: 0.5 zeta_2: 0.2 rho_C: 0.12708 rho_P: 0.9693199999999998 rho_R: 0.75556\n",
            "lam: 0.5 zeta_2: 0.25 rho_C: 0.1282 rho_P: 0.9806400000000002 rho_R: 0.7404000000000002\n",
            "lam: 0.5 zeta_2: 0.30000000000000004 rho_C: 0.20240000000000002 rho_P: 0.98116 rho_R: 0.66256\n",
            "lam: 1.0 zeta_2: 0.0 rho_C: 0.15008163265306124 rho_P: 0.042938775510204086 rho_R: 0.8285714285714284\n",
            "lam: 1.0 zeta_2: 0.05 rho_C: 0.08900000000000001 rho_P: 0.8056399999999997 rho_R: 0.8007200000000002\n",
            "lam: 1.0 zeta_2: 0.1 rho_C: 0.17244 rho_P: 0.8922799999999999 rho_R: 0.7214400000000002\n",
            "lam: 1.0 zeta_2: 0.15000000000000002 rho_C: 0.20440816326530611 rho_P: 0.9311428571428569 rho_R: 0.752408163265306\n",
            "lam: 1.0 zeta_2: 0.2 rho_C: 0.21281632653061222 rho_P: 0.9675510204081632 rho_R: 0.6760816326530612\n",
            "lam: 1.0 zeta_2: 0.25 rho_C: 0.225 rho_P: 0.9748799999999997 rho_R: 0.6639599999999999\n",
            "lam: 1.0 zeta_2: 0.30000000000000004 rho_C: 0.21503999999999998 rho_P: 0.9916799999999998 rho_R: 0.6411600000000002\n",
            "lam: 1.5 zeta_2: 0.0 rho_C: 0.056571428571428564 rho_P: 0.04351020408163265 rho_R: 0.869224489795918\n",
            "lam: 1.5 zeta_2: 0.05 rho_C: 0.18914285714285717 rho_P: 0.7714285714285717 rho_R: 0.7173877551020411\n",
            "lam: 1.5 zeta_2: 0.1 rho_C: 0.14584 rho_P: 0.8920799999999999 rho_R: 0.7577999999999996\n",
            "lam: 1.5 zeta_2: 0.15000000000000002 rho_C: 0.24967346938775511 rho_P: 0.9259999999999999 rho_R: 0.8558367346938777\n",
            "lam: 1.5 zeta_2: 0.2 rho_C: 0.1346122448979592 rho_P: 0.9780408163265305 rho_R: 0.770734693877551\n",
            "lam: 1.5 zeta_2: 0.25 rho_C: 0.11291999999999999 rho_P: 0.9851199999999994 rho_R: 0.7565200000000002\n",
            "lam: 1.5 zeta_2: 0.30000000000000004 rho_C: 0.03775510204081633 rho_P: 0.9935102040816326 rho_R: 0.6912244897959183\n",
            "lam: 2.0 zeta_2: 0.0 rho_C: 0.17024 rho_P: 0.019119999999999998 rho_R: 0.9691199999999999\n",
            "lam: 2.0 zeta_2: 0.05 rho_C: 0.28244 rho_P: 0.68352 rho_R: 0.8244400000000001\n",
            "lam: 2.0 zeta_2: 0.1 rho_C: 0.2113061224489796 rho_P: 0.8748979591836731 rho_R: 0.7385714285714287\n",
            "lam: 2.0 zeta_2: 0.15000000000000002 rho_C: 0.25136 rho_P: 0.9380399999999999 rho_R: 0.62584\n",
            "lam: 2.0 zeta_2: 0.2 rho_C: 0.18752 rho_P: 0.9694800000000002 rho_R: 0.8370799999999998\n",
            "lam: 2.0 zeta_2: 0.25 rho_C: 0.15138775510204083 rho_P: 0.9804081632653062 rho_R: 0.8315918367346935\n",
            "lam: 2.0 zeta_2: 0.30000000000000004 rho_C: 0.05738775510204082 rho_P: 0.9940816326530614 rho_R: 0.7141632653061224\n",
            "lam: 2.5 zeta_2: 0.0 rho_C: 0.20716 rho_P: 0.0 rho_R: 0.83248\n",
            "lam: 2.5 zeta_2: 0.05 rho_C: 0.15163265306122448 rho_P: 0.7823673469387755 rho_R: 0.7791020408163266\n",
            "lam: 2.5 zeta_2: 0.1 rho_C: 0.17906122448979594 rho_P: 0.9068571428571426 rho_R: 0.715795918367347\n",
            "lam: 2.5 zeta_2: 0.15000000000000002 rho_C: 0.23023999999999997 rho_P: 0.9387999999999996 rho_R: 0.6624000000000001\n",
            "lam: 2.5 zeta_2: 0.2 rho_C: 0.18567999999999998 rho_P: 0.9671999999999998 rho_R: 0.6220399999999997\n",
            "lam: 2.5 zeta_2: 0.25 rho_C: 0.22576000000000002 rho_P: 0.9777199999999998 rho_R: 0.77708\n",
            "lam: 2.5 zeta_2: 0.30000000000000004 rho_C: 0.15232 rho_P: 0.9917999999999999 rho_R: 0.74292\n",
            "lam: 3.0 zeta_2: 0.0 rho_C: 0.17048 rho_P: 0.019599999999999996 rho_R: 0.87196\n",
            "lam: 3.0 zeta_2: 0.05 rho_C: 0.1939183673469388 rho_P: 0.7316326530612244 rho_R: 0.8207755102040816\n",
            "lam: 3.0 zeta_2: 0.1 rho_C: 0.1514 rho_P: 0.90488 rho_R: 0.6649200000000001\n",
            "lam: 3.0 zeta_2: 0.15000000000000002 rho_C: 0.15084 rho_P: 0.9490399999999996 rho_R: 0.7571199999999999\n",
            "lam: 3.0 zeta_2: 0.2 rho_C: 0.2362448979591837 rho_P: 0.9682040816326533 rho_R: 0.7734285714285714\n",
            "lam: 3.0 zeta_2: 0.25 rho_C: 0.11112 rho_P: 0.9842399999999998 rho_R: 0.7547200000000001\n",
            "lam: 3.0 zeta_2: 0.30000000000000004 rho_C: 0.226 rho_P: 0.9832800000000002 rho_R: 0.7227999999999999\n",
            "lam: 3.5 zeta_2: 0.0 rho_C: 0.22812244897959186 rho_P: 0.018081632653061223 rho_R: 0.7892244897959182\n",
            "lam: 3.5 zeta_2: 0.05 rho_C: 0.19328 rho_P: 0.7539600000000002 rho_R: 0.7616399999999999\n",
            "lam: 3.5 zeta_2: 0.1 rho_C: 0.17192 rho_P: 0.8942 rho_R: 0.7624399999999999\n",
            "lam: 3.5 zeta_2: 0.15000000000000002 rho_C: 0.17059999999999997 rho_P: 0.9451600000000002 rho_R: 0.6620399999999997\n",
            "lam: 3.5 zeta_2: 0.2 rho_C: 0.24739999999999998 rho_P: 0.9693599999999999 rho_R: 0.79872\n",
            "lam: 3.5 zeta_2: 0.25 rho_C: 0.22824000000000003 rho_P: 0.9820399999999997 rho_R: 0.7014\n",
            "lam: 3.5 zeta_2: 0.30000000000000004 rho_C: 0.19016 rho_P: 0.9888799999999999 rho_R: 0.7984800000000001\n",
            "lam: 4.0 zeta_2: 0.0 rho_C: 0.22936 rho_P: 0.03848000000000001 rho_R: 0.8316\n",
            "lam: 4.0 zeta_2: 0.05 rho_C: 0.1492 rho_P: 0.8040400000000001 rho_R: 0.7631999999999997\n",
            "lam: 4.0 zeta_2: 0.1 rho_C: 0.20391666666666666 rho_P: 0.8970416666666664 rho_R: 0.7717083333333336\n"
          ]
        }
      ],
      "source": [
        "alp = 1\n",
        "zeta_1 = 0.3\n",
        "zeta_3 = 0.3\n",
        "zeta_4 = 0.3\n",
        "beta_PP = 0.06\n",
        "beta_NP = 0.07\n",
        "beta_PN = 0.08\n",
        "beta_NN = 0.089\n",
        "mu = 0.2\n",
        "n_sample = 50\n",
        "\n",
        "# Set the SN-IP and SP-IN disease spreading rates\n",
        "lam_values = np.arange(0.0, 5.1, 0.5)\n",
        "zeta_2_values = np.arange(0.0, 0.31, 0.05)\n",
        "\n",
        "# Initialize the result array\n",
        "results_rho_C = np.zeros((len(lam_values), len(zeta_2_values)))\n",
        "results_rho_P = np.zeros((len(lam_values), len(zeta_2_values)))\n",
        "results_rho_R = np.zeros((len(lam_values), len(zeta_2_values)))\n",
        "\n",
        "# Iterate over values\n",
        "for i, lam in enumerate(lam_values):\n",
        "    for j, zeta_2 in enumerate(zeta_2_values):\n",
        "        avg_rho_C, avg_rho_P, avg_rho_R = ICE_model(inw, ldeg_i, ltre, cnw, ldeg_c, lprot, enw, ldeg_e, lam, alp, zeta_1, zeta_2, zeta_3, zeta_4, beta_PP, beta_NP, beta_PN, beta_NN, mu, n_sample)\n",
        "        results_rho_C[i, j] = avg_rho_C\n",
        "        results_rho_P[i, j] = avg_rho_P\n",
        "        results_rho_R[i, j] = avg_rho_R\n",
        "        print(\"lam:\", lam, \"zeta_2:\", zeta_2, \"rho_C:\", avg_rho_C, \"rho_P:\", avg_rho_P, \"rho_R:\", avg_rho_R)\n",
        "# Save result\n",
        "df1 = pd.DataFrame(results_rho_C)\n",
        "df1.to_csv('/content/drive/My Drive/Network_Tests/rho_C_lam_zeta2_hyperedge_111223_new_beta.csv')\n",
        "df2 = pd.DataFrame(results_rho_P)\n",
        "df2.to_csv('/content/drive/My Drive/Network_Tests/rho_P_lam_zeta2_hyperedge_111223_new_beta.csv')\n",
        "df3 = pd.DataFrame(results_rho_R)\n",
        "df3.to_csv('/content/drive/My Drive/Network_Tests/rho_R_lam_zeta2_hyperedge_111223_new_beta.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RoCxNnNoeYN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming your data and values are set up as before:\n",
        "# results_rho_R3, zeta_4_values3, zeta_2_values3\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/Network_Tests/rho_R_lam_zeta2_hyperedge_111223_new_beta.csv')\n",
        "results_rho_R = df.to_numpy()\n",
        "\n",
        "lam_values = np.arange(0.0, 5.1, 0.5)\n",
        "zeta_2_values = np.arange(0.0, 0.31, 0.05)\n",
        "\n",
        "# Create a heatmap plot\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "im = ax.imshow(results_rho_R[:, 1:11], cmap='viridis', aspect='auto', origin='lower',\n",
        "               extent=[min(zeta_2_values), max(zeta_2_values), min(lam_values), max(lam_values)])\n",
        "\n",
        "# Setting labels, colorbar, and title\n",
        "ax.set_xlabel('Protection adoption rate by information $\\zeta_2$', fontsize=16)\n",
        "ax.set_ylabel('Spreading rate of information $\\lambda$', fontsize=16)\n",
        "plt.colorbar(im, label='Attack Rate', ax=ax)\n",
        "plt.rc('xtick', labelsize=16)\n",
        "plt.rc('ytick', labelsize=16)\n",
        "plt.grid()\n",
        "\n",
        "# Display the plot\n",
        "plt.savefig('/content/drive/My Drive/Network_Tests/heatmap_lam_zeta_2_hyperedge_111223_new_beta.pdf')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}