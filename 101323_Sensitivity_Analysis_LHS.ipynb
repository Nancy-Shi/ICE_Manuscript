{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nancy-Shi/ICE_Manuscript/blob/main/101323_Sensitivity_Analysis_LHS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA_qQY-h8rAL"
      },
      "source": [
        "## 3-Layer Model with Informtion, Behavior, Disease"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lvbMl01j8mD4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f99d2ab3-706d-4985-ffdb-c9e74ee915f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " No module named 'igraph'. If you need to use hypernetx.algorithms.hypergraph_modularity, please install additional packages by running the following command: pip install .['all']\n"
          ]
        }
      ],
      "source": [
        "#!pip install hypernetx\n",
        "import hypernetx as hnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Fan2mZxpB3Up",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c04b0aa-0e2d-49fc-e13b-00070ba569a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import random\n",
        "import math as math\n",
        "from math import log\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.ticker as ticker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUCtz8IJ8VkT"
      },
      "source": [
        "\n",
        "## Part 1: Hypergraph Generation\n",
        "The following steps generate a hyper graph using the XGI/HyperNetX python package,  following power-law degree distribution for predifined number of nodes n, number of hyperedges num_hyper_edges, degree exponent gamma, using a configuration model with data stored in a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3qvT8MAI8VEs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbd1d46e-cd9b-4f27-ffb4-391be3923846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Generate Degree Sequence\n",
        "def generate_degree_sequence(n, gamma, kmin):\n",
        "    # Generate a random set from the power law distribution\n",
        "    u = np.random.uniform(size=n)\n",
        "    degrees = np.ceil((1.0 - u) ** (-1.0 / (gamma - 1.0)))\n",
        "\n",
        "    # Adjust degrees based on the minimum and maximum degree values\n",
        "    kmax = int(np.sqrt(n))\n",
        "    #kmax = int(((gamma-1)/(gamma-2) * n )** (1/gamma))  # max degree\n",
        "    # kmax = int(1.5*n**(1/4)) # max degree allowed is 1.5*n^(1/4)\n",
        "    degrees = degrees[(degrees >= kmin) & (degrees <= kmax)].astype(int)\n",
        "\n",
        "    # Truncate or pad the sequence to match the length specified\n",
        "    if len(degrees) >= n:\n",
        "        degrees = degrees[:n]\n",
        "    else:\n",
        "        degrees = np.concatenate((degrees, np.full(n - len(degrees), kmin)))\n",
        "\n",
        "    return degrees.tolist()\n",
        "\n",
        "# Step 2: Generate Hyper Edge Size Sequence\n",
        "def generate_hyper_edge_sizes(degrees, num_hyper_edges):\n",
        "    total_degrees = sum(degrees)\n",
        "    hyper_edge_sizes = []\n",
        "\n",
        "    # Calculate the average size for each hyper edge\n",
        "    avg_size = total_degrees // num_hyper_edges\n",
        "    remainder = total_degrees % num_hyper_edges\n",
        "\n",
        "    # Define the range for the random distribution\n",
        "    min_size = 2  # Lower bound of the range\n",
        "    max_size = int(np.sqrt(total_degrees))  # Upper bound of the range\n",
        "    #max_size = len(degrees) - num_hyper_edges  # Upper bound of the range\n",
        "\n",
        "    # Generate hyper edge sizes\n",
        "    for _ in range(num_hyper_edges):\n",
        "        size = random.randint(min_size, max_size)\n",
        "        hyper_edge_sizes.append(size)\n",
        "\n",
        "    return hyper_edge_sizes\n",
        "\n",
        "\n",
        "# Step 3: Create Copies of Nodes\n",
        "def create_node_copies(degrees):\n",
        "    node_copies = []\n",
        "    for i, degree in enumerate(degrees):\n",
        "        for _ in range(degree):\n",
        "            node_copies.append(i)\n",
        "    return node_copies\n",
        "\n",
        "# Step 4: Create Copies of Hyper Edges\n",
        "def create_hyper_edge_copies(hyper_edge_sizes):\n",
        "    hyper_edge_copies = []\n",
        "    for i, size in enumerate(hyper_edge_sizes):\n",
        "        for _ in range(size):\n",
        "            hyper_edge_copies.append(i)\n",
        "    return hyper_edge_copies\n",
        "\n",
        "# Step 5: Randomly Pair Copies without Repeated Pairs\n",
        "def randomly_pair_copies(node_copies, hyper_edge_copies):\n",
        "    pairs = []\n",
        "    paired_hyper_edges = {} # Using a dictionary to track paired hyper-edges with nodes\n",
        "\n",
        "    for node_copy in node_copies:\n",
        "        available_hyper_edges = [h for h in hyper_edge_copies if (h, node_copy) not in paired_hyper_edges]\n",
        "\n",
        "        # If no available hyper-edges left, shuffle the paired hyper-edges and reset\n",
        "        if not available_hyper_edges:\n",
        "            paired_hyper_edges = {}\n",
        "            available_hyper_edges = [h for h in hyper_edge_copies if (h, node_copy) not in paired_hyper_edges]\n",
        "\n",
        "        # Randomly choose a hyper-edge that has not been paired yet with the current node\n",
        "        chosen_hyper_edge = random.choice(available_hyper_edges)\n",
        "        pairs.append((node_copy, chosen_hyper_edge))\n",
        "\n",
        "        # Add to paired_hyper_edges\n",
        "        paired_hyper_edges[(chosen_hyper_edge, node_copy)] = True\n",
        "        hyper_edge_copies.remove(chosen_hyper_edge)\n",
        "\n",
        "    return pairs\n",
        "\n",
        "# Step 6: Convert Bipartite Graph to A Hypergraph Dictionary\n",
        "def convert_to_hypergraph(pairs):\n",
        "    hypergraph = {}\n",
        "    for pair in pairs:\n",
        "        node, hyper_edge = pair\n",
        "        if hyper_edge in hypergraph:\n",
        "            hypergraph[hyper_edge].append(node)\n",
        "        else:\n",
        "            hypergraph[hyper_edge] = [node]\n",
        "    return hypergraph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0b6c7yfU8hg8"
      },
      "outputs": [],
      "source": [
        "def build_hypergraph(n, gamma, kmin, num_hyper_edges):\n",
        "    # Step 1: Generate Degree Sequence\n",
        "    degrees = generate_degree_sequence(n, gamma, kmin)\n",
        "    print(\"Degree Sequence: \", degrees)\n",
        "\n",
        "    # Step 2: Generate Hyper Edge Size Sequence\n",
        "    hyper_edge_sizes = generate_hyper_edge_sizes(degrees, num_hyper_edges)\n",
        "    print(\"Hyper Edge Sizes: \", hyper_edge_sizes)\n",
        "\n",
        "    # Step 3: Create Copies of Nodes\n",
        "    node_copies = create_node_copies(degrees)\n",
        "\n",
        "    # Step 4: Create Copies of Hyper Edges\n",
        "    hyper_edge_copies = create_hyper_edge_copies(hyper_edge_sizes)\n",
        "\n",
        "    # Step 5: Randomly Pair Copies\n",
        "    pairs = randomly_pair_copies(node_copies, hyper_edge_copies)\n",
        "\n",
        "    # Step 6: Convert Bipartite Graph to Hypergraph\n",
        "    hyperedge_dict = convert_to_hypergraph(pairs)\n",
        "\n",
        "    # Print the resulting hypergraph\n",
        "    print(\"Hypergraph Dictionary: \", hyperedge_dict)\n",
        "\n",
        "    return degrees, hyperedge_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-tEXGpf819Y",
        "outputId": "5ec4d23f-3678-4f56-e731-61bf98f5c9e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Degree Sequence:  [7, 3, 7, 3, 3, 3, 4, 3, 4, 5, 4, 4, 3, 8, 11, 3, 4, 5, 3, 3, 3, 5, 6, 4, 3, 3, 3, 3, 3, 3, 4, 3, 3, 18, 3, 3, 4, 5, 3, 10, 3, 3, 3, 7, 4, 3, 4, 4, 3, 13, 3, 3, 15, 3, 7, 6, 9, 4, 8, 6, 5, 3, 5, 5, 3, 3, 5, 4, 4, 3, 3, 3, 3, 4, 4, 6, 3, 5, 5, 3, 3, 8, 5, 4, 4, 3, 3, 18, 5, 4, 4, 3, 3, 4, 8, 5, 6, 4, 3, 6, 3, 3, 3, 4, 4, 4, 3, 4, 5, 6, 3, 5, 3, 3, 3, 4, 4, 4, 6, 5, 3, 6, 3, 3, 4, 4, 4, 6, 3, 4, 3, 6, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
            "Hyper Edge Sizes:  [29, 25, 14, 6, 27, 14, 20, 15, 28, 32, 26, 29, 34, 35, 27, 3, 28, 36, 17, 2, 34, 7, 5, 27, 17, 22, 31, 2, 30, 32, 18, 29, 16, 2, 19, 23, 20, 27, 34, 11, 22, 23, 24, 26, 17, 8, 8, 5, 28, 24, 16, 30, 9, 29, 35, 34, 23, 20, 5, 34, 27, 10, 31, 12, 10, 18, 34, 33, 34, 6, 30, 2, 32, 31, 10, 30, 3, 36, 32, 22, 36, 32, 11, 28, 9, 2, 2, 9, 8, 2, 8, 7, 8, 17, 36, 15, 30, 19, 11, 6]\n",
            "Hypergraph Dictionary:  {60: [0, 21, 37, 49, 57, 58, 76, 80, 116, 118, 130, 146, 151, 195, 236, 251, 254, 265, 354], 81: [0, 14, 17, 18, 39, 41, 43, 49, 52, 87, 88, 90, 128, 152, 191, 195, 197, 210, 269, 272, 318, 329, 334, 351, 384, 390], 57: [0, 12, 30, 37, 136, 141, 191, 234, 263, 276, 277, 285, 292, 333, 356, 392], 4: [0, 24, 48, 68, 71, 75, 81, 104, 135, 187, 190, 277, 291, 389], 5: [0, 29, 33, 43, 79, 114, 185, 274, 322], 98: [0, 25, 41, 121, 160, 203, 206, 273, 308, 322], 83: [0, 2, 6, 22, 33, 39, 44, 49, 94, 108, 131, 143, 159, 218, 267, 294, 299, 325, 387], 48: [1, 4, 16, 19, 20, 47, 52, 66, 88, 94, 117, 125, 136, 256, 282, 284, 285, 325, 335, 355, 373, 382], 40: [1, 7, 21, 51, 119, 121, 133, 192, 222, 229, 256, 268, 283, 345, 349, 360, 362], 68: [1, 10, 57, 65, 77, 97, 131, 133, 149, 179, 199, 201, 281, 290, 306, 310, 369, 371, 378, 384, 386], 38: [2, 3, 13, 52, 55, 65, 90, 94, 102, 116, 159, 171, 186, 207, 236, 306, 307, 308, 320, 350, 379, 381, 391], 1: [2, 3, 11, 13, 14, 50, 55, 81, 87, 94, 99, 123, 140, 164, 209, 276, 334, 369, 399], 31: [2, 35, 45, 49, 115, 129, 138, 203, 205, 250, 280, 290, 305, 314, 330, 334, 342, 374, 393], 49: [2, 22, 64, 67, 86, 103, 117, 123, 140, 162, 168, 198, 244, 248, 271, 317, 335, 346, 353, 363], 29: [2, 22, 23, 33, 55, 59, 60, 70, 84, 110, 113, 125, 178, 180, 194, 231, 239, 247, 258, 282, 305, 320, 321, 344, 363, 374, 390], 35: [2, 21, 52, 69, 81, 97, 127, 142, 146, 163, 176, 177, 179, 217, 221, 380, 381, 398], 56: [3, 15, 42, 65, 76, 107, 131, 135, 138, 144, 228, 284, 292, 319, 344, 367, 368], 50: [4, 5, 43, 64, 125, 220, 227, 357], 59: [4, 15, 27, 68, 94, 106, 109, 110, 117, 119, 132, 133, 139, 165, 167, 168, 175, 186, 203, 205, 244, 261, 279, 315, 341, 348, 351, 377], 16: [5, 47, 52, 101, 105, 118, 120, 122, 154, 184, 189, 200, 249, 266, 287, 294, 303, 365, 395], 39: [5, 39, 56, 161, 178, 261, 304, 382, 387], 51: [6, 22, 58, 98, 108, 119, 122, 150, 153, 172, 182, 193, 196, 230, 240, 245, 247, 271, 313, 321, 332, 354, 369], 92: [6, 8, 16, 143, 144, 148], 95: [6, 23, 50, 81, 93, 158, 163, 192, 275, 295, 344], 26: [7, 33, 52, 57, 69, 76, 107, 152, 180, 199, 218, 242, 266, 267, 286, 298, 299, 312, 324, 358, 381], 13: [7, 13, 18, 24, 27, 31, 33, 39, 52, 54, 101, 113, 126, 155, 174, 196, 219, 237, 263, 276, 277, 296, 313, 339, 340, 342, 367, 376], 67: [8, 31, 54, 67, 83, 104, 134, 202, 209, 212, 241, 243, 255, 260, 290, 291, 295, 302, 366, 372, 389, 394], 66: [8, 26, 96, 104, 109, 162, 172, 180, 183, 198, 243, 258, 282, 302, 311, 335, 339, 341, 356, 371, 380, 394, 396], 62: [8, 10, 14, 30, 44, 49, 68, 99, 165, 178, 198, 226, 227, 248, 264, 308, 309, 311, 364, 384, 392], 70: [9, 33, 74, 87, 98, 102, 118, 120, 126, 135, 138, 201, 247, 301, 316, 359, 365], 72: [9, 13, 33, 53, 69, 73, 87, 88, 92, 99, 103, 134, 147, 159, 183, 188, 215, 216, 224, 245, 297, 300, 346, 385, 398], 75: [9, 54, 60, 61, 72, 78, 87, 93, 101, 105, 116, 131, 175, 210, 238, 260, 273, 292, 302, 304, 370], 7: [9, 11, 22, 43, 90, 124, 140, 149, 170, 226, 315], 20: [9, 12, 46, 54, 63, 66, 77, 92, 115, 118, 166, 167, 171, 173, 216, 237, 245, 270, 287, 309, 318, 327, 337, 368], 94: [10, 11, 17, 29, 37, 45, 46, 81, 111, 127, 139, 144, 152, 153, 163, 184, 186, 237, 246, 252, 274, 287, 293, 364, 375, 377, 385, 391, 397], 10: [10, 37, 78, 95, 96, 121, 141, 166, 169, 192, 212, 253, 286, 297, 340, 343, 353, 360, 387], 30: [11, 13, 14, 30, 33, 216, 221, 289, 295, 377], 79: [12, 49, 68, 70, 75, 83, 170, 172, 215, 275, 281, 291, 313, 326, 331], 43: [13, 29, 33, 39, 58, 83, 84, 85, 94, 95, 96, 110, 122, 189, 193, 254, 355, 379], 54: [13, 14, 17, 24, 37, 51, 59, 62, 89, 95, 107, 114, 154, 197, 213, 225, 228, 231, 234, 255, 259, 283, 343, 360], 0: [13, 14, 15, 22, 27, 34, 52, 53, 87, 91, 103, 124, 176, 202, 217, 233, 328, 330, 363, 399], 74: [14, 79, 136, 147, 244, 317], 34: [14, 16, 21, 33, 34, 35, 40, 56, 79, 80, 95, 116, 119, 127, 129, 301], 11: [14, 36, 38, 50, 63, 71, 77, 87, 108, 117, 124, 126, 127, 155, 204, 207, 228, 248, 260, 274, 323, 356, 372], 37: [14, 18, 31, 58, 59, 60, 105, 113, 202, 204, 205, 214, 225, 232, 252, 270, 303, 339, 358], 61: [14, 25, 82, 87, 108, 347], 78: [16, 25, 42, 47, 49, 53, 77, 84, 86, 111, 143, 161, 177, 194, 200, 209, 225, 229, 233, 269, 283, 298, 300, 310, 320, 329, 397], 82: [17, 33, 39, 73, 81, 130, 145, 147, 239, 378], 28: [17, 39, 48, 52, 54, 63, 120, 158, 173, 183, 185, 188, 199, 265, 285, 304, 317, 350], 2: [19, 49, 75, 81, 132, 174, 243, 321, 338, 357, 374, 380], 65: [19, 20, 26, 34, 36, 66, 87, 160, 168, 272, 284, 367, 375], 12: [20, 26, 33, 36, 88, 100, 112, 132, 190, 211, 250, 253, 279, 289, 330, 343, 346, 362, 366], 17: [21, 54, 59, 82, 87, 99, 100, 121, 173, 211, 213, 256, 257, 259, 267, 286, 376, 386, 389], 45: [23, 56, 249, 296, 331, 340, 364], 47: [23, 59, 66, 222, 268], 36: [28, 33, 41, 58, 62, 75, 80, 128, 142, 181, 204, 246, 359, 361], 44: [28, 111, 123, 137, 170, 230, 235, 307, 310, 322, 368, 375], 84: [28, 33, 39, 279, 312, 319], 96: [30, 33, 40, 49, 56, 58, 60, 127, 131, 187, 200, 212, 222, 241, 242, 262, 280, 293, 332, 337, 350], 14: [32, 35, 83, 87, 91, 102, 150, 157, 257, 314, 316, 323, 324, 338, 388, 393], 42: [32, 49, 55, 56, 94, 103, 109, 139, 253, 297, 314, 345, 354], 64: [32, 164, 324, 371, 392, 399], 73: [33, 48, 70, 73, 78, 85, 90, 98, 124, 131, 142, 197, 217, 219, 223, 235, 251, 254, 336, 347, 361, 370, 378], 80: [33, 36, 52, 61, 73, 77, 87, 89, 91, 104, 108, 112, 125, 156, 191, 214, 220, 224, 234, 249, 250, 251, 255, 288, 345, 353], 55: [33, 43, 44, 49, 55, 62, 75, 78, 87, 93, 96, 97, 112, 137, 185, 190, 207, 273, 327, 341, 349, 351, 358, 394], 3: [38, 59, 232, 336, 352], 91: [38, 106, 372, 395], 88: [39, 87, 220, 319, 388], 97: [39, 55, 58, 74, 99, 181, 182, 231, 262, 318, 355], 25: [40, 43, 96, 107, 111, 153, 165, 215, 223, 232, 294, 357, 391, 396], 23: [42, 45, 52, 67, 82, 89, 106, 155, 158, 166, 188, 195, 196, 219, 227, 242, 337, 386], 6: [43, 54, 71, 92, 118, 145, 206, 238, 280, 293, 299, 300, 397], 9: [44, 56, 60, 95, 96, 100, 109, 119, 121, 128, 157, 164, 167, 194, 236, 262, 272, 342, 365, 383, 396], 58: [46, 383], 18: [46, 109, 114, 132, 169, 201, 208, 238, 311, 328, 379], 8: [47, 51, 52, 72, 87, 88, 94, 97, 115, 129, 156, 161, 181, 223, 224, 226, 229, 258, 270, 278, 331, 373, 385], 52: [49, 62, 115, 174, 182, 329, 352], 53: [49, 57, 66, 75, 81, 87, 93, 133, 150, 156, 184, 230, 233, 246, 268, 288, 289, 296, 316, 327, 333], 99: [52, 87, 160, 187, 278], 32: [52, 67, 74, 87, 193, 265, 326, 370], 77: [52, 62, 82, 105, 118, 121, 126, 129, 137, 141, 145, 146, 210, 241, 257, 264, 266, 305, 315, 325, 326, 336, 361, 383, 395, 398], 87: [56, 64, 111, 235, 390], 63: [56, 157, 177, 239, 347], 93: [56, 58, 127, 130, 151, 179, 189, 206, 240, 312, 323, 348, 373, 393], 46: [61, 89, 214, 252, 259, 366], 86: [63, 359], 69: [63, 78, 85, 261], 24: [72, 109, 134, 149, 154, 171, 211, 264, 281, 288, 301, 362], 90: [74, 148, 221, 306, 309], 41: [82, 86, 162, 176, 208, 213, 218, 263, 271, 278, 303, 328, 333, 338, 348, 349, 376, 388], 22: [84], 71: [99, 148], 21: [151, 175, 332], 85: [169, 382], 15: [208, 352], 33: [240, 269], 89: [275], 27: [298], 19: [307]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  return np.find_common_type(types, [])\n"
          ]
        }
      ],
      "source": [
        "# Test 2\n",
        "n2 =400  # Number of nodes\n",
        "gamma2 = 2.5  # Power-law exponent\n",
        "kmin2 = 3  # Minimum degree\n",
        "num_hyper_edges2 = 100  # Desired number of hyper edges\n",
        "\n",
        "degrees2, hyperedge_dict2 = build_hypergraph(n2, gamma2, kmin2, num_hyper_edges2)\n",
        "H2 = hnx.Hypergraph(hyperedge_dict2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bbX083i9Htn"
      },
      "source": [
        "## Part 2: Assign Behavior Status\n",
        "NP represents the state of no protection, while P represents the state of with protection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "elKpYEaU9HE1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6710e641-29e5-452d-ea26-a5c27aa8cf98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "def assign_protection(hypergraph, fraction_protected):\n",
        "    # Get the list of nodes from the hypergraph\n",
        "    nodes = list(hypergraph.nodes())\n",
        "\n",
        "    # Calculate the number of nodes to protect\n",
        "    num_nodes_to_protect = int(len(nodes) * fraction_protected)\n",
        "\n",
        "    # Randomly choose nodes to protect\n",
        "    nodes_to_protect = random.sample(nodes, num_nodes_to_protect)\n",
        "\n",
        "    # Initialize the protection status dictionary\n",
        "    protection_status = {}\n",
        "\n",
        "    # Assign protection status to each node\n",
        "    for node in nodes:\n",
        "        if node in nodes_to_protect:\n",
        "            protection_status[node] = \"P\"  # Protected node\n",
        "        else:\n",
        "            protection_status[node] = \"N\"  # Non-protected node\n",
        "\n",
        "    print(protection_status)\n",
        "\n",
        "    return protection_status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxZAdvJR-TXv",
        "outputId": "2639f6b6-4fc7-4047-d1e4-15b5be322080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'N', 1: 'N', 2: 'P', 3: 'N', 4: 'P', 5: 'N', 6: 'N', 7: 'N', 8: 'N', 9: 'N', 10: 'N', 11: 'N', 12: 'N', 13: 'P', 14: 'N', 15: 'N', 16: 'N', 17: 'N', 18: 'P', 19: 'P', 20: 'N', 21: 'P', 22: 'P', 23: 'P', 24: 'N', 25: 'N', 26: 'N', 27: 'N', 28: 'N', 29: 'N', 30: 'N', 31: 'N', 32: 'N', 33: 'N', 34: 'N', 35: 'N', 36: 'N', 37: 'N', 38: 'N', 39: 'N', 40: 'N', 41: 'N', 42: 'N', 43: 'N', 44: 'N', 45: 'N', 46: 'N', 47: 'N', 48: 'N', 49: 'N', 50: 'N', 51: 'N', 52: 'N', 53: 'N', 54: 'N', 55: 'N', 56: 'N', 57: 'N', 58: 'N', 59: 'N', 60: 'N', 61: 'N', 62: 'P', 63: 'N', 64: 'N', 65: 'N', 66: 'N', 67: 'N', 68: 'N', 69: 'N', 70: 'P', 71: 'N', 72: 'N', 73: 'N', 74: 'N', 75: 'N', 76: 'P', 77: 'N', 78: 'N', 79: 'N', 80: 'N', 81: 'N', 82: 'N', 83: 'N', 84: 'N', 85: 'N', 86: 'N', 87: 'N', 88: 'N', 89: 'N', 90: 'N', 91: 'N', 92: 'N', 93: 'N', 94: 'N', 95: 'N', 96: 'N', 97: 'P', 98: 'N', 99: 'N', 100: 'N', 101: 'N', 102: 'N', 103: 'N', 104: 'P', 105: 'N', 106: 'N', 107: 'N', 108: 'N', 109: 'N', 110: 'N', 111: 'N', 112: 'N', 113: 'P', 114: 'N', 115: 'P', 116: 'N', 117: 'N', 118: 'N', 119: 'N', 120: 'N', 121: 'N', 122: 'N', 123: 'N', 124: 'N', 125: 'N', 126: 'N', 127: 'N', 128: 'N', 129: 'P', 130: 'N', 131: 'N', 132: 'P', 133: 'N', 134: 'N', 135: 'N', 136: 'N', 137: 'N', 138: 'N', 139: 'N', 140: 'N', 141: 'N', 142: 'N', 143: 'N', 144: 'N', 145: 'N', 146: 'N', 147: 'N', 148: 'N', 149: 'N', 150: 'N', 151: 'N', 152: 'N', 153: 'N', 154: 'N', 155: 'N', 156: 'N', 157: 'P', 158: 'N', 159: 'N', 160: 'N', 161: 'N', 162: 'N', 163: 'N', 164: 'N', 165: 'N', 166: 'N', 167: 'N', 168: 'P', 169: 'N', 170: 'N', 171: 'N', 172: 'N', 173: 'N', 174: 'N', 175: 'N', 176: 'N', 177: 'N', 178: 'N', 179: 'N', 180: 'N', 181: 'P', 182: 'N', 183: 'N', 184: 'N', 185: 'N', 186: 'N', 187: 'N', 188: 'N', 189: 'P', 190: 'N', 191: 'N', 192: 'N', 193: 'P', 194: 'P', 195: 'N', 196: 'N', 197: 'N', 198: 'N', 199: 'N', 200: 'N', 201: 'N', 202: 'N', 203: 'N', 204: 'N', 205: 'N', 206: 'N', 207: 'N', 208: 'N', 209: 'N', 210: 'N', 211: 'N', 212: 'N', 213: 'N', 214: 'N', 215: 'N', 216: 'N', 217: 'N', 218: 'N', 219: 'N', 220: 'N', 221: 'N', 222: 'N', 223: 'N', 224: 'N', 225: 'N', 226: 'N', 227: 'N', 228: 'N', 229: 'N', 230: 'N', 231: 'N', 232: 'N', 233: 'N', 234: 'N', 235: 'N', 236: 'N', 237: 'N', 238: 'N', 239: 'N', 240: 'N', 241: 'N', 242: 'N', 243: 'N', 244: 'N', 245: 'N', 246: 'N', 247: 'N', 248: 'N', 249: 'P', 250: 'P', 251: 'N', 252: 'N', 253: 'N', 254: 'N', 255: 'N', 256: 'N', 257: 'N', 258: 'N', 259: 'N', 260: 'P', 261: 'N', 262: 'N', 263: 'N', 264: 'N', 265: 'N', 266: 'N', 267: 'N', 268: 'N', 269: 'N', 270: 'N', 271: 'N', 272: 'P', 273: 'N', 274: 'N', 275: 'N', 276: 'N', 277: 'N', 278: 'N', 279: 'N', 280: 'N', 281: 'N', 282: 'N', 283: 'N', 284: 'N', 285: 'N', 286: 'N', 287: 'N', 288: 'N', 289: 'N', 290: 'N', 291: 'N', 292: 'N', 293: 'N', 294: 'N', 295: 'N', 296: 'P', 297: 'N', 298: 'P', 299: 'P', 300: 'P', 301: 'N', 302: 'N', 303: 'N', 304: 'N', 305: 'N', 306: 'N', 307: 'N', 308: 'N', 309: 'N', 310: 'N', 311: 'N', 312: 'N', 313: 'N', 314: 'N', 315: 'N', 316: 'P', 317: 'N', 318: 'N', 319: 'N', 320: 'N', 321: 'N', 322: 'N', 323: 'N', 324: 'N', 325: 'N', 326: 'N', 327: 'N', 328: 'N', 329: 'N', 330: 'N', 331: 'P', 332: 'P', 333: 'P', 334: 'N', 335: 'N', 336: 'N', 337: 'N', 338: 'N', 339: 'P', 340: 'N', 341: 'P', 342: 'N', 343: 'N', 344: 'N', 345: 'N', 346: 'N', 347: 'N', 348: 'N', 349: 'N', 350: 'N', 351: 'N', 352: 'N', 353: 'N', 354: 'P', 355: 'N', 356: 'N', 357: 'N', 358: 'N', 359: 'N', 360: 'N', 361: 'N', 362: 'N', 363: 'N', 364: 'N', 365: 'N', 366: 'N', 367: 'N', 368: 'N', 369: 'N', 370: 'N', 371: 'N', 372: 'N', 373: 'N', 374: 'N', 375: 'P', 376: 'N', 377: 'N', 378: 'N', 379: 'N', 380: 'N', 381: 'N', 382: 'N', 383: 'N', 384: 'N', 385: 'N', 386: 'N', 387: 'N', 388: 'N', 389: 'N', 390: 'P', 391: 'N', 392: 'N', 393: 'N', 394: 'N', 395: 'N', 396: 'N', 397: 'N', 398: 'N', 399: 'N'}\n",
            "{0: 'N', 1: 'N', 2: 'P', 3: 'N', 4: 'P', 5: 'N', 6: 'N', 7: 'N', 8: 'N', 9: 'N', 10: 'N', 11: 'N', 12: 'N', 13: 'P', 14: 'N', 15: 'N', 16: 'N', 17: 'N', 18: 'P', 19: 'P', 20: 'N', 21: 'P', 22: 'P', 23: 'P', 24: 'N', 25: 'N', 26: 'N', 27: 'N', 28: 'N', 29: 'N', 30: 'N', 31: 'N', 32: 'N', 33: 'N', 34: 'N', 35: 'N', 36: 'N', 37: 'N', 38: 'N', 39: 'N', 40: 'N', 41: 'N', 42: 'N', 43: 'N', 44: 'N', 45: 'N', 46: 'N', 47: 'N', 48: 'N', 49: 'N', 50: 'N', 51: 'N', 52: 'N', 53: 'N', 54: 'N', 55: 'N', 56: 'N', 57: 'N', 58: 'N', 59: 'N', 60: 'N', 61: 'N', 62: 'P', 63: 'N', 64: 'N', 65: 'N', 66: 'N', 67: 'N', 68: 'N', 69: 'N', 70: 'P', 71: 'N', 72: 'N', 73: 'N', 74: 'N', 75: 'N', 76: 'P', 77: 'N', 78: 'N', 79: 'N', 80: 'N', 81: 'N', 82: 'N', 83: 'N', 84: 'N', 85: 'N', 86: 'N', 87: 'N', 88: 'N', 89: 'N', 90: 'N', 91: 'N', 92: 'N', 93: 'N', 94: 'N', 95: 'N', 96: 'N', 97: 'P', 98: 'N', 99: 'N', 100: 'N', 101: 'N', 102: 'N', 103: 'N', 104: 'P', 105: 'N', 106: 'N', 107: 'N', 108: 'N', 109: 'N', 110: 'N', 111: 'N', 112: 'N', 113: 'P', 114: 'N', 115: 'P', 116: 'N', 117: 'N', 118: 'N', 119: 'N', 120: 'N', 121: 'N', 122: 'N', 123: 'N', 124: 'N', 125: 'N', 126: 'N', 127: 'N', 128: 'N', 129: 'P', 130: 'N', 131: 'N', 132: 'P', 133: 'N', 134: 'N', 135: 'N', 136: 'N', 137: 'N', 138: 'N', 139: 'N', 140: 'N', 141: 'N', 142: 'N', 143: 'N', 144: 'N', 145: 'N', 146: 'N', 147: 'N', 148: 'N', 149: 'N', 150: 'N', 151: 'N', 152: 'N', 153: 'N', 154: 'N', 155: 'N', 156: 'N', 157: 'P', 158: 'N', 159: 'N', 160: 'N', 161: 'N', 162: 'N', 163: 'N', 164: 'N', 165: 'N', 166: 'N', 167: 'N', 168: 'P', 169: 'N', 170: 'N', 171: 'N', 172: 'N', 173: 'N', 174: 'N', 175: 'N', 176: 'N', 177: 'N', 178: 'N', 179: 'N', 180: 'N', 181: 'P', 182: 'N', 183: 'N', 184: 'N', 185: 'N', 186: 'N', 187: 'N', 188: 'N', 189: 'P', 190: 'N', 191: 'N', 192: 'N', 193: 'P', 194: 'P', 195: 'N', 196: 'N', 197: 'N', 198: 'N', 199: 'N', 200: 'N', 201: 'N', 202: 'N', 203: 'N', 204: 'N', 205: 'N', 206: 'N', 207: 'N', 208: 'N', 209: 'N', 210: 'N', 211: 'N', 212: 'N', 213: 'N', 214: 'N', 215: 'N', 216: 'N', 217: 'N', 218: 'N', 219: 'N', 220: 'N', 221: 'N', 222: 'N', 223: 'N', 224: 'N', 225: 'N', 226: 'N', 227: 'N', 228: 'N', 229: 'N', 230: 'N', 231: 'N', 232: 'N', 233: 'N', 234: 'N', 235: 'N', 236: 'N', 237: 'N', 238: 'N', 239: 'N', 240: 'N', 241: 'N', 242: 'N', 243: 'N', 244: 'N', 245: 'N', 246: 'N', 247: 'N', 248: 'N', 249: 'P', 250: 'P', 251: 'N', 252: 'N', 253: 'N', 254: 'N', 255: 'N', 256: 'N', 257: 'N', 258: 'N', 259: 'N', 260: 'P', 261: 'N', 262: 'N', 263: 'N', 264: 'N', 265: 'N', 266: 'N', 267: 'N', 268: 'N', 269: 'N', 270: 'N', 271: 'N', 272: 'P', 273: 'N', 274: 'N', 275: 'N', 276: 'N', 277: 'N', 278: 'N', 279: 'N', 280: 'N', 281: 'N', 282: 'N', 283: 'N', 284: 'N', 285: 'N', 286: 'N', 287: 'N', 288: 'N', 289: 'N', 290: 'N', 291: 'N', 292: 'N', 293: 'N', 294: 'N', 295: 'N', 296: 'P', 297: 'N', 298: 'P', 299: 'P', 300: 'P', 301: 'N', 302: 'N', 303: 'N', 304: 'N', 305: 'N', 306: 'N', 307: 'N', 308: 'N', 309: 'N', 310: 'N', 311: 'N', 312: 'N', 313: 'N', 314: 'N', 315: 'N', 316: 'P', 317: 'N', 318: 'N', 319: 'N', 320: 'N', 321: 'N', 322: 'N', 323: 'N', 324: 'N', 325: 'N', 326: 'N', 327: 'N', 328: 'N', 329: 'N', 330: 'N', 331: 'P', 332: 'P', 333: 'P', 334: 'N', 335: 'N', 336: 'N', 337: 'N', 338: 'N', 339: 'P', 340: 'N', 341: 'P', 342: 'N', 343: 'N', 344: 'N', 345: 'N', 346: 'N', 347: 'N', 348: 'N', 349: 'N', 350: 'N', 351: 'N', 352: 'N', 353: 'N', 354: 'P', 355: 'N', 356: 'N', 357: 'N', 358: 'N', 359: 'N', 360: 'N', 361: 'N', 362: 'N', 363: 'N', 364: 'N', 365: 'N', 366: 'N', 367: 'N', 368: 'N', 369: 'N', 370: 'N', 371: 'N', 372: 'N', 373: 'N', 374: 'N', 375: 'P', 376: 'N', 377: 'N', 378: 'N', 379: 'N', 380: 'N', 381: 'N', 382: 'N', 383: 'N', 384: 'N', 385: 'N', 386: 'N', 387: 'N', 388: 'N', 389: 'N', 390: 'P', 391: 'N', 392: 'N', 393: 'N', 394: 'N', 395: 'N', 396: 'N', 397: 'N', 398: 'N', 399: 'N'}\n"
          ]
        }
      ],
      "source": [
        "# Test:\n",
        "fraction_protected = 0.1  # 40% of nodes will be protected\n",
        "protection_status_dict = assign_protection(H2, fraction_protected)\n",
        "print(protection_status_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F71C7Qfa_b9I"
      },
      "source": [
        "\n",
        "## Part 3: Assign Threshold\n",
        "The following steps assigns a threshold value to each node in the network. The threshold follows a uniform or normal distribution with predefined mean (mu) and standard deviation (sigma)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ky4HFlQR_jBY"
      },
      "outputs": [],
      "source": [
        "# Defines the parameters to be used\n",
        "mu = 0.1\n",
        "sigma = 0.05\n",
        "\n",
        "# Function to assign thresholds to the individual nodes\n",
        "def assign_thresholds(hypergraph, mu, sigma):\n",
        "    NV = hypergraph.order()\n",
        "    Ltre = {}\n",
        "\n",
        "    for node in hypergraph.nodes():\n",
        "          # Uniform distribution: #\n",
        "          #Ltre[node] = np.random.uniform()\n",
        "          # Normal distrution\n",
        "          while True:\n",
        "              threshold = random.gauss(mu, sigma)\n",
        "              if 0 < threshold < 1:\n",
        "                  break\n",
        "          Ltre[node] = threshold\n",
        "\n",
        "    return Ltre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ11eyyS_o1O",
        "outputId": "c68bfb11-c8aa-40e5-a3dc-444350914932"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold List for Nodes:  {0: 0.1573237407670376, 1: 0.09867729481466483, 2: 0.08819866944560029, 3: 0.20515720094223633, 4: 0.09833775923690016, 5: 0.11578883158797713, 6: 0.13165750661803716, 7: 0.07635241421151201, 8: 0.13054058439322325, 9: 0.03894058186815716, 10: 0.07739054454871822, 11: 0.18745031007783075, 12: 0.1420520279029864, 13: 0.20420452268402345, 14: 0.06014636200309931, 15: 0.04227046405698714, 16: 0.09325068563583529, 17: 0.050025401513548826, 18: 0.09819243761863623, 19: 0.20057486299963664, 20: 0.09954474779444086, 21: 0.2267831254029059, 22: 0.06415535007048498, 23: 0.08457336323116232, 24: 0.09672525341359467, 25: 0.06680581395231502, 26: 0.12891184995999938, 27: 0.2115780789428366, 28: 0.14325428576592172, 29: 0.10451921489278787, 30: 0.15856556791974705, 31: 0.16033729010501796, 32: 0.11708518996117251, 33: 0.07014012919333383, 34: 0.06159300696793931, 35: 0.14460647591437817, 36: 0.10418631326920384, 37: 0.07365778588444807, 38: 0.05928049389828487, 39: 0.1085123488690573, 40: 0.03370928611824836, 41: 0.003884245937553904, 42: 0.055866109157756354, 43: 0.06159118238878757, 44: 0.11263534012289861, 45: 0.02671692315629308, 46: 0.14585132238314133, 47: 0.1332043541449654, 48: 0.15357663919460848, 49: 0.08879843561880152, 50: 0.16976468292440028, 51: 0.08042408609600003, 52: 0.09151133751452908, 53: 0.13508081950986997, 54: 0.12097573801757601, 55: 0.12865545880909, 56: 0.1851289988915721, 57: 0.12908938726526814, 58: 0.10288108799822977, 59: 0.18078453847432438, 60: 0.10430502095304527, 61: 0.060974628465303056, 62: 0.013540688001939541, 63: 0.07375012440521647, 64: 0.09419901925137762, 65: 0.0708326640152355, 66: 0.17169021017703062, 67: 0.12011657768351983, 68: 0.16074137880143044, 69: 0.058095784665430646, 70: 0.12398637625804632, 71: 0.11416725579645573, 72: 0.09649631402408806, 73: 0.16151337286318634, 74: 0.04021709634110421, 75: 0.14834855965957497, 76: 0.12666095879832753, 77: 0.07390865955338127, 78: 0.12047071413064152, 79: 0.07400093444536907, 80: 0.05379119107223959, 81: 0.08846995358834235, 82: 0.19634615301114833, 83: 0.04531539930064526, 84: 0.056457169458424064, 85: 0.11441101388070775, 86: 0.12287811773455942, 87: 0.10592282672596853, 88: 0.08515630038419376, 89: 0.14935163766496518, 90: 0.1709495451442833, 91: 0.07690032763512339, 92: 0.037060956415931975, 93: 0.029706006246850686, 94: 0.20502336879524777, 95: 0.08815500184474456, 96: 0.03777421394489081, 97: 0.11970795626185962, 98: 0.08706824605741317, 99: 0.08931898170558689, 100: 0.034974732689595736, 101: 0.05518088146430118, 102: 0.11159867467900692, 103: 0.13317777195194025, 104: 0.17961429762384873, 105: 0.0528097730908372, 106: 0.034964038370859526, 107: 0.1716272807329785, 108: 0.19439968884553194, 109: 0.04248989873231852, 110: 0.13505805525474263, 111: 0.043307383543315495, 112: 0.13309320579031056, 113: 0.017112843497866945, 114: 0.10893622824221161, 115: 0.009096591414282748, 116: 0.15519621417455734, 117: 0.09801704874060196, 118: 0.12082560402645406, 119: 0.1274049784012985, 120: 0.0002061644230111348, 121: 0.005044756128890729, 122: 0.15544668354603958, 123: 0.02211785144326381, 124: 0.10094593716749266, 125: 0.13061430098620108, 126: 0.13639324778435846, 127: 0.1621650677173373, 128: 0.12903979061565896, 129: 0.1655522608538017, 130: 0.07183476761534704, 131: 0.11449120634070921, 132: 0.0733404007169243, 133: 0.11580819771754167, 134: 0.10843015612172704, 135: 0.17559031931010746, 136: 0.09140911797477107, 137: 0.10074938606583939, 138: 0.07813224473701647, 139: 0.1022298786650975, 140: 0.11078167133266494, 141: 0.03807259889660456, 142: 0.07881956365377374, 143: 0.07763100656594601, 144: 0.13818663044060442, 145: 0.15088136193100463, 146: 0.14190363058375152, 147: 0.12283761783979263, 148: 0.15805457314901325, 149: 0.12830062996013106, 150: 0.09786735483236689, 151: 0.038427653014827916, 152: 0.11375652014373598, 153: 0.10556204706935368, 154: 0.06694325444772135, 155: 0.19857590543920484, 156: 0.04358147340643899, 157: 0.0669643259266165, 158: 0.1254897973256098, 159: 0.055718081438665946, 160: 0.07528800010142146, 161: 0.07729537634772576, 162: 0.10097856413463588, 163: 0.1108437138998645, 164: 0.1670917332185372, 165: 0.1281213748373846, 166: 0.09660395260744811, 167: 0.01659942694826541, 168: 0.08752270027448827, 169: 0.09526984833383229, 170: 0.027597395554484025, 171: 0.10540316341442822, 172: 0.08822912450386033, 173: 0.11303824368119607, 174: 0.09061728416017645, 175: 0.15545257705240534, 176: 0.09515171454697, 177: 0.13376500918582057, 178: 0.0466049486528598, 179: 0.19143063398997773, 180: 0.15955546467977505, 181: 0.06065173810160393, 182: 0.14173896804926284, 183: 0.09411039187841103, 184: 0.07640344985421846, 185: 0.12356926696142899, 186: 0.13535075936871532, 187: 0.18167624246678926, 188: 0.16524548188782529, 189: 0.13785027851550402, 190: 0.11075429572920757, 191: 0.001557884353785649, 192: 0.10273181065937069, 193: 0.13837188373941858, 194: 0.17252918800244854, 195: 0.08559432364131926, 196: 0.14982283994952458, 197: 0.07222004274696467, 198: 0.08586535959512506, 199: 0.13078713485193671, 200: 0.06851979300129538, 201: 0.011229334187586537, 202: 0.1591961433066104, 203: 0.007530177197549351, 204: 0.037826170925698045, 205: 0.02118826846517413, 206: 0.15012913031693706, 207: 0.050938256763716744, 208: 0.11891249294728684, 209: 0.08173096145004846, 210: 0.05293571891837581, 211: 0.17883036516037495, 212: 0.1307877922557443, 213: 0.08249193532163922, 214: 0.09702836587177179, 215: 0.10252428094547361, 216: 0.18693411704712917, 217: 0.05844191443407926, 218: 0.08210783144574213, 219: 0.07101234841161085, 220: 0.11053864638778906, 221: 0.08245453800281062, 222: 0.1728885755215837, 223: 0.1399735303214375, 224: 0.12220787335943013, 225: 0.12365837014239649, 226: 0.0806236133731589, 227: 0.1216343075434884, 228: 0.07912384318650498, 229: 0.09975088705859733, 230: 0.07730169062784213, 231: 0.10639191388325572, 232: 0.06858376605983178, 233: 0.13645690015992, 234: 0.14788825824361526, 235: 0.15366645402999565, 236: 0.14822245746060095, 237: 0.12275862330054851, 238: 0.07151498600930219, 239: 0.08708863992016588, 240: 0.138255883823522, 241: 0.10420348751180386, 242: 0.09938435813265324, 243: 0.06720310114839353, 244: 0.09073211212447271, 245: 0.11980580286885707, 246: 0.08991415665245872, 247: 0.1082736652476115, 248: 0.11140211195340555, 249: 0.1626258881543146, 250: 0.052142599462591394, 251: 0.032244848121310885, 252: 0.07400844224681115, 253: 0.11011567332394832, 254: 0.08430883734482054, 255: 0.1389115783378391, 256: 0.17793171250487574, 257: 0.1929813509436486, 258: 0.13739521604632046, 259: 0.17494954608217683, 260: 0.10176143827752894, 261: 0.10018354868539427, 262: 0.15978551569533683, 263: 0.08371449256613608, 264: 0.12724116926568563, 265: 0.17563439859100968, 266: 0.18013170624170388, 267: 0.11881443249842046, 268: 0.07958473498864557, 269: 0.030720119038784202, 270: 0.1466333335773632, 271: 0.05709436493182309, 272: 0.03246050905076717, 273: 0.07891299685830402, 274: 0.13403765886065008, 275: 0.11931807416374327, 276: 0.14479153620263296, 277: 0.07154146517572275, 278: 0.08909442025945961, 279: 0.07893773061023267, 280: 0.10068743770174259, 281: 0.14710725538063096, 282: 0.06101773159118299, 283: 0.12353877699480487, 284: 0.05956424781322425, 285: 0.06992104386776953, 286: 0.13324138912200173, 287: 0.04999466197967076, 288: 0.05306228722400697, 289: 0.15084327187999758, 290: 0.09850092400587526, 291: 0.11973135040182242, 292: 0.0743723323091155, 293: 0.03818702246645546, 294: 0.15226227401158013, 295: 0.13562983110704485, 296: 0.12521321912668976, 297: 0.12016442654372808, 298: 0.08093314772700898, 299: 0.02022933791445132, 300: 0.1271520266256097, 301: 0.005211662682769874, 302: 0.09989671526064973, 303: 0.04566260439947735, 304: 0.10859922272327363, 305: 0.08181609969549686, 306: 0.12490373908153661, 307: 0.038956983704826025, 308: 0.21270798843872704, 309: 0.22314454476262321, 310: 0.1380152012905856, 311: 0.06356749985285914, 312: 0.10407048053066442, 313: 0.13419191497765293, 314: 0.06098755408024155, 315: 0.07443022456739709, 316: 0.16518575156725446, 317: 0.15122908648675526, 318: 0.0635855045067947, 319: 0.1741841374770978, 320: 0.059666993707468814, 321: 0.13289837588012698, 322: 0.0884663279978258, 323: 0.15604723627334138, 324: 0.10341966189393255, 325: 0.06884128914534302, 326: 0.10495071784983631, 327: 0.11640560078028807, 328: 0.12183494154434626, 329: 0.1186401408828086, 330: 0.12432305738478916, 331: 0.07976829580048092, 332: 0.11971142936741888, 333: 0.06731179877247223, 334: 0.10630305750270722, 335: 0.06076877241195804, 336: 0.13409279248389588, 337: 0.15871355840089602, 338: 0.13247181805943098, 339: 0.02370798536401432, 340: 0.11865196430067446, 341: 0.028271728935412507, 342: 0.14550117915570313, 343: 0.1242677269576034, 344: 0.1384458034851354, 345: 0.11615432370724384, 346: 0.1718198220556008, 347: 0.10703510180910948, 348: 0.03251263263140579, 349: 0.03882620195148101, 350: 0.049892374765184405, 351: 0.04477693602324992, 352: 0.13055894429121656, 353: 0.136772670241604, 354: 0.07186724224009078, 355: 0.10049620139325713, 356: 0.024482757208532074, 357: 0.11976934419616951, 358: 0.1667943201392077, 359: 0.058544343369543894, 360: 0.14286318502327952, 361: 0.14113888376634742, 362: 0.15596076923561503, 363: 0.09128502720140873, 364: 0.09786993379259284, 365: 0.1648668525519425, 366: 0.0560067235824471, 367: 0.09770991673507282, 368: 0.16999974826311676, 369: 0.01685174582975961, 370: 0.10703808537579255, 371: 0.08407642759796459, 372: 0.10383051996505129, 373: 0.060887356019488095, 374: 0.09656338677144637, 375: 0.06997292313657377, 376: 0.005296577539046082, 377: 0.13732496242323064, 378: 0.132307732082119, 379: 0.056505325676349055, 380: 0.13308081144956035, 381: 0.04734362272630023, 382: 0.0994859144844498, 383: 0.05087073329443895, 384: 0.051529755833126245, 385: 0.05856572292242672, 386: 0.11673974458866818, 387: 0.041289276690854096, 388: 0.08547955713328151, 389: 0.16694992627015431, 390: 0.07555025393225238, 391: 0.04027474369842139, 392: 0.058064196906223144, 393: 0.022611190532874026, 394: 0.10393517373043443, 395: 0.10073799288850588, 396: 0.20895713768525256, 397: 0.1366392093806653, 398: 0.09896675599069923, 399: 0.08412054953828596}\n"
          ]
        }
      ],
      "source": [
        "Ltre2 = assign_thresholds(H2, mu, sigma)\n",
        "\n",
        "print(\"Threshold List for Nodes: \", Ltre2 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSmz7Gj6AA9m"
      },
      "source": [
        "# Part 4: The ICE Model (The Information Cognition Epidemics Model)\n",
        "## Information Layer\n",
        "The misinformation spread occurs on a hyperedge network involving group spreading. The three stages are U(unaware), G(gossip/spreader), and C(stifler/corrected).  \n",
        "\n",
        "## Cognition Layer\n",
        "In the cognitive behavioral layer, P is protected, and N is not protected. The rate of transition from state P to N, p, depends on the information layer. The rate from NP to P is 1-p. The transition rate of a node is also affected by the number of active spreader/stiflers. The bigger number of active neighbors, the faster the rate. Another way behavior may change is based on the fraction of protected neighbors.\n",
        "\n",
        "## Epidemics Layer\n",
        "In the epidemics layer, the possible disease states are S(susceptible), I(infected), and R(recovered). The illness spreading is pairwise. The disease propagation rate depends on the fraction of protected individuals $\\rho_P$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3rNTHw7F-6v",
        "outputId": "eeccebef-5e37-420b-9582-ad331e1300d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "def ICE_model_no_control(inw, ldeg_i, ltre, cnw, ldeg_c, lprot, enw, ldeg_e, lam, alp, zeta_1, zeta_2, zeta_3, zeta_4, beta_PP, beta_NP, beta_PN, beta_NN, mu, n_sample):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "      inw - information hyperedge network\n",
        "      ltre - list of thresholds for informaiton spread\n",
        "      ldeg_i - degree sequence of information layer\n",
        "\n",
        "      cnw - cognitive network\n",
        "      lprot - list of protection status\n",
        "      ldeg_c - degree sequence of cognition layer\n",
        "\n",
        "      enw - epidemic pairwise network\n",
        "      ldeg_e - degree sequence of epidemic layer\n",
        "\n",
        "      lambda - information spreading rate\n",
        "      alp - informaiton stifling rate\n",
        "\n",
        "      zeta_1 - removing protection rate based on information\n",
        "      zeta_2 - removing protection rate based on neighborhood behavior\n",
        "      zeta_1 - adopting protection rate based on information\n",
        "      zeta_2 - adopting protection rate based on neighborhood behavior\n",
        "\n",
        "      beta_PP - disease transmission rate between protected S and protected I\n",
        "      beta_NP - disease transmission rate between not protected S and protected I\n",
        "      beta_PN - disease transmission rate between protected S and not protected I\n",
        "      beta_NN - disease transmission rate between not protected S and not protected I\n",
        "\n",
        "      mu - disease recovery rate\n",
        "\n",
        "      n_sample - number of samples\n",
        "  \"\"\"\n",
        "\n",
        "  t_max = 1000      # Set maximum time\n",
        "  kmax_i = max (ldeg_i)     # Get maximum hyperedge degree in information layer\n",
        "  kmax_c = max (ldeg_c)     # Get maximum hyperedge degree in cognition layer\n",
        "  kmax_e = max (ldeg_e)     # Get maximum degree in epidemic layer\n",
        "  N = inw.order()  # Get the network size\n",
        "\n",
        "  rho_C = []   # Keep track of fraction of corrected in information layer\n",
        "  rho_P = []   # Keep track of fraction of protected in cognition layer\n",
        "  rho_R = []   # Keep track of fraction of recovered in epidemic layer\n",
        "\n",
        "  for i_samp in range(1, n_sample + 1):\n",
        "      t = 0                 # Initialize time, number of corrected, number of recovered\n",
        "      N_corrected = 0\n",
        "      N_recovered = 0\n",
        "\n",
        "      info_states = {j: \"U\" for j in inw.nodes()}   # Initialize information and disease states\n",
        "      disease_states = {k: \"S\" for k in enw.nodes()}\n",
        "\n",
        "      protected = list(filter(lambda node: lprot[node] == \"P\", lprot))\n",
        "      N_protected = len(protected)\n",
        "      not_protected = list(filter(lambda node: lprot[node] == \"N\", lprot))\n",
        "\n",
        "\n",
        "      gossip = []     # Create lists to store gossip and corrected individuals in information layer\n",
        "      corrected = []\n",
        "\n",
        "      rumor_node_0 = np.random.choice(list(inw.nodes()))   # Pick a random person to start misinformaiton spreading\n",
        "      info_states[rumor_node_0] = \"G\"\n",
        "      gossip.append(rumor_node_0)\n",
        "      N_gossip = 1\n",
        "      N_e_i = inw.degree(rumor_node_0)\n",
        "\n",
        "      infected = []     # Create lists to store infected and recovered individuals in epidemic layer\n",
        "      recovered = []\n",
        "\n",
        "      ill_node_0 = np.random.choice(list(enw.nodes()))   # Pick a random person to start disease spreading\n",
        "      disease_states[ill_node_0] = \"I\"\n",
        "      infected.append(ill_node_0)\n",
        "      N_infected = 1\n",
        "      N_e_e = enw.degree(ill_node_0)\n",
        "\n",
        "      while N_gossip > 0:   # We stop when there is no infection and no gossip\n",
        "          total_rate = lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected + zeta_1 * N_protected + zeta_2 * (N-N_protected) + zeta_3 * N_protected + zeta_4 * (N-N_protected)\n",
        "          tau = -np.log(np.random.uniform(1e-6, 1)) / total_rate\n",
        "          t += tau\n",
        "\n",
        "          if t >= t_max:\n",
        "                break\n",
        "\n",
        "          # Determine which event occurs\n",
        "          event = np.random.uniform()\n",
        "          p1 = (lam * N_e_i) / total_rate     # rumor spreading\n",
        "          p2 = (lam * N_e_i + alp * N_e_i) / total_rate  # rumor stifling (by meeting stifling neighbor threshold)\n",
        "          p3 = (lam * N_e_i + 2 * alp * N_e_i) / total_rate  # rumor stifling (by meeting gossip neighbor threshold)\n",
        "\n",
        "          p4 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e) / total_rate  # disease propagation\n",
        "          p5 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected) / total_rate  # disease recovery\n",
        "\n",
        "          p6 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected + zeta_1 * N_protected) / total_rate # change to not adopting protection by information\n",
        "          p7 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected + zeta_1 * N_protected + zeta_2 * (N-N_protected) ) / total_rate # change to adopting protection by information\n",
        "          p8 = (lam * N_e_i + 2 * alp * N_e_i + beta_NN * N_e_e + mu * N_infected + zeta_1 * N_protected + zeta_2 * (N-N_protected)  + zeta_3 * N_protected) / total_rate # change to not adopting protection by neighborhood behavior\n",
        "          # > p8 # change to adopting protection by neighborhood behavior\n",
        "          #print(p1, p2, p3, p4, p5, p6, p7, p8)\n",
        "\n",
        "          # Determine if accept selected individual based on degree distribution\n",
        "          q_deg_i = np.random.uniform()\n",
        "          q_deg_c = np.random.uniform()\n",
        "          q_deg_e = np.random.uniform()\n",
        "\n",
        "          # Case 1: Rumor spreading\n",
        "          if event < p1:\n",
        "                gossip_node = random.choice(gossip)\n",
        "                if q_deg_i < inw.degree(gossip_node) / kmax_i:\n",
        "                    rumor_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                    neighbors = inw[rumor_hyper_edge]\n",
        "                    \"\"\"\n",
        "                    while gossip_node not in neighbors:\n",
        "                        rumor_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                        neighbors = inw[rumor_hyper_edge]\n",
        "                    \"\"\"\n",
        "                    MAX_ITERATIONS = 20 # Set a reasonable limit based on your specific case\n",
        "                    iterations = 0\n",
        "                    while gossip_node not in neighbors:\n",
        "                        if iterations > MAX_ITERATIONS:\n",
        "                           break\n",
        "                        rumor_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                        neighbors = inw[rumor_hyper_edge]\n",
        "                        iterations += 1\n",
        "\n",
        "                    for neighbor in neighbors:\n",
        "                            if info_states[neighbor] == \"U\":\n",
        "                                count_gossip_neighbors = sum(1 for node in inw.neighbors(neighbor) if info_states[node] == \"G\")\n",
        "                                if count_gossip_neighbors / len(inw.neighbors(neighbor)) >= ltre[neighbor]:\n",
        "                                    info_states[neighbor] = \"G\"  # uninformed neighbor becomes gossip spreader\n",
        "                                    gossip.append(neighbor)\n",
        "                                    N_gossip += 1\n",
        "\n",
        "\n",
        "\n",
        "          # Case 2: Rumor stifling (by meeting stifling neighbor threshold)\n",
        "          elif event < p2:\n",
        "            #if N_gossip > 0:\n",
        "                stifler_node = np.random.choice(gossip)\n",
        "                if q_deg_i < inw.degree(stifler_node)  / kmax_i:\n",
        "                    stifler_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                    neighbors = inw[stifler_hyper_edge]\n",
        "                    count_stifler_neighbors = sum(1 for node in inw.neighbors(stifler_node) if info_states[node] == \"C\")\n",
        "                    if count_stifler_neighbors / len(neighbors) >= 0.3: # New rule #2 for recovery\n",
        "                    #neighbor = np.random.choice(neighbors) # New rule for recovery\n",
        "                    #if info_states[neighbor==\"C\"]:\n",
        "                            info_states[stifler_node] = \"C\"\n",
        "                            N_gossip -= 1\n",
        "                            gossip.remove(stifler_node)\n",
        "                            corrected.append(stifler_node)\n",
        "                            N_corrected += 1\n",
        "\n",
        "          # Case 3: Rumor stifling (by meeting gossip neighbor threshold)\n",
        "          elif event < p3:\n",
        "            #if N_gossip > 0:\n",
        "                stifler_node = np.random.choice(gossip)\n",
        "                if q_deg_i < inw.degree(stifler_node) / kmax_i:\n",
        "                    stifler_hyper_edge = np.random.choice(list(inw.edges()))\n",
        "                    neighbors = inw[stifler_hyper_edge]\n",
        "                    count_gossip_neighbors = sum(1 for node in inw.neighbors(stifler_node) if info_states[node] == \"G\")\n",
        "                    if count_gossip_neighbors / len(neighbors) >= 0.3: # New rule #2 for recovery\n",
        "                    #neighbor = np.random.choice(neighbors) # New rule for recovery\n",
        "                    #if info_states[neighbor==\"G\"]:\n",
        "                            info_states[stifler_node] = \"C\"\n",
        "                            N_gossip -= 1\n",
        "                            gossip.remove(stifler_node)\n",
        "                            corrected.append(stifler_node)\n",
        "                            N_corrected += 1\n",
        "\n",
        "          # Case 4: Disease propagation\n",
        "          elif event < p4:\n",
        "            if N_infected > 0:\n",
        "              infected_node = np.random.choice(infected)\n",
        "              infected_protected = lprot[infected_node]\n",
        "              neighbors = list(enw.neighbors(infected_node))\n",
        "              susceptible_neighbors = [n for n in neighbors if disease_states[n] == \"S\"]\n",
        "\n",
        "              if len(susceptible_neighbors) > 0:\n",
        "                  neighbor = np.random.choice(susceptible_neighbors)\n",
        "                  neighbor_protected = lprot[neighbor]\n",
        "\n",
        "                  # Determine the appropriate transmission rate based on protection status\n",
        "                  if neighbor_protected == \"P\" and infected_protected == \"P\":\n",
        "                            transmission_rate = beta_PP/beta_NN\n",
        "                  elif neighbor_protected == \"N\" and infected_protected == \"P\":\n",
        "                            transmission_rate = beta_NP/beta_NN\n",
        "                  elif neighbor_protected == \"P\" and infected_protected == \"N\":\n",
        "                            transmission_rate = beta_PN/beta_NN\n",
        "                  else:\n",
        "                            transmission_rate = beta_NN/beta_NN\n",
        "\n",
        "                  if np.random.uniform() < transmission_rate:\n",
        "                      disease_states[neighbor] = \"I\"\n",
        "                      infected.append(neighbor)\n",
        "                      N_infected += 1\n",
        "                      N_e_e += enw.degree(neighbor)\n",
        "\n",
        "          # Case 5: Disease recovery\n",
        "          elif event < p5:\n",
        "            if N_infected > 0:\n",
        "                recovered_node = np.random.choice(infected)\n",
        "                if q_deg_e < ldeg_e[recovered_node]/kmax_e:\n",
        "                    disease_states[recovered_node] = \"R\"\n",
        "                    infected.remove(recovered_node)\n",
        "                    recovered.append(recovered_node)\n",
        "                    N_infected -= 1\n",
        "                    N_recovered += 1\n",
        "                    N_e_e -= enw.degree(recovered_node)\n",
        "\n",
        "\n",
        "          # Case 6: # Change to not adopting protection based on information layer\n",
        "          # rate = zeta_1 * n_G / k_info\n",
        "          # n_G is the total spreader neighbors on the information layer,\n",
        "          # while k_info is the total neighbor count on the information layer\n",
        "          elif event < p6:\n",
        "            if len(protected) > 0:\n",
        "              node_to_not_protect = np.random.choice(protected)\n",
        "              n_G = sum(1 for node in filter(lambda x: info_states[x] == \"G\", inw.neighbors(node_to_not_protect)))\n",
        "              k_info = len(list(inw.neighbors(node_to_not_protect)))\n",
        "              if np.random.uniform() < zeta_1 * n_G / k_info:\n",
        "                    lprot[node_to_not_protect] = \"N\"\n",
        "                    protected.remove(node_to_not_protect)\n",
        "                    not_protected.append(node_to_not_protect)\n",
        "                    N_protected -= 1\n",
        "\n",
        "          # Case 7: Change to adopting protection based on information layer\n",
        "          # rate = zeta_2 * (1 - n_G / k_info)\n",
        "          elif event < p7:\n",
        "            if len(not_protected) > 0:\n",
        "                node_to_protect = np.random.choice(not_protected)\n",
        "                n_G = sum(1 for node in filter(lambda x: info_states[x] == \"G\", inw.neighbors(node_to_protect)))\n",
        "                k_info = len(list(inw.neighbors(node_to_protect)))\n",
        "                if np.random.uniform() < zeta_2 * (1 - n_G / k_info):\n",
        "                        lprot[node_to_protect] = \"P\"\n",
        "                        not_protected.remove(node_to_protect)\n",
        "                        protected.append(node_to_protect)\n",
        "                        N_protected += 1\n",
        "\n",
        "\n",
        "          # Case 8: # Change to not adopting protection based on neighborhood behavior in cognition layer\n",
        "          # rate = zeta_3 * (1 - n_P / k_cog)\n",
        "          # n_P is the total protected neighbors on the cognition layer,\n",
        "          # while k_cog is the total neighbor count on the cognition layer\n",
        "          elif event < p8:\n",
        "            if len(protected) > 0:\n",
        "                node_to_not_protect = np.random.choice(protected)\n",
        "                n_P = sum(1 for node in filter(lambda x: lprot[x] == \"P\", cnw.neighbors(node_to_not_protect)))\n",
        "                k_cog = len(list(cnw.neighbors(node_to_not_protect)))\n",
        "                if np.random.uniform() < zeta_3 * (1 - n_P / k_cog):\n",
        "                        lprot[node_to_not_protect] = \"N\"\n",
        "                        protected.remove(node_to_not_protect)\n",
        "                        not_protected.append(node_to_not_protect)\n",
        "                        N_protected -= 1\n",
        "\n",
        "\n",
        "          # Case 9: # Change to adopting protection based on neighborhood behavior in cognition layer\n",
        "          # rate = zeta_4 * n_P / k_cog\n",
        "          else:\n",
        "            if len(not_protected) > 0:\n",
        "                node_to_protect = np.random.choice(not_protected)\n",
        "                n_P = sum(1 for node in filter(lambda x: lprot[x] == \"P\", cnw.neighbors(node_to_protect)))\n",
        "                k_cog = len(list(cnw.neighbors(node_to_protect)))\n",
        "                if np.random.uniform() < zeta_4 * n_P / k_cog:\n",
        "                        lprot[node_to_protect] = \"P\"\n",
        "                        not_protected.remove(node_to_protect)\n",
        "                        protected.append(node_to_protect)\n",
        "                        N_protected += 1\n",
        "\n",
        "      #print(\"N_infected\", N_infected, \"N_gossip\", N_gossip)\n",
        "      if N_infected == 0:\n",
        "          corrected_frac = N_corrected / N\n",
        "          protected_frac = N_protected / N\n",
        "          recovered_frac = N_recovered / N\n",
        "          rho_C.append(corrected_frac)\n",
        "          rho_P.append(protected_frac)\n",
        "          rho_R.append(recovered_frac)\n",
        "          #print(\"corrected_frac\", corrected_frac, \"recovered_frac\", recovered_frac)\n",
        "\n",
        "  avg_rho_C = sum(rho_C) / len(rho_C)\n",
        "  avg_rho_P = sum(rho_P) / len(rho_P)\n",
        "  avg_rho_R = sum(rho_R) / len(rho_R)\n",
        "\n",
        "  return avg_rho_C, avg_rho_P, avg_rho_R\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_NnnBI-BZpo",
        "outputId": "25c869f2-e4c8-4812-8e57-0c66a4ed094b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Degree Sequence:  [5, 8, 3, 3, 3, 20, 5, 3, 3, 4, 4, 3, 6, 3, 5, 4, 4, 4, 8, 8, 6, 8, 3, 3, 9, 3, 6, 3, 3, 3, 4, 4, 3, 5, 3, 5, 4, 3, 5, 5, 4, 5, 12, 3, 3, 3, 9, 5, 3, 3, 3, 4, 15, 4, 3, 4, 6, 3, 3, 7, 3, 4, 5, 11, 3, 5, 4, 5, 5, 4, 12, 3, 5, 8, 3, 4, 15, 3, 5, 4, 3, 3, 7, 5, 5, 4, 3, 3, 3, 4, 3, 5, 4, 11, 13, 4, 8, 4, 5, 3, 3, 3, 5, 4, 7, 8, 6, 3, 4, 3, 4, 6, 7, 4, 5, 3, 3, 4, 3, 4, 3, 3, 3, 3, 3, 16, 5, 3, 4, 17, 3, 6, 4, 3, 4, 6, 3, 9, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
            "Hyper Edge Sizes:  [32, 21, 22, 5, 38, 22, 36, 26, 36, 23, 6, 35, 5, 10, 18, 30, 6, 28, 12, 26, 13, 8, 2, 31, 11, 26, 8, 24, 37, 9, 31, 35, 37, 16, 27, 8, 11, 18, 13, 19, 23, 31, 18, 2, 16, 16, 32, 10, 23, 37, 10, 31, 27, 36, 23, 38, 32, 10, 6, 15, 12, 15, 5, 22, 34, 16, 36, 13, 13, 21, 34, 21, 11, 3, 38, 31, 8, 9, 30, 30, 31, 23, 4, 27, 35, 10, 29, 25, 3, 14, 4, 16, 14, 19, 11, 21, 2, 31, 24, 8]\n",
            "Hypergraph Dictionary:  {7: [0, 12, 18, 20, 23, 73, 102, 103, 132, 138, 171, 185, 209, 211, 214, 217, 243, 254, 278, 321, 366, 377], 21: [0, 62, 87, 114, 152, 158, 303, 398], 53: [0, 33, 52, 78, 119, 125, 129, 168, 178, 206, 208, 213, 250, 276, 290, 337, 357, 360, 372], 66: [0, 8, 33, 34, 38, 42, 76, 84, 87, 102, 107, 110, 113, 166, 185, 235, 268, 274, 323, 359], 68: [0, 70, 111, 114, 122, 131, 221, 256, 260, 285, 354, 385], 31: [1, 5, 6, 14, 21, 26, 45, 49, 74, 76, 79, 80, 87, 99, 105, 112, 148, 165, 223, 224, 231, 262, 282, 299, 335, 336, 374, 382], 55: [1, 11, 33, 36, 38, 52, 63, 70, 83, 96, 129, 137, 141, 145, 180, 183, 198, 215, 219, 228, 232, 274, 287, 307, 347, 394], 10: [1, 70, 81, 312, 366], 13: [1, 16, 56, 64, 108, 168, 187, 216, 351], 42: [1, 35, 46, 83, 117, 125, 149, 221, 280, 289, 349, 377, 383, 396], 46: [1, 12, 17, 37, 51, 73, 94, 107, 112, 127, 166, 181, 227, 263, 270, 309, 328, 331, 358, 386, 390, 398], 27: [1, 26, 30, 48, 63, 106, 109, 110, 134, 139, 158, 248, 255, 281, 298], 94: [1, 24, 175, 186, 225, 288, 325, 369, 385], 98: [2, 5, 9, 48, 80, 94, 95, 102, 112, 179, 254, 259, 291, 310, 325, 334, 347, 398], 45: [2, 4, 5, 29, 66, 121, 124, 165, 176, 207, 250], 8: [2, 10, 12, 34, 36, 45, 61, 62, 70, 78, 92, 97, 103, 105, 143, 167, 169, 191, 202, 211, 217, 244, 246, 283, 307, 370, 375, 380, 391, 396], 93: [3, 21, 90, 95, 106, 137, 140, 162, 194, 200, 202, 205, 222, 234, 249, 361, 389], 17: [3, 4, 23, 24, 33, 42, 58, 70, 76, 156, 160, 164, 172, 182, 224, 229, 258, 277, 290, 317, 363, 376], 24: [3, 13, 70, 93, 170, 192, 264, 293, 340, 378], 69: [4, 21, 26, 36, 100, 129, 131, 155, 201, 203, 278, 338, 363], 25: [5, 8, 13, 21, 24, 27, 47, 52, 53, 59, 75, 76, 129, 137, 160, 161, 176, 226, 251, 264, 308, 327, 355], 44: [5, 54, 94, 95, 99, 111, 116, 155, 193, 237, 258, 275, 339, 343, 360], 41: [5, 25, 52, 65, 70, 73, 107, 125, 126, 128, 129, 133, 173, 183, 195, 198, 233, 278, 306, 333, 334, 368, 375], 30: [5, 21, 24, 39, 55, 59, 76, 93, 117, 120, 139, 143, 175, 177, 186, 225, 230, 238, 305, 315, 354, 381], 48: [5, 9, 14, 18, 31, 69, 104, 117, 201, 261, 273, 276, 339, 360, 395], 6: [5, 19, 24, 43, 60, 82, 98, 105, 112, 125, 134, 147, 161, 170, 217, 230, 239, 252, 253, 257, 271, 301, 303, 308, 314, 330, 373], 1: [5, 31, 52, 83, 92, 94, 125, 194, 228, 277, 287, 369, 370, 386], 84: [5, 16, 18, 47, 59, 65, 68, 125, 128, 137, 140, 151, 168, 177, 196, 222, 230, 269, 272, 288, 293, 295, 315, 336, 348, 373, 375], 4: [5, 6, 18, 19, 24, 25, 52, 57, 59, 64, 111, 116, 125, 137, 142, 159, 209, 244, 289, 292, 300, 313, 330, 336, 352, 361, 384, 390], 86: [5, 15, 22, 30, 35, 40, 52, 53, 85, 90, 98, 115, 128, 135, 174, 194, 204, 215, 220, 233, 293, 309, 359, 380, 397], 89: [5, 41, 71, 100, 136, 181, 207, 251, 298], 36: [5, 163, 180, 206, 244, 342, 356, 387], 11: [5, 20, 41, 44, 73, 86, 88, 89, 104, 125, 126, 135, 154, 162, 178, 184, 221, 234, 237, 245, 289, 305, 316, 333, 341, 354], 70: [5, 9, 33, 38, 63, 76, 81, 91, 93, 94, 102, 105, 106, 129, 145, 153, 158, 188, 201, 208, 240, 277, 280, 285, 322, 344, 386, 387, 395], 23: [5, 12, 27, 51, 85, 126, 129, 135, 144, 150, 209, 224, 226, 242, 243, 260, 282, 297, 301, 344, 364, 376, 399], 74: [5, 7, 40, 56, 61, 65, 72, 79, 109, 111, 119, 125, 189, 190, 193, 196, 211, 254, 268, 281, 308, 325, 329, 358, 363, 367, 394], 32: [5, 19, 22, 29, 46, 51, 55, 67, 88, 93, 97, 149, 174, 180, 204, 205, 220, 247, 267, 295, 303, 332, 345, 349, 353, 367, 382], 49: [6, 7, 8, 20, 34, 35, 41, 42, 67, 84, 101, 129, 138, 147, 154, 161, 193, 213, 229, 286, 300, 306, 380, 391, 397], 64: [6, 15, 19, 44, 45, 49, 60, 62, 72, 78, 108, 109, 119, 120, 123, 147, 192, 214, 236, 245, 253, 256, 312, 316, 318, 324, 348, 352], 54: [6, 14, 37, 39, 54, 82, 93, 104, 163, 200, 239, 265, 275, 279, 320, 331, 345, 365], 63: [7, 15, 38, 57, 76, 84, 151, 157, 187, 223, 225, 231, 241, 243, 271, 291, 304, 315, 362, 379], 52: [9, 24, 50, 76, 80, 94, 96, 112, 132, 141, 148, 270, 295, 334, 339, 373, 381, 390], 75: [10, 18, 20, 36, 42, 52, 66, 159, 198, 232, 240, 265, 311, 312, 319, 320, 321, 327, 338, 340, 362, 365], 56: [10, 20, 30, 35, 65, 73, 79, 82, 95, 97, 111, 116, 142, 157, 160, 192, 218, 226, 261, 318, 322, 370, 383], 97: [10, 40, 42, 52, 53, 59, 64, 75, 94, 99, 103, 108, 110, 117, 129, 133, 134, 238, 263, 284, 286, 297, 322, 376, 394], 78: [11, 20, 22, 46, 52, 56, 72, 74, 79, 103, 125, 136, 142, 164, 241, 269, 304, 318, 335, 351, 365], 26: [11, 66, 214, 319, 321, 335], 38: [12, 30, 42, 69, 94, 197, 207, 242, 332, 355], 39: [12, 27, 46, 55, 112, 118, 127, 132, 137, 163, 218, 266, 294, 299, 378], 37: [13, 17, 23, 58, 74, 77, 82, 96, 104, 154, 184, 385], 81: [14, 21, 52, 81, 91, 129, 130, 132, 196, 257, 268, 294, 296, 317, 320], 51: [14, 26, 41, 68, 77, 136, 165, 169, 172, 173, 175, 178, 203, 204, 215, 216, 229, 260, 279, 284, 333, 364, 374], 83: [15, 16, 19, 39, 48, 52, 54, 55, 57, 61, 92, 113, 124, 129, 167, 208, 266, 319, 357], 65: [16, 62, 63, 108, 118, 129, 169, 274, 317, 330, 374], 90: [17, 63, 131], 5: [17, 25, 66, 125, 135, 167, 189, 199, 236, 264, 272, 273, 283, 296, 302, 313, 314], 15: [18, 19, 42, 46, 47, 52, 61, 70, 78, 82, 83, 94, 102, 104, 120, 124, 129, 212, 247, 257, 279, 324, 337, 346, 368, 369, 393], 92: [18, 76, 94, 121, 231, 233, 287, 292, 384], 99: [18, 21, 50, 69, 267, 311, 337], 72: [19, 26, 68, 172, 191, 346, 350], 87: [19, 32, 62, 67, 69, 129, 131, 137, 140, 144, 185, 188, 227, 329, 349, 351, 389, 392], 2: [21, 29, 46, 94, 106, 135, 144, 164, 247, 252, 253, 271, 273, 306, 331, 379, 399], 95: [24, 110, 123, 125, 130, 133, 187, 246, 310, 350, 378, 392, 397], 91: [24, 52, 63, 76, 93, 98, 188, 191, 195, 309, 324, 344, 379], 73: [26, 42, 60], 79: [28, 31, 32, 49, 76, 82, 83, 85, 94, 105, 113, 114, 134, 146, 151, 181, 210, 255, 294, 299, 353], 80: [28, 32, 63, 70, 75, 100, 114, 126, 152, 179, 182, 190, 212, 218, 249, 265, 272, 311, 326, 329, 371], 9: [28, 70, 93, 101, 205, 234, 259, 304, 338, 350, 352, 357, 388, 399], 57: [31, 101, 137, 176, 249, 355], 28: [35, 63, 70, 72, 104, 119, 125, 126, 146, 156, 177, 179, 222, 261, 262, 300, 328, 347, 383, 384], 40: [37, 42, 50, 70, 73, 84, 90, 96, 114, 122, 150, 200, 223, 282, 290, 323, 326, 327, 368, 372], 0: [38, 40, 47, 56, 59, 89, 94, 96, 123, 128, 129, 171, 189, 197, 199, 232, 241, 258, 297, 326, 382, 392], 14: [39, 52, 76, 82, 113, 135, 197, 239, 248, 251, 285, 305], 61: [39, 46, 91, 96, 97, 106, 121, 125, 216, 269, 341, 345], 20: [41, 58, 65, 75, 91, 105, 153, 162, 213, 235, 245, 328], 47: [42, 67, 71, 89, 98, 267], 33: [42, 68, 93, 248, 262, 283, 296, 298, 314, 359], 71: [42, 51, 63, 68, 93, 105, 125, 141, 157, 166, 219, 266, 284, 371, 388], 59: [43, 46, 96, 115, 150, 174, 250, 288, 302, 341, 361, 393], 18: [43, 76, 85, 145, 184, 236, 301, 396], 29: [44, 59, 105, 111, 131, 242, 246], 19: [46, 67, 92, 104, 139, 156, 170, 173, 186, 220, 270, 291, 323, 332, 343, 346, 353, 356, 381, 387, 388, 393], 82: [47, 125, 131, 362], 76: [53, 89, 115, 148, 281, 358], 85: [56, 93, 130, 138, 155, 190, 203, 235, 252], 50: [56, 106, 143, 171, 256, 280, 371], 43: [63], 12: [63, 88, 122, 348], 35: [71, 137, 182, 219], 34: [72, 73, 86, 93, 129, 149, 153, 199, 202, 237, 238, 255, 263, 286, 310, 313, 340, 366, 367, 372], 67: [73, 86, 91, 212, 259, 275, 276, 391], 16: [76, 127, 206, 210, 307], 60: [76, 84, 112, 129, 146, 152, 183, 195, 342, 364], 77: [77, 78, 96, 210, 240, 316, 377], 58: [98, 292, 389, 395], 3: [118, 159, 356], 62: [227, 302, 342], 88: [228], 96: [343]}\n",
            "Acceptance Threshold Sequence:  {0: 0.14522544073310448, 1: 0.045971623215439045, 2: 0.1230170765229372, 3: 0.05311272063998865, 4: 0.12268034289026479, 5: 0.06231689182936961, 6: 0.12007091411367746, 7: 0.1551599625321409, 8: 0.1268985675050826, 9: 0.04807493870587525, 10: 0.11012361098541085, 11: 0.13013195404563163, 12: 0.11407318913501382, 13: 0.08992626405434334, 14: 0.12301330248503393, 15: 0.041450879856945205, 16: 0.04493897130051652, 17: 0.09111508206154327, 18: 0.17851528553410015, 19: 0.1139104365157294, 20: 0.08357416037908148, 21: 0.08414347902894734, 22: 0.1080301588823854, 23: 0.11444638635760884, 24: 0.11471714973925, 25: 0.11210377410637143, 26: 0.03238000614188456, 27: 0.0755586820713909, 28: 0.05228823634317159, 29: 0.1571828439030642, 30: 0.08078568702287142, 31: 0.09332215194852454, 32: 0.1476040974775973, 33: 0.09544925513662085, 34: 0.13983712634143666, 35: 0.018734814429257424, 36: 0.0655921683941981, 37: 0.14308690881760552, 38: 0.11760470836499473, 39: 0.11089304427598554, 40: 0.1484098620751269, 41: 0.12815607976813972, 42: 0.13545066227863076, 43: 0.10026212569112891, 44: 0.20269587496325336, 45: 0.12398017411732302, 46: 0.08096724099845094, 47: 0.20896696277396107, 48: 0.09817191647216614, 49: 0.14156426842770614, 50: 0.05788842990101706, 51: 0.16639956236205705, 52: 0.040799648473475184, 53: 0.08767534131411327, 54: 0.05917012511496582, 55: 0.16739594368221378, 56: 0.12835899775722845, 57: 0.05982922650831923, 58: 0.11796774396379767, 59: 0.028951587947816493, 60: 0.1334222819572373, 61: 0.08652159784778254, 62: 0.08706578442881815, 63: 0.05986072411959647, 64: 0.07785785157307334, 65: 0.06744641744140645, 66: 0.08160542397890702, 67: 0.1804958414229728, 68: 0.0866501921549471, 69: 0.12101061164628092, 70: 0.053885367376640764, 71: 0.018256946899047194, 72: 0.09046912926641157, 73: 0.13754424821255973, 74: 0.1440873347937303, 75: 0.06712932963639091, 76: 0.11191290564050088, 77: 0.03132238621876303, 78: 0.08632901724006982, 79: 0.09958570404481643, 80: 0.1095041769360197, 81: 0.08827847759099285, 82: 0.13872703338757045, 83: 0.1852590338399871, 84: 0.07870872119741139, 85: 0.027722000929611648, 86: 0.10362860707013616, 87: 0.06480943584653465, 88: 0.16610830339502242, 89: 0.09823473540753663, 90: 0.03145041222792265, 91: 0.09035841783312304, 92: 0.08976691008515336, 93: 0.08192209672465109, 94: 0.0727687553790093, 95: 0.04188717289294594, 96: 0.14269499023175886, 97: 0.08772810180541647, 98: 0.07655889343105883, 99: 0.05335468824099357, 100: 0.13921737288761943, 101: 0.024603226130399086, 102: 0.08625643634906094, 103: 0.0531630320824602, 104: 0.008751535779613157, 105: 0.14345152575204262, 106: 0.161389512559153, 107: 0.0874703961946264, 108: 0.10140324039926646, 109: 0.09999205115218886, 110: 0.21427031487406534, 111: 0.05469338378489546, 112: 0.04778643173912044, 113: 0.056893476642555674, 114: 0.16569110814270038, 115: 0.1388990638243459, 116: 0.13315544270983468, 117: 0.05921023496957058, 118: 0.12239409207032889, 119: 0.09923869199608899, 120: 0.14132492758110432, 121: 0.09809156555209957, 122: 0.2234919106584345, 123: 0.12757098290124097, 124: 0.04222769487826838, 125: 0.05996466279097985, 126: 0.08889626825401994, 127: 0.2002436779385033, 128: 0.0492829282339958, 129: 0.03136078569881087, 130: 0.13400985454576356, 131: 0.14460167654058292, 132: 0.0687539669915676, 133: 0.007514237471243038, 134: 0.06351230183207959, 135: 0.1285101793185265, 136: 0.10859290052524073, 137: 0.19111360222533505, 138: 0.1362804305813355, 139: 0.11680659956278128, 140: 0.11502017824077342, 141: 0.12375244541387716, 142: 0.19243260256883207, 143: 0.13624356150864944, 144: 0.1718399536918268, 145: 0.05237901908651936, 146: 0.16362009990084048, 147: 0.17118825867593213, 148: 0.10826148177222514, 149: 0.05825164246033627, 150: 0.0599692888400565, 151: 0.13054859640436695, 152: 0.006340588762911825, 153: 0.13137210653958173, 154: 0.0967206429237046, 155: 0.04017763074353584, 156: 0.031383157568763434, 157: 0.07755421458860524, 158: 0.06564940819159275, 159: 0.07895240399438187, 160: 0.1550804745023835, 161: 0.12647435814492727, 162: 0.092719105236782, 163: 0.14025176969698733, 164: 0.07230746794770278, 165: 0.14890810095306484, 166: 0.10076316478048811, 167: 0.09466241152632539, 168: 0.01609794289505566, 169: 0.11888463941801755, 170: 0.1863529435364632, 171: 0.09946046377040602, 172: 0.06630356184327939, 173: 0.07015840900062037, 174: 0.15818139510455975, 175: 0.09344081269683804, 176: 0.19165446791827404, 177: 0.09365426958973001, 178: 0.11660139162337516, 179: 0.1424564829007889, 180: 0.09019221147740233, 181: 0.12711500961835387, 182: 0.16807812280503687, 183: 0.09830064516613048, 184: 0.07026789311963867, 185: 0.06066011525862995, 186: 0.2076077142742041, 187: 0.13301979733999578, 188: 0.10527374920828898, 189: 0.17034793370452267, 190: 0.21640981898896605, 191: 0.16873291699159063, 192: 0.061801104531521926, 193: 0.055945084006740246, 194: 0.11941488642098255, 195: 0.14737032374701825, 196: 0.1494864271459881, 197: 0.1519797276108535, 198: 0.08390443769764504, 199: 0.09872980623626071, 200: 0.08361617497603448, 201: 0.05030245137417341, 202: 0.1540062043874868, 203: 0.1273455734897339, 204: 0.10699501442928601, 205: 0.10213681702767509, 206: 0.08547954004029513, 207: 0.06128355512059556, 208: 0.1432782682293684, 209: 0.12426773912721956, 210: 0.13496867371666815, 211: 0.153963711400638, 212: 0.15986574233827475, 213: 0.11627351341332488, 214: 0.11659439160466323, 215: 0.10068128150405156, 216: 0.129316082187115, 217: 0.0531863835886342, 218: 0.12834478218785456, 219: 0.06381073478112825, 220: 0.14208113576716017, 221: 0.06191354698623254, 222: 0.03688960969072691, 223: 0.06850349604634995, 224: 0.04852309949666205, 225: 0.13635494851369426, 226: 0.0931384220040913, 227: 0.08888415140202757, 228: 0.03761126700514361, 229: 0.16151295350122677, 230: 0.061105840102141706, 231: 0.08689859284734172, 232: 0.07763095927045684, 233: 0.08449170164217337, 234: 0.10635779146345962, 235: 0.042399623314660885, 236: 0.0576502208389548, 237: 0.10034414093902398, 238: 0.027576610923160105, 239: 0.091947457982523, 240: 0.19926234811342025, 241: 0.05739744030233441, 242: 0.047642064448305925, 243: 0.09899127435063594, 244: 0.18346588940632658, 245: 0.1744515822827835, 246: 0.07447391688001216, 247: 0.12349837987121806, 248: 0.09370603926787158, 249: 0.1307904717138234, 250: 0.04918757151770312, 251: 0.07939028780447477, 252: 0.14458783446154422, 253: 0.10266051369559687, 254: 0.12483580393758976, 255: 0.0648136057174884, 256: 0.07315174904942731, 257: 0.131894823113551, 258: 0.005732369831528555, 259: 0.049220004909599296, 260: 0.11926774276410289, 261: 0.10849337131069806, 262: 0.12059015864647599, 263: 0.19143390413784905, 264: 0.11086677662824779, 265: 0.0781107903638848, 266: 0.006265407194340572, 267: 0.12326874321478906, 268: 0.12995070594511665, 269: 0.1101121990736463, 270: 0.06055503929588822, 271: 0.20309523954787134, 272: 0.06063986714788508, 273: 0.13812841124129516, 274: 0.12002396637797055, 275: 0.12479398386395868, 276: 0.07270134258106128, 277: 0.10143684496132029, 278: 0.1262336188058612, 279: 0.09710484720210531, 280: 0.12569264022471638, 281: 0.13182844504656024, 282: 0.03905278981831604, 283: 0.11351626531181203, 284: 0.040920678373908725, 285: 0.09737302962560497, 286: 0.0857480544655424, 287: 0.11899891979323243, 288: 0.0170595989705086, 289: 0.12435771102122353, 290: 0.06607462134171319, 291: 0.07242634879737894, 292: 0.15226153131756637, 293: 0.15487802152265015, 294: 0.15436007494157444, 295: 0.06139925922901441, 296: 0.09617542698748342, 297: 0.08443138582021043, 298: 0.10137565992878082, 299: 0.05293687127025168, 300: 0.0901184710769247, 301: 0.13009857448465212, 302: 0.14779775707553064, 303: 0.05457772511949391, 304: 0.033068010729475406, 305: 0.09009339472815096, 306: 0.07922410993506136, 307: 0.04594025054632041, 308: 0.06626784911876002, 309: 0.12942660909519005, 310: 0.17158966266796322, 311: 0.08803994269974416, 312: 0.102068348564519, 313: 0.19562002286193209, 314: 0.0046177802073281565, 315: 0.16137220086805576, 316: 0.0946162119030002, 317: 0.02249192638481068, 318: 0.12638741462046607, 319: 0.11687973934104036, 320: 0.0902012144467535, 321: 0.15476106706721585, 322: 0.14327813371662956, 323: 0.11008535861918488, 324: 0.08221764801853673, 325: 0.14497154056059586, 326: 0.1228803731154523, 327: 0.0852423088589004, 328: 0.12229337557984993, 329: 0.10825580065251858, 330: 0.1264019578507359, 331: 0.029995844817064327, 332: 0.025025251712530186, 333: 0.09419305538827608, 334: 0.07220957635171708, 335: 0.08788344384777196, 336: 0.06725318086884191, 337: 0.049542032824250015, 338: 0.11594318176772017, 339: 0.14397839530947412, 340: 0.06291317203498042, 341: 0.1572473916874051, 342: 0.15349667939368453, 343: 0.2245331537585209, 344: 0.04634184740271113, 345: 0.14467428345240158, 346: 0.06238726781200203, 347: 0.05369675742494623, 348: 0.15294373943736855, 349: 0.06084658296071102, 350: 0.11860327738829876, 351: 0.13492201941839868, 352: 0.025938710402899967, 353: 0.07965274296931073, 354: 0.05939191320000912, 355: 0.11721609103214164, 356: 0.10108891283288415, 357: 0.18281491597845728, 358: 0.17771489440663113, 359: 0.15004021328612907, 360: 0.14057480941538117, 361: 0.025703775553336264, 362: 0.08593732252087964, 363: 0.18155168292946847, 364: 0.12578514248512826, 365: 0.08195796677583275, 366: 0.07996950303133372, 367: 0.15033317101583385, 368: 0.18867552403849994, 369: 0.17315127221624632, 370: 0.1221364242287346, 371: 0.1725612247718143, 372: 0.15442896832487954, 373: 0.07038682767331988, 374: 0.13363595280366422, 375: 0.12589930156390308, 376: 0.12526769913827623, 377: 0.03181616685388898, 378: 0.07155848672552222, 379: 0.023980095069396884, 380: 0.07883667865148057, 381: 0.05038947788589058, 382: 0.1977869425602909, 383: 0.1980569118431, 384: 0.03485559924132063, 385: 0.11383498310886193, 386: 0.20301113749249822, 387: 0.09871684410240976, 388: 0.13199584744750775, 389: 0.08853944710199421, 390: 0.0767190703689575, 391: 0.12616402002299804, 392: 0.1035506381497612, 393: 0.006464728280739282, 394: 0.16960482787403575, 395: 0.18511361681583632, 396: 0.0029741268512343266, 397: 0.1847996390258227, 398: 0.21402309483636525, 399: 0.07228333354673463}\n",
            "Behavior Degree Sequence:  [3, 3, 4, 3, 3, 3, 3, 10, 4, 4, 3, 4, 3, 4, 4, 5, 3, 7, 3, 3, 3, 3, 6, 3, 3, 4, 7, 3, 5, 4, 4, 3, 6, 3, 3, 4, 3, 3, 5, 3, 3, 3, 3, 3, 3, 5, 4, 3, 3, 3, 3, 4, 3, 4, 3, 3, 7, 6, 3, 3, 3, 3, 3, 3, 6, 3, 3, 6, 3, 3, 3, 5, 9, 3, 3, 3, 6, 3, 10, 3, 4, 8, 3, 3, 4, 7, 3, 3, 3, 4, 4, 4, 4, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
            "{0: 'N', 1: 'P', 2: 'P', 3: 'N', 4: 'N', 5: 'N', 6: 'N', 7: 'N', 8: 'N', 9: 'N', 10: 'N', 11: 'P', 12: 'N', 13: 'N', 14: 'N', 15: 'N', 16: 'N', 17: 'N', 18: 'P', 19: 'N', 20: 'P', 21: 'N', 22: 'N', 23: 'N', 24: 'P', 25: 'N', 26: 'N', 27: 'N', 28: 'P', 29: 'P', 30: 'P', 31: 'P', 32: 'N', 33: 'N', 34: 'N', 35: 'P', 36: 'N', 37: 'N', 38: 'N', 39: 'P', 40: 'N', 41: 'N', 42: 'P', 43: 'P', 44: 'N', 45: 'P', 46: 'N', 47: 'N', 48: 'P', 49: 'N', 50: 'N', 51: 'N', 52: 'N', 53: 'N', 54: 'N', 55: 'P', 56: 'P', 57: 'N', 58: 'P', 59: 'N', 60: 'N', 61: 'P', 62: 'N', 63: 'N', 64: 'P', 65: 'N', 66: 'N', 67: 'N', 68: 'P', 69: 'N', 70: 'N', 71: 'N', 72: 'N', 73: 'N', 74: 'P', 75: 'N', 76: 'P', 77: 'N', 78: 'N', 79: 'N', 80: 'N', 81: 'N', 82: 'N', 83: 'P', 84: 'N', 85: 'N', 86: 'N', 87: 'N', 88: 'N', 89: 'N', 90: 'P', 91: 'N', 92: 'N', 93: 'N', 94: 'N', 95: 'N', 96: 'N', 97: 'N', 98: 'N', 99: 'N', 100: 'P', 101: 'N', 102: 'P', 103: 'N', 104: 'N', 105: 'P', 106: 'N', 107: 'N', 108: 'P', 109: 'N', 110: 'N', 111: 'N', 112: 'N', 113: 'N', 114: 'N', 115: 'N', 116: 'N', 117: 'P', 118: 'N', 119: 'N', 120: 'N', 121: 'N', 122: 'N', 123: 'P', 124: 'N', 125: 'P', 126: 'N', 127: 'N', 128: 'N', 129: 'P', 130: 'N', 131: 'N', 132: 'P', 133: 'N', 134: 'N', 135: 'N', 136: 'N', 137: 'P', 138: 'P', 139: 'N', 140: 'N', 141: 'P', 142: 'P', 143: 'N', 144: 'N', 145: 'N', 146: 'P', 147: 'N', 148: 'P', 149: 'N', 150: 'N', 151: 'P', 152: 'N', 153: 'N', 154: 'P', 155: 'N', 156: 'N', 157: 'P', 158: 'N', 159: 'N', 160: 'P', 161: 'N', 162: 'N', 163: 'P', 164: 'N', 165: 'N', 166: 'P', 167: 'N', 168: 'N', 169: 'N', 170: 'N', 171: 'N', 172: 'P', 173: 'P', 174: 'P', 175: 'N', 176: 'N', 177: 'N', 178: 'N', 179: 'P', 180: 'P', 181: 'N', 182: 'N', 183: 'N', 184: 'P', 185: 'N', 186: 'N', 187: 'N', 188: 'N', 189: 'N', 190: 'N', 191: 'N', 192: 'N', 193: 'N', 194: 'N', 195: 'P', 196: 'N', 197: 'N', 198: 'N', 199: 'N', 200: 'P', 201: 'N', 202: 'N', 203: 'N', 204: 'P', 205: 'P', 206: 'P', 207: 'N', 208: 'P', 209: 'N', 210: 'N', 211: 'N', 212: 'P', 213: 'N', 214: 'P', 215: 'N', 216: 'N', 217: 'N', 218: 'N', 219: 'N', 220: 'N', 221: 'P', 222: 'N', 223: 'N', 224: 'N', 225: 'N', 226: 'N', 227: 'N', 228: 'N', 229: 'P', 230: 'N', 231: 'N', 232: 'P', 233: 'N', 234: 'N', 235: 'N', 236: 'P', 237: 'N', 238: 'N', 239: 'P', 240: 'N', 241: 'N', 242: 'N', 243: 'N', 244: 'P', 245: 'N', 246: 'P', 247: 'N', 248: 'N', 249: 'N', 250: 'P', 251: 'N', 252: 'P', 253: 'N', 254: 'P', 255: 'N', 256: 'N', 257: 'N', 258: 'P', 259: 'N', 260: 'N', 261: 'N', 262: 'P', 263: 'N', 264: 'P', 265: 'N', 266: 'P', 267: 'P', 268: 'N', 269: 'N', 270: 'N', 271: 'N', 272: 'N', 273: 'N', 274: 'N', 275: 'P', 276: 'N', 277: 'N', 278: 'P', 279: 'P', 280: 'P', 281: 'N', 282: 'P', 283: 'N', 284: 'N', 285: 'P', 286: 'N', 287: 'N', 288: 'N', 289: 'N', 290: 'N', 291: 'N', 292: 'N', 293: 'N', 294: 'N', 295: 'P', 296: 'N', 297: 'P', 298: 'N', 299: 'P', 300: 'N', 301: 'P', 302: 'N', 303: 'N', 304: 'P', 305: 'N', 306: 'P', 307: 'N', 308: 'P', 309: 'N', 310: 'N', 311: 'P', 312: 'N', 313: 'N', 314: 'N', 315: 'P', 316: 'N', 317: 'N', 318: 'P', 319: 'N', 320: 'N', 321: 'N', 322: 'P', 323: 'N', 324: 'N', 325: 'N', 326: 'N', 327: 'N', 328: 'N', 329: 'N', 330: 'P', 331: 'N', 332: 'N', 333: 'P', 334: 'P', 335: 'N', 336: 'N', 337: 'N', 338: 'N', 339: 'N', 340: 'N', 341: 'N', 342: 'P', 343: 'P', 344: 'N', 345: 'P', 346: 'P', 347: 'N', 348: 'N', 349: 'P', 350: 'N', 351: 'N', 352: 'N', 353: 'N', 354: 'P', 355: 'N', 356: 'N', 357: 'N', 358: 'P', 359: 'P', 360: 'N', 361: 'P', 362: 'P', 363: 'N', 364: 'N', 365: 'N', 366: 'P', 367: 'P', 368: 'P', 369: 'N', 370: 'P', 371: 'P', 372: 'N', 373: 'N', 374: 'N', 375: 'N', 376: 'N', 377: 'P', 378: 'N', 379: 'N', 380: 'P', 381: 'N', 382: 'N', 383: 'P', 384: 'N', 385: 'P', 386: 'N', 387: 'P', 388: 'N', 389: 'N', 390: 'P', 391: 'N', 392: 'P', 393: 'N', 394: 'N', 395: 'N', 396: 'N', 397: 'P', 398: 'N', 399: 'P'}\n",
            "Degree Sequence:  [3, 6, 3, 3, 3, 9, 4, 3, 3, 3, 4, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 8, 7, 3, 3, 3, 3, 4, 4, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/core/dtypes/cast.py:1641: DeprecationWarning: np.find_common_type is deprecated.  Please use `np.result_type` or `np.promote_types`.\n",
            "See https://numpy.org/devdocs/release/1.25.0-notes.html and the docs for more information.  (Deprecated NumPy 1.25)\n",
            "  return np.find_common_type(types, [])\n"
          ]
        }
      ],
      "source": [
        "n = 400  # Number of nodes\n",
        "\n",
        "# Information Layer\n",
        "gamma_i = 2.5  # Power-law exponent\n",
        "kmin_i = 3  # Minimum degree\n",
        "num_hyper_edges_i = 100  # Desired number of hyper edges\n",
        "ldeg_i, hyperedge_dict_i = build_hypergraph(n, gamma_i, kmin_i, num_hyper_edges_i)\n",
        "inw = hnx.Hypergraph(hyperedge_dict_i)\n",
        "ltre = assign_thresholds(inw, 0.1, 0.05)\n",
        "print(\"Acceptance Threshold Sequence: \", ltre)\n",
        "\n",
        "# Cognition Layer\n",
        "gamma_c = 3.0  # Power-law exponent\n",
        "kmin_c = 3  # Minimum degree\n",
        "ldeg_c = generate_degree_sequence(n, gamma_c, kmin_c)\n",
        "print(\"Behavior Degree Sequence: \", ldeg_c)\n",
        "cnw = nx.configuration_model(ldeg_c)\n",
        "frac_prot = 0.3\n",
        "lprot = assign_protection(cnw, frac_prot)\n",
        "\n",
        "# Epidemic Layer\n",
        "gamma_e = 4.0\n",
        "kmin_e = 3\n",
        "ldeg_e = generate_degree_sequence(n, gamma_e, kmin_e)\n",
        "print(\"Degree Sequence: \", ldeg_e)\n",
        "enw = nx.configuration_model(ldeg_e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iGOHKVGoPuRu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba75fc6d-e6db-474b-e1da-001b83bfaecd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pexpect/popen_spawn.py:60: DeprecationWarning: setDaemon() is deprecated, set the daemon attribute instead\n",
            "  self._read_thread.setDaemon(True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LcPhYNaPUdYJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ba7959-a173-472a-8767-f7664c684bfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SALib\n",
            "  Downloading salib-1.4.7-py3-none-any.whl (757 kB)\n",
            "\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/758.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m\u001b[0m\u001b[91m\u001b[0m\u001b[90m\u001b[0m \u001b[32m92.2/758.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m\u001b[0m\u001b[91m\u001b[0m \u001b[32m757.8/758.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m758.0/758.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from SALib) (3.7.1)\n",
            "Collecting multiprocess (from SALib)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from SALib) (1.26.0)\n",
            "Requirement already satisfied: pandas>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from SALib) (1.5.3)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from SALib) (1.11.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.2->SALib) (2023.3.post1)\n",
            "Collecting dill>=0.3.7 (from multiprocess->SALib)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->SALib) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, SALib\n",
            "Successfully installed SALib-1.4.7 dill-0.3.7 multiprocess-0.70.15\n"
          ]
        }
      ],
      "source": [
        "!pip install SALib\n",
        "from SALib.sample import saltelli\n",
        "from SALib.analyze import sobol\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WeTdQVmy9P4f"
      },
      "outputs": [],
      "source": [
        "alp = 1\n",
        "beta_NN = 0.4\n",
        "mu = 1\n",
        "n_sample2 = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HhC-3wZ9Pmd",
        "outputId": "87e41cb3-f2fe-4fc2-8347-bfd254cb046d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1.0, 0.9016666666666667, 0.006666666666666667)\n",
            "(0.0, 0.9991666666666666, 0.004166666666666667)\n",
            "(0.3333333333333333, 0.9874999999999999, 0.005)\n",
            "(0.3333333333333333, 0.9874999999999999, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.9674999999999999, 0.0025)\n",
            "(0.0, 0.9941666666666666, 0.01)\n",
            "(0.6666666666666666, 0.9950000000000001, 0.0025)\n",
            "(0.3333333333333333, 0.9983333333333334, 0.0025)\n",
            "(0.3333333333333333, 0.9908333333333333, 0.0025)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(0.6666666666666666, 0.9950000000000001, 0.0025)\n",
            "(0.3333333333333333, 0.8258333333333333, 0.005)\n",
            "(0.3333333333333333, 0.0, 0.005833333333333334)\n",
            "(0.3333333333333333, 0.8741666666666666, 0.31916666666666665)\n",
            "(0.3333333333333333, 0.9333333333333332, 0.012499999999999999)\n",
            "(0.6666666666666666, 0.5525, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9716666666666667, 0.004166666666666667)\n",
            "(0.0, 1.0, 0.005833333333333334)\n",
            "(0.3333333333333333, 0.9991666666666666, 0.0025)\n",
            "(0.3333333333333333, 0.9983333333333334, 0.0025)\n",
            "(0.0, 0.9975, 0.0025)\n",
            "(0.6666666666666666, 0.7908333333333334, 0.011666666666666667)\n",
            "(1.0, 0.9925, 0.005833333333333333)\n",
            "(0.3333333333333333, 0.8958333333333334, 0.005)\n",
            "(0.6666666666666666, 0.9991666666666666, 0.0025)\n",
            "(0.6666666666666666, 0.995, 0.0025)\n",
            "(0.6666666666666666, 0.23, 0.56)\n",
            "(0.6666666666666666, 0.9950000000000001, 0.028333333333333335)\n",
            "(0.3333333333333333, 1.0, 0.0025)\n",
            "(0.0, 1.0, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.9991666666666666, 0.0025)\n",
            "(0.3333333333333333, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.1475, 0.6041666666666666)\n",
            "(0.6666666666666666, 0.9775, 0.005833333333333334)\n",
            "(1.0, 1.0, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.9550000000000001, 0.0025)\n",
            "(0.3333333333333333, 0.9016666666666667, 0.0033333333333333335)\n",
            "(1.0, 0.9783333333333334, 0.0025)\n",
            "(0.3333333333333333, 0.0016666666666666668, 0.3158333333333333)\n",
            "(0.6666666666666666, 0.85, 0.2808333333333333)\n",
            "(0.3333333333333333, 0.9866666666666667, 0.005833333333333334)\n",
            "(0.3333333333333333, 0.9791666666666666, 0.0025)\n",
            "(0.0, 0.9941666666666666, 0.0033333333333333335)\n",
            "(0.6533333333333333, 0.7433333333333333, 0.0025)\n",
            "(1.0, 0.9725, 0.006666666666666665)\n",
            "(0.6658333333333334, 0.9975, 0.0025)\n",
            "(0.6666666666666666, 1.0, 0.0025)\n",
            "(0.0, 0.9991666666666666, 0.0025)\n",
            "(0.0, 1.0, 0.004166666666666667)\n",
            "(0.3333333333333333, 0.9033333333333333, 0.0025)\n",
            "(0.0, 0.9991666666666666, 0.0025)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.8525, 0.0025)\n",
            "(0.6666666666666666, 0.9991666666666666, 0.0025)\n",
            "(0.3333333333333333, 0.9991666666666666, 0.005)\n",
            "(0.33166666666666667, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.8225000000000001, 0.0025)\n",
            "(0.6666666666666666, 0.9916666666666667, 0.115)\n",
            "(1.0, 1.0, 0.0025)\n",
            "(0.6666666666666666, 0.5841666666666666, 0.0075)\n",
            "(0.6666666666666666, 0.9791666666666666, 0.005)\n",
            "(0.9841666666666667, 0.39916666666666667, 0.0025)\n",
            "(0.6666666666666666, 0.9741666666666666, 0.004166666666666667)\n",
            "(0.6666666666666666, 1.0, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.8266666666666667, 0.0025)\n",
            "(0.6666666666666666, 0.8925, 0.010833333333333334)\n",
            "(0.3333333333333333, 0.8908333333333333, 0.007500000000000001)\n",
            "(1.0, 0.9950000000000001, 0.004166666666666667)\n",
            "(0.6666666666666666, 0.9958333333333332, 0.006666666666666665)\n",
            "(0.3333333333333333, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.9533333333333335, 0.0025)\n",
            "(1.0, 0.13083333333333333, 0.29250000000000004)\n",
            "(0.6666666666666666, 0.8916666666666666, 0.008333333333333333)\n",
            "(1.0, 0.0, 0.6133333333333333)\n",
            "(0.6666666666666666, 0.6908333333333333, 0.4925)\n",
            "(0.0, 0.010833333333333334, 0.0033333333333333335)\n",
            "(0.0, 0.9983333333333334, 0.12333333333333334)\n",
            "(0.3333333333333333, 0.30583333333333335, 0.3116666666666667)\n",
            "(0.0, 0.27166666666666667, 0.3541666666666667)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(0.20166666666666666, 0.8150000000000001, 0.006666666666666667)\n",
            "(0.6541666666666667, 0.005833333333333334, 0.615)\n",
            "(0.3333333333333333, 1.0, 0.0025)\n",
            "(0.6666666666666666, 0.995, 0.0025)\n",
            "(0.6666666666666666, 0.7383333333333333, 0.0025)\n",
            "(0.0, 0.9975, 0.02916666666666667)\n",
            "(0.0, 0.9941666666666666, 0.005)\n",
            "(0.0, 1.0, 0.008333333333333333)\n",
            "(0.6083333333333334, 0.9991666666666666, 0.0025)\n",
            "(0.3333333333333333, 0.9941666666666666, 0.0025)\n",
            "(0.3325, 0.9766666666666667, 0.0025)\n",
            "(0.6666666666666666, 1.0, 0.005)\n",
            "(0.0, 0.9991666666666666, 0.0025)\n",
            "(0.6666666666666666, 0.985, 0.0025)\n",
            "(0.3333333333333333, 0.9816666666666668, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.0, 0.6391666666666667)\n",
            "(0.6666666666666666, 0.27666666666666667, 0.58)\n",
            "(0.6666666666666666, 0.17500000000000002, 0.005)\n",
            "(0.3333333333333333, 0.9991666666666666, 0.2583333333333333)\n",
            "(0.3333333333333333, 0.022500000000000003, 0.6308333333333334)\n",
            "(0.0, 0.8583333333333334, 0.2883333333333333)\n",
            "(0.6666666666666666, 0.9908333333333333, 0.0025)\n",
            "(0.13833333333333334, 0.8191666666666665, 0.0025)\n",
            "(0.3333333333333333, 0.8841666666666668, 0.005)\n",
            "(0.6666666666666666, 0.9891666666666667, 0.0025)\n",
            "(0.6666666666666666, 0.4875, 0.0025)\n",
            "(0.6666666666666666, 0.9874999999999999, 0.005833333333333334)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(0.3125, 0.0275, 0.30666666666666664)\n",
            "(0.3333333333333333, 0.8808333333333334, 0.3283333333333333)\n",
            "(0.6666666666666666, 0.9883333333333333, 0.004166666666666667)\n",
            "(0.32916666666666666, 0.9824999999999999, 0.0025)\n",
            "(0.6666666666666666, 0.9883333333333333, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.004166666666666667, 0.005833333333333334)\n",
            "(0.0, 0.13666666666666666, 0.012500000000000002)\n",
            "(1.0, 0.9666666666666667, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.9516666666666667, 0.0033333333333333335)\n",
            "(0.3333333333333333, 1.0, 0.004166666666666667)\n",
            "(0.6666666666666666, 0.8841666666666667, 0.004166666666666667)\n",
            "(0.3333333333333333, 0.6566666666666666, 0.004166666666666667)\n",
            "(1.0, 0.9475000000000001, 0.2925)\n",
            "(0.3333333333333333, 0.9883333333333333, 0.005)\n",
            "(0.3333333333333333, 0.9775, 0.005)\n",
            "(0.20583333333333334, 0.9683333333333334, 0.005)\n",
            "(0.3333333333333333, 0.9916666666666667, 0.0033333333333333335)\n",
            "(0.0, 0.9975, 0.005833333333333334)\n",
            "(0.6666666666666666, 0.9883333333333333, 0.0025)\n",
            "(0.6666666666666666, 0.995, 0.0025)\n",
            "(0.6666666666666666, 0.7075, 0.0025)\n",
            "(0.6666666666666666, 0.9816666666666668, 0.0025)\n",
            "(0.0, 0.9991666666666666, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9966666666666667, 0.0033333333333333335)\n",
            "(0.3333333333333333, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.9908333333333333, 0.0025)\n",
            "(0.6666666666666666, 0.02, 0.29916666666666664)\n",
            "(0.32, 0.5133333333333333, 0.31249999999999994)\n",
            "(1.0, 0.9966666666666667, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9891666666666667, 0.0025)\n",
            "(0.6658333333333334, 1.0, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9583333333333334, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9991666666666666, 0.0025)\n",
            "(0.6666666666666666, 0.4491666666666667, 0.25083333333333335)\n",
            "(0.6666666666666666, 0.9916666666666667, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9541666666666666, 0.0025)\n",
            "(0.6666666666666666, 0.9758333333333334, 0.0025)\n",
            "(0.6666666666666666, 0.4383333333333333, 0.2816666666666666)\n",
            "(0.3333333333333333, 0.9983333333333334, 0.0025)\n",
            "(0.3333333333333333, 0.9900000000000001, 0.010833333333333334)\n",
            "(1.0, 0.1075, 0.31)\n",
            "(0.3333333333333333, 0.77, 0.011666666666666667)\n",
            "(0.33166666666666667, 0.6783333333333333, 0.004166666666666667)\n",
            "(0.6666666666666666, 0.15333333333333332, 0.24)\n",
            "(0.6666666666666666, 0.9991666666666666, 0.16666666666666666)\n",
            "(0.3333333333333333, 0.965, 0.0025)\n",
            "(0.3333333333333333, 0.9858333333333333, 0.0025)\n",
            "(0.6666666666666666, 0.9966666666666667, 0.005)\n",
            "(0.3333333333333333, 0.9950000000000001, 0.0025)\n",
            "(0.3333333333333333, 0.9883333333333334, 0.004166666666666667)\n",
            "(0.5766666666666667, 0.6183333333333333, 0.005833333333333334)\n",
            "(0.3333333333333333, 1.0, 0.0025)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(0.6666666666666666, 0.1175, 0.005)\n",
            "(0.3333333333333333, 0.015833333333333335, 0.9483333333333334)\n",
            "(0.0, 1.0, 0.24916666666666665)\n",
            "(0.0, 0.9816666666666666, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9758333333333334, 0.0025)\n",
            "(0.6666666666666666, 0.4275, 0.11583333333333334)\n",
            "(0.6658333333333334, 0.9975, 0.2925)\n",
            "(0.3333333333333333, 1.0, 0.004166666666666667)\n",
            "(0.6666666666666666, 0.9925, 0.0025)\n",
            "(0.6666666666666666, 0.9483333333333333, 0.0025)\n",
            "(0.0, 0.9983333333333334, 0.005833333333333333)\n",
            "(0.3333333333333333, 1.0, 0.004166666666666667)\n",
            "(0.3333333333333333, 0.5425, 0.115)\n",
            "(0.6666666666666666, 0.9908333333333333, 0.0075)\n",
            "(0.6666666666666666, 0.8266666666666667, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9891666666666667, 0.0025)\n",
            "(0.3333333333333333, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.9775, 0.0025)\n",
            "(0.4216666666666667, 0.9291666666666667, 0.005)\n",
            "(0.3333333333333333, 0.1325, 0.31)\n",
            "(0.245, 0.9091666666666667, 0.2525)\n",
            "(0.3333333333333333, 0.9841666666666667, 0.0025)\n",
            "(0.9991666666666666, 0.04583333333333334, 0.30333333333333334)\n",
            "(0.3333333333333333, 0.9941666666666666, 0.3008333333333333)\n",
            "(0.0, 0.9558333333333334, 0.0025)\n",
            "(0.6666666666666666, 0.9274999999999999, 0.005833333333333334)\n",
            "(0.3333333333333333, 1.0, 0.0025)\n",
            "(0.6666666666666666, 0.9991666666666666, 0.0025)\n",
            "(0.4025, 0.14666666666666667, 0.2758333333333333)\n",
            "(0.3908333333333333, 0.7141666666666667, 0.036666666666666674)\n",
            "(0.3333333333333333, 0.9441666666666667, 0.0025)\n",
            "(1.0, 0.9975, 0.0025)\n",
            "(0.6666666666666666, 0.2841666666666667, 0.0025)\n",
            "(0.0, 1.0, 0.18833333333333332)\n",
            "(0.6666666666666666, 0.9775, 0.0025)\n",
            "(1.0, 1.0, 0.0033333333333333335)\n",
            "(1.0, 0.9916666666666667, 0.005)\n",
            "(1.0, 0.6441666666666667, 0.004166666666666667)\n",
            "(0.6666666666666666, 0.9966666666666667, 0.006666666666666665)\n",
            "(0.0, 0.6133333333333333, 0.008333333333333333)\n",
            "(0.0, 0.33166666666666667, 0.0033333333333333335)\n",
            "(0.3333333333333333, 1.0, 0.0033333333333333335)\n",
            "(1.0, 0.9933333333333333, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9316666666666666, 0.0025)\n",
            "(0.0, 0.375, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.8358333333333333, 0.13333333333333333)\n",
            "(0.0, 0.9616666666666666, 0.005)\n",
            "(0.3333333333333333, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.9858333333333333, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.9966666666666667, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.3758333333333333, 0.16749999999999998)\n",
            "(0.6666666666666666, 0.9858333333333333, 0.009166666666666665)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.5800000000000001, 0.0025)\n",
            "(0.6666666666666666, 0.9900000000000001, 0.008333333333333333)\n",
            "(0.9791666666666666, 0.05333333333333334, 0.3075)\n",
            "(0.6666666666666666, 1.0, 0.009166666666666665)\n",
            "(0.3333333333333333, 0.5741666666666667, 0.29166666666666663)\n",
            "(0.6666666666666666, 0.4741666666666667, 0.0075)\n",
            "(0.6666666666666666, 0.9558333333333334, 0.0025)\n",
            "(0.6016666666666667, 0.8266666666666667, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.5575, 0.0033333333333333335)\n",
            "(0.33, 0.9983333333333334, 0.004166666666666667)\n",
            "(1.0, 0.8125, 0.0033333333333333335)\n",
            "(0.6666666666666666, 1.0, 0.0033333333333333335)\n",
            "(0.3325, 0.0033333333333333335, 0.6408333333333333)\n",
            "(0.6666666666666666, 0.995, 0.17249999999999996)\n",
            "(0.3333333333333333, 1.0, 0.004166666666666667)\n",
            "(0.6666666666666666, 0.9975, 0.0025)\n",
            "(0.3333333333333333, 0.9691666666666667, 0.004166666666666667)\n",
            "(1.0, 0.4558333333333333, 0.005833333333333334)\n",
            "(0.6666666666666666, 0.8425000000000001, 0.012500000000000002)\n",
            "(0.6666666666666666, 0.36000000000000004, 0.31416666666666665)\n",
            "(0.6666666666666666, 0.3491666666666667, 0.3525)\n",
            "(0.3333333333333333, 0.6883333333333334, 0.44416666666666665)\n",
            "(0.6666666666666666, 0.9333333333333335, 0.009166666666666667)\n",
            "(0.0, 0.9958333333333332, 0.009166666666666668)\n",
            "(0.3333333333333333, 1.0, 0.004166666666666667)\n",
            "(0.6666666666666666, 0.20583333333333334, 0.5791666666666666)\n",
            "(0.6666666666666666, 0.9900000000000001, 0.14916666666666667)\n",
            "(0.3333333333333333, 0.9883333333333333, 0.006666666666666667)\n",
            "(0.0, 0.9958333333333335, 0.0025)\n",
            "(0.6666666666666666, 0.5216666666666666, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9891666666666667, 0.0025)\n",
            "(0.3333333333333333, 0.8416666666666668, 0.0025)\n",
            "(0.0, 0.012499999999999999, 0.315)\n",
            "(0.0, 1.0, 0.20416666666666664)\n",
            "(0.3325, 0.8883333333333333, 0.005)\n",
            "(0.0, 0.9950000000000001, 0.0033333333333333335)\n",
            "(0.0, 0.9991666666666666, 0.0025)\n",
            "(0.3333333333333333, 0.6691666666666666, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9933333333333333, 0.3158333333333333)\n",
            "(0.6666666666666666, 1.0, 0.0025)\n",
            "(0.6666666666666666, 0.9883333333333333, 0.0025)\n",
            "(0.0, 0.7741666666666668, 0.0033333333333333335)\n",
            "(0.0, 0.9341666666666667, 0.0175)\n",
            "(0.3333333333333333, 0.3125, 0.1733333333333333)\n",
            "(0.3333333333333333, 0.9958333333333332, 0.004166666666666667)\n",
            "(0.33, 0.6774999999999999, 0.004166666666666667)\n",
            "(0.6666666666666666, 1.0, 0.08750000000000001)\n",
            "(1.0, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.995, 0.005833333333333334)\n",
            "(0.3333333333333333, 0.9983333333333334, 0.0025)\n",
            "(0.3333333333333333, 0.20166666666666666, 0.2683333333333333)\n",
            "(1.0, 0.9966666666666667, 0.14583333333333334)\n",
            "(0.3333333333333333, 0.9966666666666667, 0.0025)\n",
            "(0.3333333333333333, 0.014166666666666668, 0.015000000000000001)\n",
            "(0.3333333333333333, 0.8424999999999999, 0.30916666666666665)\n",
            "(0.0008333333333333334, 0.9408333333333333, 0.0025)\n",
            "(0.6666666666666666, 0.9991666666666666, 0.004166666666666667)\n",
            "(0.6666666666666666, 0.9741666666666666, 0.004166666666666667)\n",
            "(0.3333333333333333, 0.9841666666666667, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9741666666666667, 0.0025)\n",
            "(0.665, 1.0, 0.0025)\n",
            "(0.9991666666666666, 0.7041666666666666, 0.005833333333333334)\n",
            "(0.0, 0.9966666666666667, 0.0025)\n",
            "(0.3333333333333333, 0.9975, 0.005833333333333334)\n",
            "(0.6666666666666666, 0.9991666666666666, 0.0025)\n",
            "(0.9991666666666666, 0.34249999999999997, 0.24166666666666667)\n",
            "(0.6666666666666666, 0.9858333333333333, 0.04083333333333333)\n",
            "(0.6666666666666666, 0.9916666666666667, 0.0025)\n",
            "(0.6666666666666666, 0.9966666666666667, 0.0025)\n",
            "(0.6666666666666666, 0.9641666666666667, 0.0025)\n",
            "(0.3333333333333333, 0.9941666666666666, 0.0025)\n",
            "(0.6666666666666666, 0.29083333333333333, 0.27499999999999997)\n",
            "(0.3333333333333333, 0.9824999999999999, 0.022500000000000003)\n",
            "(0.6516666666666667, 0.9941666666666666, 0.0025)\n",
            "(0.6666666666666666, 0.9925, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9925, 0.004166666666666667)\n",
            "(0.3333333333333333, 0.96, 0.008333333333333333)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.7825000000000001, 0.0025)\n",
            "(1.0, 0.49416666666666664, 0.030833333333333334)\n",
            "(0.3333333333333333, 0.5708333333333334, 0.03)\n",
            "(0.0, 0.045000000000000005, 0.3208333333333333)\n",
            "(0.6666666666666666, 0.03666666666666666, 0.6358333333333333)\n",
            "(0.6666666666666666, 1.0, 0.22916666666666663)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(0.3116666666666667, 0.8225000000000001, 0.0025)\n",
            "(1.0, 0.33416666666666667, 0.2283333333333333)\n",
            "(0.3333333333333333, 0.9958333333333335, 0.0025)\n",
            "(1.0, 0.8683333333333333, 0.0025)\n",
            "(0.3333333333333333, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.9975, 0.0025)\n",
            "(0.9925, 1.0, 0.0025)\n",
            "(0.6666666666666666, 0.9874999999999999, 0.0025)\n",
            "(0.6666666666666666, 0.9958333333333332, 0.005)\n",
            "(0.6666666666666666, 0.9975, 0.004166666666666667)\n",
            "(0.3325, 1.0, 0.004166666666666667)\n",
            "(0.3333333333333333, 0.5775, 0.0025)\n",
            "(0.3333333333333333, 1.0, 0.006666666666666667)\n",
            "(0.0, 0.9991666666666666, 0.0025)\n",
            "(0.0, 0.9775, 0.005)\n",
            "(0.3333333333333333, 0.9341666666666667, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.9625, 0.005)\n",
            "(0.3325, 0.9700000000000001, 0.005833333333333334)\n",
            "(0.6666666666666666, 0.895, 0.0025)\n",
            "(0.0, 1.0, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9991666666666666, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9983333333333334, 0.0025)\n",
            "(0.6666666666666666, 0.6808333333333332, 0.0025)\n",
            "(0.6666666666666666, 0.9416666666666668, 0.0025)\n",
            "(0.6666666666666666, 0.17833333333333334, 0.5625)\n",
            "(0.0, 1.0, 0.03166666666666667)\n",
            "(0.9966666666666667, 0.9783333333333334, 0.0033333333333333335)\n",
            "(1.0, 0.9533333333333333, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.7033333333333335, 0.0025)\n",
            "(0.6666666666666666, 0.85, 0.0025)\n",
            "(1.0, 0.9966666666666667, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.9883333333333333, 0.005)\n",
            "(0.3333333333333333, 1.0, 0.0033333333333333335)\n",
            "(0.26666666666666666, 0.9991666666666666, 0.0033333333333333335)\n",
            "(0.33, 0.9733333333333333, 0.004166666666666667)\n",
            "(0.0, 0.9991666666666666, 0.0025)\n",
            "(0.6666666666666666, 0.9991666666666666, 0.0025)\n",
            "(0.6658333333333334, 0.028333333333333335, 0.31916666666666665)\n",
            "(0.0, 0.9991666666666666, 0.0025)\n",
            "(0.0, 0.07833333333333332, 0.0025)\n",
            "(0.3333333333333333, 0.9641666666666667, 0.27749999999999997)\n",
            "(0.3333333333333333, 0.9908333333333333, 0.005)\n",
            "(0.0, 0.9975, 0.0025)\n",
            "(0.3333333333333333, 0.03, 0.6116666666666667)\n",
            "(0.6666666666666666, 0.315, 0.16333333333333333)\n",
            "(1.0, 0.13083333333333333, 0.545)\n",
            "(1.0, 0.020833333333333332, 0.6458333333333334)\n",
            "(1.0, 0.9975, 0.13999999999999999)\n",
            "(0.0, 0.9558333333333332, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.945, 0.006666666666666665)\n",
            "(0.6666666666666666, 0.9991666666666666, 0.0025)\n",
            "(0.6666666666666666, 0.5566666666666666, 0.0025)\n",
            "(0.0, 0.9983333333333334, 0.004166666666666667)\n",
            "(0.6666666666666666, 0.985, 0.0025)\n",
            "(0.3333333333333333, 0.9899999999999999, 0.0025)\n",
            "(0.6666666666666666, 0.9816666666666666, 0.005)\n",
            "(0.6666666666666666, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.9375, 0.0025)\n",
            "(0.3333333333333333, 0.9725, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.014166666666666668, 0.013333333333333334)\n",
            "(0.6666666666666666, 0.49416666666666664, 0.005)\n",
            "(0.6666666666666666, 0.9966666666666667, 0.049999999999999996)\n",
            "(1.0, 0.0775, 0.31666666666666665)\n",
            "(0.6666666666666666, 0.9441666666666667, 0.26166666666666666)\n",
            "(0.65, 0.9708333333333333, 0.0025)\n",
            "(0.3333333333333333, 0.9958333333333332, 0.0025)\n",
            "(0.6666666666666666, 0.8575, 0.0025)\n",
            "(0.6666666666666666, 0.8725, 0.008333333333333333)\n",
            "(1.0, 0.4266666666666667, 0.020833333333333332)\n",
            "(0.3333333333333333, 0.8966666666666666, 0.0075)\n",
            "(0.3333333333333333, 0.9908333333333333, 0.0033333333333333335)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(0.3125, 0.9783333333333334, 0.005)\n",
            "(0.3333333333333333, 0.2808333333333333, 0.07833333333333334)\n",
            "(0.3325, 0.28750000000000003, 0.02416666666666667)\n",
            "(0.3333333333333333, 0.9991666666666666, 0.29166666666666663)\n",
            "(0.3333333333333333, 0.7833333333333333, 0.1425)\n",
            "(0.3325, 0.09083333333333332, 0.3033333333333333)\n",
            "(1.0, 0.9666666666666667, 0.01916666666666667)\n",
            "(0.0, 0.9991666666666666, 0.0025)\n",
            "(0.3325, 0.9908333333333333, 0.005)\n",
            "(0.6666666666666666, 0.8741666666666666, 0.0033333333333333335)\n",
            "(1.0, 0.02333333333333333, 0.31999999999999995)\n",
            "(1.0, 0.9466666666666667, 0.2808333333333333)\n",
            "(0.3333333333333333, 0.9625, 0.006666666666666667)\n",
            "(0.0, 0.9983333333333334, 0.005833333333333334)\n",
            "(0.33166666666666667, 1.0, 0.0025)\n",
            "(0.6666666666666666, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.9941666666666666, 0.0025)\n",
            "(1.0, 0.9900000000000001, 0.0025)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.4708333333333334, 0.07333333333333333)\n",
            "(0.625, 0.15333333333333332, 0.25499999999999995)\n",
            "(0.6666666666666666, 0.985, 0.0025)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.8841666666666667, 0.01333333333333333)\n",
            "(1.0, 0.7383333333333333, 0.0075)\n",
            "(0.6658333333333334, 0.9975, 0.008333333333333333)\n",
            "(0.0, 1.0, 0.0033333333333333335)\n",
            "(0.3066666666666667, 0.9925, 0.0025)\n",
            "(0.3333333333333333, 0.9916666666666667, 0.005833333333333334)\n",
            "(0.3333333333333333, 0.9783333333333334, 0.0025)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(0.3333333333333333, 1.0, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9991666666666666, 0.0025)\n",
            "(0.6666666666666666, 0.9958333333333332, 0.0033333333333333335)\n",
            "(1.0, 0.25333333333333335, 0.2641666666666666)\n",
            "(0.6666666666666666, 0.19666666666666666, 0.5725)\n",
            "(0.3333333333333333, 0.9133333333333334, 0.16666666666666666)\n",
            "(0.3, 0.9983333333333334, 0.0025)\n",
            "(0.3333333333333333, 0.8633333333333333, 0.0025)\n",
            "(0.3325, 0.9866666666666667, 0.005833333333333334)\n",
            "(0.6658333333333334, 0.0016666666666666668, 0.3183333333333333)\n",
            "(1.0, 0.0016666666666666668, 0.3158333333333333)\n",
            "(0.33083333333333337, 0.8158333333333333, 0.3)\n",
            "(0.3333333333333333, 0.995, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9783333333333334, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.8408333333333333, 0.0025)\n",
            "(0.5891666666666667, 0.995, 0.0025)\n",
            "(0.6666666666666666, 0.7808333333333333, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9858333333333333, 0.0025)\n",
            "(0.21166666666666667, 0.9741666666666667, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.98, 0.0025)\n",
            "(0.3333333333333333, 0.9616666666666668, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.9958333333333335, 0.004166666666666667)\n",
            "(0.6666666666666666, 0.9883333333333333, 0.0025)\n",
            "(0.3333333333333333, 0.9975, 0.004166666666666667)\n",
            "(0.29583333333333334, 0.975, 0.0033333333333333335)\n",
            "(0.6666666666666666, 1.0, 0.005)\n",
            "(1.0, 0.9983333333333334, 0.0025)\n",
            "(1.0, 0.31833333333333336, 0.005833333333333334)\n",
            "(0.32916666666666666, 0.5708333333333333, 0.0025)\n",
            "(0.6666666666666666, 0.9958333333333332, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.9899999999999999, 0.004166666666666667)\n",
            "(0.3333333333333333, 0.7999999999999999, 0.0025)\n",
            "(0.3333333333333333, 0.06166666666666667, 0.6283333333333333)\n",
            "(0.6658333333333334, 0.9908333333333333, 0.23416666666666663)\n",
            "(1.0, 0.0, 0.32916666666666666)\n",
            "(0.6666666666666666, 0.9458333333333333, 0.0033333333333333335)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(1.0, 0.9016666666666667, 0.0025)\n",
            "(0.0, 0.9883333333333333, 0.011666666666666667)\n",
            "(0.255, 0.8883333333333333, 0.0025)\n",
            "(0.6666666666666666, 0.9975, 0.004166666666666667)\n",
            "(0.6666666666666666, 0.29833333333333334, 0.12)\n",
            "(0.5033333333333333, 0.2916666666666667, 0.0025)\n",
            "(0.9983333333333334, 0.9708333333333333, 0.0025)\n",
            "(0.6666666666666666, 0.9541666666666666, 0.0025)\n",
            "(0.605, 0.9241666666666667, 0.0033333333333333335)\n",
            "(0.0, 0.9991666666666666, 0.0025)\n",
            "(0.6666666666666666, 0.8216666666666667, 0.0025)\n",
            "(0.6666666666666666, 0.9550000000000001, 0.0025)\n",
            "(1.0, 0.985, 0.0075)\n",
            "(1.0, 0.7208333333333333, 0.0025)\n",
            "(0.6666666666666666, 0.11750000000000001, 0.6433333333333334)\n",
            "(0.6658333333333334, 0.8975000000000001, 0.27999999999999997)\n",
            "(0.6666666666666666, 0.9983333333333334, 0.0025)\n",
            "(0.6666666666666666, 0.8366666666666666, 0.0033333333333333335)\n",
            "(0.0, 0.9933333333333333, 0.0033333333333333335)\n",
            "(0.0, 0.9975, 0.0025)\n",
            "(1.0, 0.9900000000000001, 0.0025)\n",
            "(0.6666666666666666, 0.17, 0.5950000000000001)\n",
            "(0.6666666666666666, 0.9316666666666666, 0.0025)\n",
            "(0.3333333333333333, 1.0, 0.005)\n",
            "(1.0, 0.013333333333333334, 0.31)\n",
            "(0.6666666666666666, 0.15583333333333335, 0.6033333333333334)\n",
            "(0.6666666666666666, 0.0008333333333333334, 0.8966666666666666)\n",
            "(0.0, 0.0075, 0.9358333333333334)\n",
            "(0.3333333333333333, 1.0, 0.0025)\n",
            "(1.0, 1.0, 0.0025)\n",
            "(0.3333333333333333, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.10666666666666667, 0.5458333333333334)\n",
            "(0.0, 0.9958333333333335, 0.25666666666666665)\n",
            "(0.3333333333333333, 0.8650000000000001, 0.0025)\n",
            "(0.0, 0.9950000000000001, 0.0025)\n",
            "(0.6666666666666666, 0.0008333333333333334, 0.29083333333333333)\n",
            "(0.5241666666666667, 0.9533333333333333, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9900000000000001, 0.0025)\n",
            "(0.3333333333333333, 0.9166666666666666, 0.0033333333333333335)\n",
            "(0.47500000000000003, 0.2333333333333333, 0.012499999999999999)\n",
            "(1.0, 0.9783333333333334, 0.004166666666666667)\n",
            "(0.3333333333333333, 0.5783333333333333, 0.295)\n",
            "(0.0, 0.9708333333333333, 0.0025)\n",
            "(0.0, 1.0, 0.0033333333333333335)\n",
            "(0.34, 0.9825, 0.0033333333333333335)\n",
            "(1.0, 0.145, 0.5875)\n",
            "(0.06, 0.9874999999999999, 0.2575)\n",
            "(0.6666666666666666, 0.5141666666666667, 0.01916666666666667)\n",
            "(0.3333333333333333, 1.0, 0.005)\n",
            "(0.6666666666666666, 0.6866666666666666, 0.0025)\n",
            "(0.6666666666666666, 0.9025, 0.006666666666666665)\n",
            "(0.3333333333333333, 0.9541666666666666, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9975, 0.0025)\n",
            "(0.3325, 0.9950000000000001, 0.0025)\n",
            "(0.6666666666666666, 0.9916666666666667, 0.0025)\n",
            "(0.0, 0.9991666666666666, 0.0025)\n",
            "(0.3333333333333333, 1.0, 0.004166666666666667)\n",
            "(0.6575000000000001, 0.10666666666666667, 0.3158333333333333)\n",
            "(0.3333333333333333, 0.9941666666666666, 0.24666666666666662)\n",
            "(0.6666666666666666, 0.9800000000000001, 0.004166666666666667)\n",
            "(0.0, 0.9991666666666666, 0.0025)\n",
            "(0.6666666666666666, 0.9641666666666667, 0.0025)\n",
            "(1.0, 0.016666666666666666, 0.3233333333333333)\n",
            "(0.0, 0.43083333333333335, 0.30249999999999994)\n",
            "(0.6666666666666666, 0.39666666666666667, 0.005)\n",
            "(0.3333333333333333, 0.9858333333333333, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.9708333333333333, 0.004166666666666667)\n",
            "(1.0, 0.9899999999999999, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.9941666666666666, 0.0025)\n",
            "(0.3333333333333333, 0.9908333333333333, 0.0025)\n",
            "(0.6666666666666666, 0.35000000000000003, 0.03)\n",
            "(0.3333333333333333, 0.8875000000000001, 0.2741666666666666)\n",
            "(0.6666666666666666, 0.9708333333333332, 0.005833333333333334)\n",
            "(0.6666666666666666, 0.4558333333333333, 0.2691666666666666)\n",
            "(0.6666666666666666, 0.6483333333333333, 0.012500000000000002)\n",
            "(0.3333333333333333, 0.9191666666666666, 0.0075)\n",
            "(0.7200000000000001, 0.08750000000000001, 0.2891666666666667)\n",
            "(0.3333333333333333, 1.0, 0.010833333333333334)\n",
            "(0.6666666666666666, 0.9133333333333332, 0.0025)\n",
            "(0.6666666666666666, 0.8266666666666667, 0.008333333333333333)\n",
            "(0.6641666666666667, 0.9725, 0.0033333333333333335)\n",
            "(0.0, 0.9975, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9958333333333332, 0.0025)\n",
            "(0.0, 0.9991666666666666, 0.0033333333333333335)\n",
            "(0.0, 0.9991666666666666, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.9975, 0.004166666666666667)\n",
            "(0.3333333333333333, 0.005, 0.6158333333333333)\n",
            "(0.6666666666666666, 0.24250000000000002, 0.3)\n",
            "(0.6666666666666666, 0.995, 0.0025)\n",
            "(0.0, 0.22083333333333333, 0.19416666666666663)\n",
            "(0.19999999999999998, 0.33916666666666667, 0.4791666666666667)\n",
            "(0.0, 0.9991666666666666, 0.0025)\n",
            "(0.6641666666666667, 0.9983333333333334, 0.0033333333333333335)\n",
            "(0.9883333333333333, 0.8458333333333332, 0.006666666666666665)\n",
            "(1.0, 0.4991666666666667, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.9158333333333334, 0.0025)\n",
            "(0.6666666666666666, 0.875, 0.005833333333333334)\n",
            "(0.3333333333333333, 0.7758333333333334, 0.015833333333333335)\n",
            "(0.6666666666666666, 0.30583333333333335, 0.2608333333333333)\n",
            "(0.3333333333333333, 0.9899999999999999, 0.0625)\n",
            "(0.3333333333333333, 0.9941666666666666, 0.0025)\n",
            "(0.0, 1.0, 0.005833333333333334)\n",
            "(1.0, 0.7491666666666666, 0.0075)\n",
            "(0.3333333333333333, 0.11416666666666668, 0.2658333333333333)\n",
            "(0.6666666666666666, 0.5416666666666666, 0.27999999999999997)\n",
            "(0.6666666666666666, 0.9975, 0.08666666666666667)\n",
            "(0.3333333333333333, 0.9633333333333334, 0.005)\n",
            "(0.3325, 0.9891666666666667, 0.0033333333333333335)\n",
            "(0.0, 0.6708333333333334, 0.016666666666666666)\n",
            "(0.6666666666666666, 0.8416666666666668, 0.006666666666666667)\n",
            "(0.9983333333333334, 0.9975, 0.0025)\n",
            "(0.6666666666666666, 0.9933333333333333, 0.0025)\n",
            "(0.3333333333333333, 0.32083333333333336, 0.49333333333333335)\n",
            "(0.6258333333333334, 0.9333333333333335, 0.0025)\n",
            "(0.6666666666666666, 0.9958333333333335, 0.0033333333333333335)\n",
            "(1.0, 0.9975, 0.0025)\n",
            "(0.6666666666666666, 0.9866666666666667, 0.0033333333333333335)\n",
            "(0.3283333333333333, 0.9958333333333335, 0.0025)\n",
            "(0.6666666666666666, 0.3358333333333334, 0.25833333333333336)\n",
            "(0.3333333333333333, 0.995, 0.004166666666666667)\n",
            "(1.0, 0.9858333333333333, 0.0025)\n",
            "(0.6666666666666666, 0.9808333333333333, 0.004166666666666667)\n",
            "(0.9858333333333333, 0.3441666666666667, 0.24833333333333332)\n",
            "(0.3333333333333333, 0.021666666666666667, 0.19249999999999998)\n",
            "(0.3333333333333333, 1.0, 0.07833333333333334)\n",
            "(0.6166666666666667, 0.9975, 0.0025)\n",
            "(0.665, 0.9975, 0.0025)\n",
            "(0.3333333333333333, 0.19083333333333333, 0.5)\n",
            "(0.0, 0.9975, 0.004166666666666667)\n",
            "(1.0, 0.01916666666666667, 0.3158333333333333)\n",
            "(0.0, 0.029166666666666664, 0.6425)\n",
            "(0.6666666666666666, 0.9941666666666666, 0.2891666666666666)\n",
            "(0.3333333333333333, 0.995, 0.0025)\n",
            "(0.29, 0.745, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9866666666666667, 0.005833333333333334)\n",
            "(0.33083333333333337, 0.8283333333333335, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.83, 0.0033333333333333335)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(0.0, 0.056666666666666664, 0.31416666666666665)\n",
            "(0.6666666666666666, 0.9816666666666666, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.7925, 0.0025)\n",
            "(0.3333333333333333, 0.0025, 0.32916666666666666)\n",
            "(0.3333333333333333, 0.9925, 0.2791666666666666)\n",
            "(1.0, 0.9966666666666667, 0.0025)\n",
            "(0.6033333333333334, 0.9841666666666667, 0.008333333333333333)\n",
            "(0.3333333333333333, 0.6333333333333333, 0.0025)\n",
            "(0.6666666666666666, 0.005, 0.615)\n",
            "(0.3333333333333333, 0.9808333333333333, 0.004166666666666667)\n",
            "(0.6666666666666666, 0.7549999999999999, 0.0025)\n",
            "(0.3333333333333333, 0.9891666666666667, 0.0025)\n",
            "(0.9125000000000001, 0.016666666666666666, 0.32416666666666666)\n",
            "(0.6666666666666666, 0.9516666666666667, 0.0033333333333333335)\n",
            "(1.0, 0.9874999999999999, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9874999999999999, 0.0025)\n",
            "(1.0, 0.9325, 0.004166666666666667)\n",
            "(0.6666666666666666, 0.8491666666666666, 0.015000000000000001)\n",
            "(0.5991666666666666, 0.93, 0.0025)\n",
            "(1.0, 0.9950000000000001, 0.0025)\n",
            "(0.5391666666666667, 0.9391666666666666, 0.0025)\n",
            "(0.6666666666666666, 0.9441666666666667, 0.005833333333333334)\n",
            "(0.3333333333333333, 0.9075000000000001, 0.0025)\n",
            "(0.3333333333333333, 0.6741666666666667, 0.13833333333333334)\n",
            "(0.3333333333333333, 0.9833333333333334, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.9966666666666667, 0.0033333333333333335)\n",
            "(1.0, 0.38083333333333336, 0.0025)\n",
            "(0.6666666666666666, 0.8424999999999999, 0.006666666666666667)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.9966666666666667, 0.0033333333333333335)\n",
            "(1.0, 0.9908333333333333, 0.0025)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(0.0, 1.0, 0.005833333333333334)\n",
            "(0.9441666666666667, 0.98, 0.0025)\n",
            "(0.3333333333333333, 0.9666666666666667, 0.0025)\n",
            "(0.3333333333333333, 0.9908333333333333, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9975, 0.0025)\n",
            "(1.0, 0.09833333333333334, 0.33916666666666667)\n",
            "(0.6666666666666666, 0.9950000000000001, 0.0075)\n",
            "(0.6666666666666666, 0.9891666666666667, 0.0025)\n",
            "(0.3333333333333333, 0.9975, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.995, 0.0033333333333333335)\n",
            "(0.9991666666666666, 0.28833333333333333, 0.1225)\n",
            "(0.6666666666666666, 0.995, 0.004166666666666667)\n",
            "(1.0, 0.8866666666666667, 0.005)\n",
            "(0.3333333333333333, 0.9916666666666667, 0.006666666666666665)\n",
            "(0.0, 0.965, 0.0025)\n",
            "(0.3333333333333333, 0.9191666666666668, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.8150000000000001, 0.08166666666666667)\n",
            "(0.3333333333333333, 0.051666666666666666, 0.32916666666666666)\n",
            "(0.6666666666666666, 0.8099999999999999, 0.012500000000000002)\n",
            "(0.6666666666666666, 0.9891666666666667, 0.0075)\n",
            "(0.33083333333333337, 0.9933333333333333, 0.004166666666666667)\n",
            "(0.3333333333333333, 0.9966666666666667, 0.0033333333333333335)\n",
            "(0.0, 0.9950000000000001, 0.0025)\n",
            "(0.3333333333333333, 0.8641666666666667, 0.0033333333333333335)\n",
            "(0.5575, 0.605, 0.015)\n",
            "(0.6666666666666666, 0.9991666666666666, 0.0025)\n",
            "(0.6666666666666666, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.9933333333333333, 0.0025)\n",
            "(0.6666666666666666, 0.9899999999999999, 0.0025)\n",
            "(0.6666666666666666, 1.0, 0.0033333333333333335)\n",
            "(0.6658333333333334, 0.9866666666666667, 0.0025)\n",
            "(0.0, 0.01, 0.30416666666666664)\n",
            "(0.6666666666666666, 0.13166666666666668, 0.5975)\n",
            "(0.3333333333333333, 0.9633333333333334, 0.0025)\n",
            "(0.6666666666666666, 0.9958333333333335, 0.0025)\n",
            "(0.5808333333333334, 0.9983333333333334, 0.0025)\n",
            "(0.6641666666666667, 0.9175, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.24833333333333332, 0.265)\n",
            "(0.3125, 0.8058333333333333, 0.26249999999999996)\n",
            "(0.6666666666666666, 0.9750000000000001, 0.011666666666666665)\n",
            "(0.3333333333333333, 0.08833333333333333, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.155, 0.8891666666666667)\n",
            "(0.12833333333333333, 0.9725, 0.235)\n",
            "(0.3333333333333333, 1.0, 0.0025)\n",
            "(0.6666666666666666, 0.93, 0.005)\n",
            "(0.3333333333333333, 0.9966666666666667, 0.006666666666666667)\n",
            "(1.0, 0.9683333333333334, 0.005)\n",
            "(0.3333333333333333, 1.0, 0.0033333333333333335)\n",
            "(0.0, 0.9925, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.6308333333333334, 0.0025)\n",
            "(1.0, 0.9058333333333334, 0.29)\n",
            "(0.0, 0.2733333333333333, 0.0033333333333333335)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.9975, 0.005833333333333334)\n",
            "(0.3333333333333333, 1.0, 0.0025)\n",
            "(0.05833333333333333, 0.1758333333333333, 0.5475)\n",
            "(0.0, 0.9983333333333334, 0.0025)\n",
            "(0.6666666666666666, 0.20166666666666666, 0.62)\n",
            "(0.6666666666666666, 0.9966666666666667, 0.004166666666666667)\n",
            "(1.0, 0.08083333333333333, 0.5983333333333333)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(1.0, 0.20666666666666667, 0.0025)\n",
            "(0.6666666666666666, 0.9825, 0.0025)\n",
            "(0.6666666666666666, 0.9933333333333335, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9575, 0.004166666666666667)\n",
            "(0.6666666666666666, 0.15083333333333335, 0.3016666666666667)\n",
            "(0.3333333333333333, 0.8441666666666666, 0.29250000000000004)\n",
            "(0.33, 0.9608333333333334, 0.0025)\n",
            "(0.3333333333333333, 0.9166666666666666, 0.0025)\n",
            "(0.3333333333333333, 0.9941666666666666, 0.0025)\n",
            "(0.0, 0.9966666666666667, 0.0025)\n",
            "(0.0, 0.9975, 0.0025)\n",
            "(0.6666666666666666, 0.08916666666666666, 0.2841666666666666)\n",
            "(1.0, 0.6075, 0.0025)\n",
            "(0.3333333333333333, 0.9875000000000002, 0.0025)\n",
            "(0.6666666666666666, 0.9900000000000001, 0.0025)\n",
            "(0.6666666666666666, 0.8875000000000001, 0.004166666666666667)\n",
            "(0.33166666666666667, 1.0, 0.0033333333333333335)\n",
            "(0.0, 1.0, 0.0033333333333333335)\n",
            "(1.0, 0.9975, 0.0025)\n",
            "(0.6658333333333334, 1.0, 0.0025)\n",
            "(0.6666666666666666, 0.965, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.5566666666666668, 0.0033333333333333335)\n",
            "(0.6158333333333333, 0.6975000000000001, 0.08833333333333333)\n",
            "(0.6666666666666666, 1.0, 0.0025)\n",
            "(0.6666666666666666, 0.31083333333333335, 0.3233333333333333)\n",
            "(0.6666666666666666, 0.9966666666666667, 0.15833333333333333)\n",
            "(0.3333333333333333, 1.0, 0.0025)\n",
            "(1.0, 0.9616666666666666, 0.0025)\n",
            "(0.6666666666666666, 0.5958333333333333, 0.005833333333333334)\n",
            "(0.3333333333333333, 0.8374999999999999, 0.0033333333333333335)\n",
            "(0.33083333333333337, 0.4908333333333334, 0.012499999999999999)\n",
            "(0.9991666666666666, 0.9966666666666667, 0.0033333333333333335)\n",
            "(0.0, 0.011666666666666667, 0.0025)\n",
            "(1.0, 0.7866666666666666, 0.31999999999999995)\n",
            "(0.6666666666666666, 0.6233333333333333, 0.023333333333333334)\n",
            "(0.3016666666666667, 0.9966666666666667, 0.0025)\n",
            "(0.0, 0.9933333333333333, 0.0025)\n",
            "(1.0, 0.9908333333333333, 0.005)\n",
            "(0.3333333333333333, 0.9049999999999999, 0.0025)\n",
            "(0.6666666666666666, 0.9500000000000001, 0.0025)\n",
            "(0.6666666666666666, 0.5958333333333333, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9991666666666666, 0.004166666666666667)\n",
            "(0.6666666666666666, 0.8858333333333333, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.9483333333333333, 0.0033333333333333335)\n",
            "(0.665, 0.15416666666666667, 0.0025)\n",
            "(0.6666666666666666, 0.9941666666666668, 0.2758333333333333)\n",
            "(0.6666666666666666, 0.20000000000000004, 0.31666666666666665)\n",
            "(0.3333333333333333, 0.9091666666666667, 0.0025)\n",
            "(0.3333333333333333, 0.9616666666666666, 0.0025)\n",
            "(0.6666666666666666, 0.28833333333333333, 0.25916666666666666)\n",
            "(0.3333333333333333, 0.22166666666666668, 0.8683333333333333)\n",
            "(0.3275, 0.9975, 0.0033333333333333335)\n",
            "(0.0, 0.19333333333333336, 0.4991666666666667)\n",
            "(1.0, 0.2708333333333333, 0.4766666666666666)\n",
            "(0.3333333333333333, 0.9891666666666667, 0.0025)\n",
            "(0.6666666666666666, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.9616666666666666, 0.0025)\n",
            "(0.3333333333333333, 0.5558333333333333, 0.004166666666666667)\n",
            "(0.6666666666666666, 0.9916666666666667, 0.0033333333333333335)\n",
            "(0.6666666666666666, 1.0, 0.0033333333333333335)\n",
            "(0.051666666666666666, 0.8708333333333335, 0.0025)\n",
            "(0.0, 0.9908333333333333, 0.0025)\n",
            "(1.0, 0.9725, 0.0025)\n",
            "(0.6666666666666666, 0.8300000000000001, 0.0025)\n",
            "(0.0, 0.9983333333333334, 0.0025)\n",
            "(0.6666666666666666, 0.8358333333333334, 0.0025)\n",
            "(0.3333333333333333, 0.5625, 0.0075)\n",
            "(0.6666666666666666, 0.9541666666666666, 0.01)\n",
            "(0.3333333333333333, 0.9983333333333334, 0.0033333333333333335)\n",
            "(0.0, 0.9983333333333334, 0.005)\n",
            "(0.6666666666666666, 0.9941666666666666, 0.004166666666666667)\n",
            "(0.0, 0.28583333333333333, 0.5016666666666666)\n",
            "(0.6666666666666666, 0.9341666666666667, 0.010833333333333334)\n",
            "(0.6658333333333334, 0.735, 0.005)\n",
            "(0.6666666666666666, 1.0, 0.0025)\n",
            "(0.6666666666666666, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.9225, 0.0025)\n",
            "(0.9966666666666667, 0.8816666666666667, 0.0025)\n",
            "(0.0, 0.9824999999999999, 0.0025)\n",
            "(1.0, 0.9983333333333334, 0.0033333333333333335)\n",
            "(0.64, 0.9841666666666665, 0.0025)\n",
            "(0.0, 0.9975, 0.005)\n",
            "(0.0, 1.0, 0.004166666666666667)\n",
            "(0.3333333333333333, 0.05333333333333334, 0.6133333333333333)\n",
            "(0.6566666666666666, 0.4575, 0.2608333333333333)\n",
            "(0.3333333333333333, 0.18666666666666665, 0.2658333333333333)\n",
            "(1.0, 0.9900000000000001, 0.10916666666666668)\n",
            "(0.3333333333333333, 0.9491666666666667, 0.0025)\n",
            "(0.6666666666666666, 0.2125, 0.43083333333333335)\n",
            "(0.6666666666666666, 0.9908333333333333, 0.005)\n",
            "(0.3333333333333333, 0.9983333333333334, 0.0025)\n",
            "(0.6666666666666666, 0.049999999999999996, 0.6183333333333333)\n",
            "(0.3333333333333333, 0.14583333333333334, 0.8558333333333333)\n",
            "(0.3333333333333333, 0.20166666666666666, 0.5708333333333333)\n",
            "(0.6666666666666666, 0.9858333333333335, 0.07833333333333334)\n",
            "(0.3333333333333333, 0.023333333333333334, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9983333333333334, 0.20666666666666664)\n",
            "(0.6666666666666666, 0.965, 0.004166666666666667)\n",
            "(0.3333333333333333, 0.9950000000000001, 0.0025)\n",
            "(0.0, 0.9983333333333334, 0.0025)\n",
            "(0.0, 0.9975, 0.0025)\n",
            "(0.6666666666666666, 0.9925, 0.005)\n",
            "(0.3333333333333333, 0.9683333333333334, 0.0025)\n",
            "(0.3333333333333333, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.2783333333333333, 0.23750000000000002)\n",
            "(0.3333333333333333, 0.0, 0.6033333333333334)\n",
            "(1.0, 0.3866666666666667, 0.43166666666666664)\n",
            "(0.3333333333333333, 0.9941666666666666, 0.050833333333333335)\n",
            "(0.0, 0.9991666666666666, 0.0025)\n",
            "(0.0, 0.9975, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.46083333333333326, 0.030833333333333334)\n",
            "(0.6666666666666666, 0.9941666666666666, 0.0025)\n",
            "(0.3333333333333333, 0.9958333333333332, 0.0025)\n",
            "(0.665, 0.7025, 0.0033333333333333335)\n",
            "(1.0, 0.2891666666666667, 0.41)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(0.6666666666666666, 0.9991666666666666, 0.0025)\n",
            "(1.0, 0.19333333333333336, 0.295)\n",
            "(0.6666666666666666, 0.935, 0.0025)\n",
            "(0.6666666666666666, 0.7241666666666666, 0.0025)\n",
            "(0.0, 0.9900000000000001, 0.006666666666666665)\n",
            "(0.6666666666666666, 0.34, 0.008333333333333333)\n",
            "(0.6666666666666666, 0.9133333333333334, 0.006666666666666667)\n",
            "(0.0, 0.9991666666666666, 0.005)\n",
            "(1.0, 0.8491666666666666, 0.0025)\n",
            "(0.6666666666666666, 1.0, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.84, 0.0025)\n",
            "(0.3333333333333333, 0.9500000000000001, 0.0025)\n",
            "(0.3333333333333333, 0.9049999999999999, 0.0025)\n",
            "(0.3333333333333333, 0.9966666666666667, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.69, 0.07833333333333334)\n",
            "(0.6666666666666666, 0.8375, 0.0025)\n",
            "(0.3333333333333333, 0.9583333333333334, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.10333333333333333, 0.30916666666666665)\n",
            "(0.6666666666666666, 1.0, 0.0575)\n",
            "(0.6666666666666666, 0.9950000000000001, 0.0025)\n",
            "(0.3333333333333333, 1.0, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.5158333333333333, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.4275, 0.165)\n",
            "(0.6666666666666666, 0.14416666666666667, 0.8508333333333334)\n",
            "(0.0, 0.9991666666666666, 0.030833333333333334)\n",
            "(0.3333333333333333, 0.33416666666666667, 0.0025)\n",
            "(0.3333333333333333, 0.7525, 0.0025)\n",
            "(0.3333333333333333, 0.9458333333333333, 0.09416666666666668)\n",
            "(0.3333333333333333, 1.0, 0.0033333333333333335)\n",
            "(0.0, 0.9525, 0.0025)\n",
            "(0.6666666666666666, 0.46083333333333326, 0.008333333333333333)\n",
            "(0.3333333333333333, 0.3208333333333333, 0.05333333333333334)\n",
            "(0.0, 1.0, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9933333333333333, 0.0025)\n",
            "(0.3333333333333333, 0.9991666666666666, 0.0025)\n",
            "(0.9625, 0.0525, 0.31083333333333335)\n",
            "(0.32666666666666666, 0.96, 0.2608333333333333)\n",
            "(0.6666666666666666, 0.9908333333333333, 0.005)\n",
            "(0.6666666666666666, 0.9575, 0.004166666666666667)\n",
            "(0.3333333333333333, 0.7608333333333333, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9991666666666666, 0.013333333333333334)\n",
            "(0.6658333333333334, 0.6833333333333335, 0.004166666666666667)\n",
            "(0.6666666666666666, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.995, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.004166666666666667, 0.6366666666666666)\n",
            "(0.6666666666666666, 0.9899999999999999, 0.0025)\n",
            "(0.3333333333333333, 0.005833333333333333, 0.3333333333333333)\n",
            "(1.0, 0.9725, 0.0025)\n",
            "(0.3325, 0.9408333333333333, 0.005833333333333334)\n",
            "(0.0, 0.2058333333333333, 0.0025)\n",
            "(0.3333333333333333, 0.9991666666666666, 0.27833333333333327)\n",
            "(0.3333333333333333, 0.8966666666666666, 0.0025)\n",
            "(0.0, 0.9883333333333333, 0.0033333333333333335)\n",
            "(0.0, 1.0, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9991666666666666, 0.005)\n",
            "(0.6391666666666667, 0.9958333333333335, 0.004166666666666667)\n",
            "(0.0, 0.6558333333333333, 0.009166666666666667)\n",
            "(0.3333333333333333, 0.9958333333333332, 0.0033333333333333335)\n",
            "(0.6616666666666666, 0.2933333333333333, 0.10000000000000002)\n",
            "(0.6666666666666666, 0.9775, 0.045000000000000005)\n",
            "(0.6666666666666666, 0.48333333333333334, 0.0025)\n",
            "(0.6666666666666666, 0.9366666666666666, 0.004166666666666667)\n",
            "(0.3333333333333333, 0.9958333333333332, 0.0025)\n",
            "(1.0, 0.9899999999999999, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.9433333333333334, 0.0025)\n",
            "(0.0, 1.0, 0.01)\n",
            "(0.3333333333333333, 0.011666666666666667, 0.0025)\n",
            "(0.3333333333333333, 0.9933333333333333, 0.0033333333333333335)\n",
            "(0.0, 0.9991666666666666, 0.008333333333333333)\n",
            "(0.0008333333333333334, 0.9616666666666668, 0.005)\n",
            "(0.3333333333333333, 0.13749999999999998, 0.23750000000000002)\n",
            "(0.3333333333333333, 0.9541666666666666, 0.004166666666666667)\n",
            "(0.3333333333333333, 1.0, 0.0025)\n",
            "(0.3333333333333333, 0.011666666666666667, 0.31749999999999995)\n",
            "(0.28250000000000003, 0.21833333333333335, 0.015833333333333335)\n",
            "(0.6666666666666666, 0.9083333333333333, 0.22416666666666663)\n",
            "(0.6666666666666666, 0.3758333333333333, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.8116666666666665, 0.07416666666666667)\n",
            "(0.3333333333333333, 0.8083333333333335, 0.01)\n",
            "(1.0, 0.8041666666666667, 0.004166666666666667)\n",
            "(0.3333333333333333, 0.9883333333333333, 0.0025)\n",
            "(0.3333333333333333, 0.5908333333333333, 0.006666666666666667)\n",
            "(0.0, 0.9508333333333333, 0.010833333333333334)\n",
            "(0.3325, 0.9683333333333334, 0.008333333333333333)\n",
            "(0.0, 0.9250000000000002, 0.0025)\n",
            "(0.3333333333333333, 0.9875000000000002, 0.005)\n",
            "(0.3333333333333333, 1.0, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.9975, 0.0025)\n",
            "(0.665, 0.0, 0.6383333333333333)\n",
            "(0.0, 1.0, 0.23249999999999996)\n",
            "(0.6566666666666667, 0.9966666666666667, 0.0025)\n",
            "(1.0, 0.985, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.7341666666666667, 0.005)\n",
            "(0.3333333333333333, 0.6491666666666666, 0.005833333333333334)\n",
            "(0.30833333333333335, 0.7441666666666666, 0.013333333333333334)\n",
            "(0.6666666666666666, 0.11499999999999999, 0.31916666666666665)\n",
            "(0.6666666666666666, 1.0, 0.0725)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(0.6658333333333334, 0.9758333333333334, 0.0025)\n",
            "(0.9983333333333334, 0.9366666666666666, 0.005)\n",
            "(0.2733333333333333, 0.9975, 0.0025)\n",
            "(0.6666666666666666, 0.8908333333333335, 0.0025)\n",
            "(1.0, 0.9508333333333333, 0.0025)\n",
            "(0.0, 1.0, 0.005833333333333334)\n",
            "(0.3333333333333333, 0.19166666666666665, 0.2733333333333334)\n",
            "(0.3333333333333333, 0.985, 0.0025)\n",
            "(0.3333333333333333, 0.98, 0.0025)\n",
            "(0.6666666666666666, 0.9674999999999999, 0.0025)\n",
            "(0.9991666666666666, 0.3225, 0.016666666666666666)\n",
            "(0.3333333333333333, 0.9983333333333334, 0.0025)\n",
            "(0.6666666666666666, 0.6750000000000002, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.9941666666666666, 0.005833333333333334)\n",
            "(0.3325, 0.8533333333333334, 0.01)\n",
            "(0.0, 0.9858333333333333, 0.0025)\n",
            "(0.3333333333333333, 1.0, 0.0025)\n",
            "(0.6666666666666666, 0.9366666666666666, 0.0025)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(0.0, 0.9991666666666666, 0.0025)\n",
            "(0.3333333333333333, 0.9991666666666666, 0.0025)\n",
            "(0.3333333333333333, 0.9725, 0.004166666666666667)\n",
            "(0.6666666666666666, 0.8633333333333333, 0.0025)\n",
            "(0.6516666666666667, 0.25333333333333335, 0.2575)\n",
            "(0.5591666666666667, 0.8716666666666667, 0.06083333333333333)\n",
            "(0.6666666666666666, 0.985, 0.005833333333333334)\n",
            "(0.6666666666666666, 1.0, 0.004166666666666667)\n",
            "(0.6658333333333334, 0.4608333333333334, 0.0025)\n",
            "(0.6666666666666666, 0.9575, 0.12916666666666668)\n",
            "(0.6258333333333334, 0.9983333333333334, 0.0025)\n",
            "(0.0, 0.48500000000000004, 0.2725)\n",
            "(0.32916666666666666, 0.9866666666666667, 0.2866666666666667)\n",
            "(0.3333333333333333, 0.9958333333333332, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.8675, 0.005833333333333334)\n",
            "(0.3333333333333333, 0.8966666666666666, 0.004166666666666667)\n",
            "(1.0, 0.7891666666666667, 0.012499999999999999)\n",
            "(0.6666666666666666, 0.9858333333333333, 0.004166666666666667)\n",
            "(0.3333333333333333, 0.9291666666666667, 0.0025)\n",
            "(0.3333333333333333, 0.9941666666666666, 0.0025)\n",
            "(0.6666666666666666, 0.4191666666666667, 0.0025)\n",
            "(0.6666666666666666, 0.0675, 0.31666666666666665)\n",
            "(0.6666666666666666, 0.59, 0.009166666666666665)\n",
            "(0.3333333333333333, 0.9991666666666666, 0.0025)\n",
            "(0.3333333333333333, 0.09999999999999999, 0.30333333333333334)\n",
            "(1.0, 0.9683333333333334, 0.015000000000000001)\n",
            "(0.3333333333333333, 0.9941666666666666, 0.009166666666666668)\n",
            "(0.6741666666666667, 0.9558333333333334, 0.0025)\n",
            "(0.3333333333333333, 0.9575, 0.0025)\n",
            "(0.3333333333333333, 0.9333333333333332, 0.0025)\n",
            "(0.6666666666666666, 0.30166666666666664, 0.2875)\n",
            "(0.6666666666666666, 0.9883333333333333, 0.3258333333333333)\n",
            "(0.6666666666666666, 0.9725, 0.0033333333333333335)\n",
            "(1.0, 0.9624999999999999, 0.0025)\n",
            "(0.0, 0.9966666666666667, 0.0025)\n",
            "(0.6666666666666666, 0.815, 0.0025)\n",
            "(0.3333333333333333, 0.9983333333333334, 0.005833333333333334)\n",
            "(0.0, 0.9891666666666667, 0.0025)\n",
            "(0.3333333333333333, 0.9608333333333334, 0.0025)\n",
            "(1.0, 0.9900000000000001, 0.0025)\n",
            "(0.6666666666666666, 1.0, 0.0025)\n",
            "(0.6666666666666666, 0.9866666666666667, 0.0025)\n",
            "(0.6666666666666666, 0.9908333333333333, 0.0025)\n",
            "(0.3333333333333333, 0.9583333333333334, 0.0025)\n",
            "(0.0, 0.10666666666666667, 0.33749999999999997)\n",
            "(0.3333333333333333, 0.9141666666666666, 0.31749999999999995)\n",
            "(0.6666666666666666, 0.6675, 0.05000000000000001)\n",
            "(0.9991666666666666, 0.8083333333333332, 0.0025)\n",
            "(0.0, 0.33916666666666667, 0.0025)\n",
            "(0.3333333333333333, 0.9941666666666666, 0.008333333333333333)\n",
            "(0.3333333333333333, 1.0, 0.0025)\n",
            "(1.0, 0.9991666666666666, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9958333333333332, 0.0025)\n",
            "(0.9925, 0.9283333333333333, 0.006666666666666667)\n",
            "(1.0, 0.9416666666666665, 0.0033333333333333335)\n",
            "(0.6666666666666666, 0.33416666666666667, 0.0025)\n",
            "(0.3333333333333333, 0.9975, 0.0025)\n",
            "(0.6666666666666666, 0.9308333333333333, 0.0025)\n",
            "(1.0, 0.9983333333333334, 0.0025)\n",
            "(0.3333333333333333, 0.0625, 0.29333333333333333)\n",
            "(0.3333333333333333, 0.9858333333333333, 0.0033333333333333335)\n",
            "(1.0, 0.9966666666666667, 0.0025)\n",
            "(0.3333333333333333, 0.9791666666666666, 0.0025)\n",
            "(0.3333333333333333, 0.9950000000000001, 0.005)\n",
            "(1.0, 1.0, 0.0033333333333333335)\n",
            "(0.0, 1.0, 0.0025)\n",
            "(1.0, 1.0, 0.004166666666666667)\n",
            "(0.665, 0.9266666666666667, 0.004166666666666667)\n",
            "(0.3333333333333333, 0.9883333333333333, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9091666666666667, 0.0025)\n",
            "(0.3333333333333333, 0.995, 0.0033333333333333335)\n",
            "(0.6666666666666666, 1.0, 0.0025)\n",
            "(0.9049999999999999, 0.6566666666666666, 0.02333333333333333)\n",
            "(0.6666666666666666, 0.4291666666666667, 0.0025)\n",
            "(0.6666666666666666, 0.25166666666666665, 0.006666666666666667)\n",
            "(0.3333333333333333, 0.9991666666666666, 0.009166666666666667)\n",
            "(0.0, 0.9991666666666666, 0.0025)\n",
            "(0.33166666666666667, 0.9466666666666667, 0.0075)\n",
            "(0.6625, 0.9975, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.9433333333333334, 0.0033333333333333335)\n",
            "(0.3333333333333333, 0.6783333333333333, 0.0025)\n"
          ]
        }
      ],
      "source": [
        "# Mapping of csv column indices to varying parameter names\n",
        "csv_column_to_param = {\n",
        "    0: 'lam',\n",
        "    1: 'zeta_1',\n",
        "    2: 'zeta_2',\n",
        "    3: 'zeta_3',\n",
        "    4: 'zeta_4',\n",
        "    5: 'beta_PP',\n",
        "    6: 'beta_NP',\n",
        "    7: 'beta_PN'\n",
        "}\n",
        "\n",
        "# read the LHS parameter csv\n",
        "df = pd.read_csv('/content/drive/My Drive/Information_Behavior_Disease_Networks/LHS/LHS_parameters_1000_samples.csv', header=None)\n",
        "\n",
        "# fixed parameters\n",
        "fixed_params = {\n",
        "    'inw': inw,\n",
        "    'ldeg_i': ldeg_i,\n",
        "    'ltre': ltre,\n",
        "    'cnw': cnw,\n",
        "    'ldeg_c': ldeg_c,\n",
        "    'lprot': lprot,\n",
        "    'enw': enw,\n",
        "    'ldeg_e': ldeg_e,\n",
        "    'alp': alp,\n",
        "    'beta_NN': beta_NN,\n",
        "    'mu': mu,\n",
        "    'n_sample': n_sample2\n",
        "}\n",
        "\n",
        "\n",
        "# order of all parameters\n",
        "param_order = ['inw', 'ldeg_i', 'ltre', 'cnw', 'ldeg_c', 'lprot', 'enw', 'ldeg_e', 'lam', 'alp', 'zeta_1', 'zeta_2', 'zeta_3', 'zeta_4', 'beta_PP', 'beta_NP', 'beta_PN', 'beta_NN', 'mu', 'n_sample']\n",
        "\n",
        "\n",
        "# run the model for each sample\n",
        "outputs = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    params_from_csv = {csv_column_to_param[i]: row[i] for i in csv_column_to_param.keys()}\n",
        "\n",
        "    ordered_params = [params_from_csv[p] if p in params_from_csv else fixed_params[p] for p in param_order]\n",
        "\n",
        "    output = ICE_model_no_control(*ordered_params)\n",
        "    outputs.append(output)\n",
        "    print(output)\n",
        "\n",
        "# store outputs\n",
        "output_df2 = pd.DataFrame({'Output': outputs})\n",
        "output_df2.to_csv('/content/drive/My Drive/Information_Behavior_Disease_Networks/LHS/LHS_1000_samples_outputs_modified_2.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pR62eE2plWrG"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the varying parameters\n",
        "params_df2 = pd.read_csv('/content/drive/My Drive/Information_Behavior_Disease_Networks/LHS/LHS_parameters_1000_samples.csv', header=None)\n",
        "\n",
        "# Load the outputs (excluding the header)\n",
        "outputs_df2 = pd.read_csv('/content/drive/My Drive/Information_Behavior_Disease_Networks/LHS/LHS_1000_samples_outputs_modified_2.csv', skiprows=1, header=None)\n",
        "#outputs2 = outputs_df2.iloc[:, 0].values\n",
        "outputs2 = outputs_df2.iloc[:, 0].apply(lambda x: float(x.split(\", \")[2].strip(\"()\"))).values\n",
        "\n",
        "# Define your problem again\n",
        "problem = {\n",
        "    'num_vars': 8,\n",
        "    'names': ['Lambda', 'Zeta_1', 'Zeta_2', 'Zeta_3', 'Zeta_4', 'beta_PP', 'beta_NP', 'beta_PN'],\n",
        "    'bounds': [[0, 1], [0, 0.2], [0, 0.2], [0, 0.2], [0, 0.2], [0, 0.05], [0.05, 0.2], [0.2, 0.4]]\n",
        "}\n",
        "\n",
        "# Perform Saltelli sampling\n",
        "param_samples2 = params_df2.values\n",
        "\n",
        "# Initialize an array to store PRCC results\n",
        "prcc_results2 = np.zeros((problem['num_vars'],))\n",
        "\n",
        "# Iterate through each parameter and calculate PRCC\n",
        "for i, param_name in enumerate(problem['names']):\n",
        "    X = param_samples2[:, i]\n",
        "\n",
        "    prcc_result = np.corrcoef(X, outputs2)[0, 1]\n",
        "    prcc_results2[i] = prcc_result\n",
        "\n",
        "# Print PRCC results\n",
        "for i, param_name in enumerate(problem['names']):\n",
        "    print(f\"{param_name}: {prcc_results2[i]}\")\n",
        "\n",
        "    # Latex math symbols for parameter labels\n",
        "param_labels = ['$\\lambda$', '$\\zeta_1$', '$\\zeta_2$', '$\\zeta_3$','$\\zeta_4$',r'$\\beta_{PP}$', r'$\\beta_{NP}$', r'$\\beta_{PN}$']\n",
        "\n",
        "# Plot PRCC results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(param_labels, prcc_results2, color='orange')\n",
        "plt.xlabel('Parameters', fontsize=16)\n",
        "plt.ylabel('PRCC Value', fontsize=16)\n",
        "plt.title('PRCC Sensitivity Analysis', fontsize=16)\n",
        "plt.xticks(rotation=45, fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.grid(axis='y')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "H6hzOy6GlnYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "636a09c9-8696-445e-dc0f-96ed81f05f48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SALib in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from SALib) (3.7.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from SALib) (0.70.15)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from SALib) (1.26.0)\n",
            "Requirement already satisfied: pandas>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from SALib) (1.5.3)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.10/dist-packages (from SALib) (1.11.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->SALib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.2->SALib) (2023.3.post1)\n",
            "Requirement already satisfied: dill>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from multiprocess->SALib) (0.3.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.2.2->SALib) (1.16.0)\n",
            "Lambda: PRCC=0.0227, 95% CI=(-0.0394, 0.0845), p-value=0.4740\n",
            "Zeta_1: PRCC=0.0386, 95% CI=(-0.0234, 0.1004), p-value=0.2225\n",
            "Zeta_2: PRCC=-0.3940, 95% CI=(-0.4452, -0.3404), p-value=0.0000\n",
            "Zeta_3: PRCC=0.2845, 95% CI=(0.2265, 0.3404), p-value=0.0000\n",
            "Zeta_4: PRCC=-0.1387, 95% CI=(-0.1990, -0.0774), p-value=0.0000\n",
            "beta_PP: PRCC=0.0295, 95% CI=(-0.0325, 0.0914), p-value=0.3509\n",
            "beta_NP: PRCC=0.0337, 95% CI=(-0.0284, 0.0955), p-value=0.2876\n",
            "beta_PN: PRCC=0.0337, 95% CI=(-0.0284, 0.0955), p-value=0.2876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-79c8fc47de00>:7: DeprecationWarning: Please use `pearsonr` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
            "  from scipy.stats.stats import pearsonr\n"
          ]
        }
      ],
      "source": [
        "!pip install SALib\n",
        "from SALib.sample import saltelli\n",
        "from SALib.analyze import sobol\n",
        "import matplotlib.pyplot as plt\n",
        "from SALib.sample import saltelli\n",
        "from scipy.stats import norm\n",
        "from scipy.stats.stats import pearsonr\n",
        "\n",
        "# Load the varying parameters\n",
        "params_df3 = pd.read_csv('/content/drive/My Drive/Information_Behavior_Disease_Networks/LHS/LHS_parameters_1000_samples.csv', header=None)\n",
        "\n",
        "# Load the outputs (excluding the header)\n",
        "outputs_df3 = pd.read_csv('/content/drive/My Drive/Information_Behavior_Disease_Networks/LHS/LHS_1000_samples_outputs_modified_2.csv', skiprows=1, header=None)\n",
        "#outputs3 = outputs_df3.iloc[:, 0].values\n",
        "outputs3 = outputs_df3.iloc[:, 0].apply(lambda x: float(x.split(\", \")[2].strip(\"()\"))).values\n",
        "\n",
        "\n",
        "# Define your problem again\n",
        "problem = {\n",
        "    'num_vars': 8,\n",
        "    'names': ['Lambda', 'Zeta_1', 'Zeta_2', 'Zeta_3', 'Zeta_4', 'beta_PP', 'beta_NP', 'beta_PN'],\n",
        "    'bounds': [[0, 1], [0, 0.2], [0, 0.2], [0, 0.2], [0, 0.2], [0, 0.05], [0.05, 0.2], [0.2, 0.4]]\n",
        "}\n",
        "\n",
        "# Perform Saltelli sampling\n",
        "param_samples3 = params_df3.values\n",
        "\n",
        "# Initialize arrays to store PRCC results, CI, and p-values\n",
        "prcc_results3 = np.zeros((problem['num_vars'],))\n",
        "ci_lower = np.zeros((problem['num_vars'],))\n",
        "ci_upper = np.zeros((problem['num_vars'],))\n",
        "p_values = np.zeros((problem['num_vars'],))\n",
        "\n",
        "# Iterate through each parameter and calculate PRCC\n",
        "for i, param_name in enumerate(problem['names']):\n",
        "    X = param_samples3[:, i]\n",
        "    Y = outputs3\n",
        "\n",
        "    # Calculate PRCC using Pearson correlation coefficient\n",
        "    prcc_result, p_value = pearsonr(X, Y)\n",
        "    prcc_results3[i] = prcc_result\n",
        "\n",
        "    # Calculate 95% CI for the PRCC using Fisher's Z-transform\n",
        "    n = len(X)\n",
        "    z_value = 0.5 * np.log((1 + prcc_result) / (1 - prcc_result))\n",
        "    se = 1 / np.sqrt(n - 3)\n",
        "    z_critical = norm.ppf(0.975)\n",
        "    ci_lower[i] = np.tanh(z_value - z_critical * se)\n",
        "    ci_upper[i] = np.tanh(z_value + z_critical * se)\n",
        "\n",
        "    # Store p-value\n",
        "    p_values[i] = p_value\n",
        "\n",
        "# Print PRCC results, CI, and p-values\n",
        "for i, param_name in enumerate(problem['names']):\n",
        "    print(f\"{param_name}: PRCC={prcc_results3[i]:.4f}, 95% CI=({ci_lower[i]:.4f}, {ci_upper[i]:.4f}), p-value={p_values[i]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "s6qOePfgmR0s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 900
        },
        "outputId": "41713431-eaed-44f2-ecd0-ef1e4b99d99f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:2: DeprecationWarning: invalid escape sequence '\\l'\n",
            "<>:2: DeprecationWarning: invalid escape sequence '\\z'\n",
            "<>:2: DeprecationWarning: invalid escape sequence '\\z'\n",
            "<>:2: DeprecationWarning: invalid escape sequence '\\z'\n",
            "<>:2: DeprecationWarning: invalid escape sequence '\\z'\n",
            "<>:2: DeprecationWarning: invalid escape sequence '\\l'\n",
            "<>:2: DeprecationWarning: invalid escape sequence '\\z'\n",
            "<>:2: DeprecationWarning: invalid escape sequence '\\z'\n",
            "<>:2: DeprecationWarning: invalid escape sequence '\\z'\n",
            "<>:2: DeprecationWarning: invalid escape sequence '\\z'\n",
            "<ipython-input-20-8abf405de05d>:2: DeprecationWarning: invalid escape sequence '\\l'\n",
            "  param_labels = ['$\\lambda$', '$\\zeta_1$', '$\\zeta_2$', '$\\zeta_3$', '$\\zeta_4$', r'$\\beta_{PP}$', r'$\\beta_{NP}$', r'$\\beta_{PN}$']\n",
            "<ipython-input-20-8abf405de05d>:2: DeprecationWarning: invalid escape sequence '\\z'\n",
            "  param_labels = ['$\\lambda$', '$\\zeta_1$', '$\\zeta_2$', '$\\zeta_3$', '$\\zeta_4$', r'$\\beta_{PP}$', r'$\\beta_{NP}$', r'$\\beta_{PN}$']\n",
            "<ipython-input-20-8abf405de05d>:2: DeprecationWarning: invalid escape sequence '\\z'\n",
            "  param_labels = ['$\\lambda$', '$\\zeta_1$', '$\\zeta_2$', '$\\zeta_3$', '$\\zeta_4$', r'$\\beta_{PP}$', r'$\\beta_{NP}$', r'$\\beta_{PN}$']\n",
            "<ipython-input-20-8abf405de05d>:2: DeprecationWarning: invalid escape sequence '\\z'\n",
            "  param_labels = ['$\\lambda$', '$\\zeta_1$', '$\\zeta_2$', '$\\zeta_3$', '$\\zeta_4$', r'$\\beta_{PP}$', r'$\\beta_{NP}$', r'$\\beta_{PN}$']\n",
            "<ipython-input-20-8abf405de05d>:2: DeprecationWarning: invalid escape sequence '\\z'\n",
            "  param_labels = ['$\\lambda$', '$\\zeta_1$', '$\\zeta_2$', '$\\zeta_3$', '$\\zeta_4$', r'$\\beta_{PP}$', r'$\\beta_{NP}$', r'$\\beta_{PN}$']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Latex math symbols for parameter labels\n",
        "param_labels = ['$\\lambda$', '$\\zeta_1$', '$\\zeta_2$', '$\\zeta_3$', '$\\zeta_4$', r'$\\beta_{PP}$', r'$\\beta_{NP}$', r'$\\beta_{PN}$']\n",
        "\n",
        "# Plot PRCC results with error bars\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.barh(param_labels, prcc_results3, color='yellowgreen')\n",
        "\n",
        "# Add error bars (95% CI)\n",
        "for i, bar in enumerate(bars):\n",
        "    plt.errorbar(prcc_results3[i], i, xerr=[[prcc_results3[i] - ci_lower[i]], [ci_upper[i] - prcc_results3[i]]],\n",
        "                 fmt='o', capsize=5, color='black', linewidth=1)\n",
        "\n",
        "plt.ylabel('Parameters', fontsize=16)\n",
        "plt.xlabel('PRCC Value', fontsize=16)\n",
        "#plt.title('PRCC Sensitivity Analysis with 95% CI', fontsize=16)\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(range(len(param_labels)), param_labels, fontsize=14)  # Adjust y-axis ticks\n",
        "plt.grid(axis='x')\n",
        "\n",
        "plt.savefig('/content/drive/My Drive/Network_Tests/LHS_modified_2.pdf')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}