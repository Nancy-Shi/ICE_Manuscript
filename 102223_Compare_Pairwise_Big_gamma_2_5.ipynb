{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6nmzaTKvO7r3VI+nOQ67a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nancy-Shi/ICE_Manuscript/blob/main/102223_Compare_Pairwise_Big_gamma_2_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is used to demonstrate the result of pairwise rumor spread on a network. In this example, the network size is 400, with degree exponent of 2.5, and minimum degree of 3. The heatmap shows the stifler density with varying transmission rate while setting the threshold constant to 0."
      ],
      "metadata": {
        "id": "BHqT-N6dZ2S9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5CAKLFvjVjq6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import random\n",
        "import math as math\n",
        "from math import log\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_degree_sequence(n, gamma, kmin):\n",
        "    # Generate a random set from the power law distribution\n",
        "    u = np.random.uniform(size=n)\n",
        "    degrees = np.ceil((1.0 - u) ** (-1.0 / (gamma - 1.0)))\n",
        "\n",
        "    # Adjust degrees based on the minimum and maximum degree values\n",
        "    kmax = int(np.sqrt(n))\n",
        "    #kmax = int(1.5*n**(1/4)) # max degree allowed is 1.5*n^(1/4)\n",
        "    degrees = degrees[(degrees >= kmin) & (degrees <= kmax)].astype(int)\n",
        "\n",
        "    # Truncate or pad the sequence to match the length specified\n",
        "    if len(degrees) >= n:\n",
        "        degrees = degrees[:n]\n",
        "    else:\n",
        "        degrees = np.concatenate((degrees, np.full(n - len(degrees), kmin)))\n",
        "\n",
        "    return degrees.tolist()"
      ],
      "metadata": {
        "id": "qrW-OjByW_Kk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Rumor_Basic(nw, lam, alp, n_samp):\n",
        "   # initialize variables\n",
        "    t_max = 10000\n",
        "    #n_times = 100000  # number of time points at which rho_R is recorded and averaged\n",
        "    #rho_R_av = np.zeros(n_times+1)  # Initialize rho_R_av as a numpy array of zeros\n",
        "    #t_sav = np.zeros(n_times+1)  # Initialize t_sav as a numpy array of zeros\n",
        "    #t_sav0 = 0\n",
        "    N = len(nw.nodes)\n",
        "    degrees = dict(nw.degree())\n",
        "    kmax = max(degrees.values())\n",
        "\n",
        "    t_end = 0\n",
        "    stifler_fractions = []  # Initialize list to store stifler fractions\n",
        "\n",
        "\n",
        "    for i_samp in range(1, n_samp+1):\n",
        "        t = 0\n",
        "        #n_sav = 0 # an index variable that keeps track of the current position in the rho_R_av array.\n",
        "        #t_sav[n_sav] = t_sav0\n",
        "        #rho_R = 0\n",
        "        N_rec = 0\n",
        "\n",
        "        # Initialize states with ignorant individuals\n",
        "        states = {j: 0 for j in nw.nodes()}\n",
        "\n",
        "        # Randomly select an initial spreader node\n",
        "        inf = []\n",
        "        initial_node = np.random.choice(list(nw.nodes()))\n",
        "        states[initial_node] = 1\n",
        "        inf.append(initial_node)\n",
        "        N_inf = 1\n",
        "        N_e = nw.degree(initial_node)\n",
        "\n",
        "        while N_inf != 0:\n",
        "            total_rate = lam * N_e + 2 * alp * N_e\n",
        "            tau = -np.log(np.random.uniform(1e-6, 1)) / total_rate\n",
        "            t += tau\n",
        "\n",
        "            # Update average rho_R at specific time points\n",
        "            #while n_sav < n_times and t > t_sav[n_sav]:\n",
        "            #    rho_R_av[n_sav] += rho_R\n",
        "            #    n_sav += 1\n",
        "            #    t_sav[n_sav] += t_max/n_times\n",
        "\n",
        "\n",
        "            if t >= t_max or lam == 0:\n",
        "                break\n",
        "\n",
        "            # Determine which event occurs\n",
        "            event = np.random.uniform()\n",
        "            p1 = lam / (lam + 2 * alp)\n",
        "            p2 = (lam + alp )/ (lam + 2 * alp)\n",
        "\n",
        "            # Determine if accept selected spreader based on degree distribution\n",
        "            q_deg = np.random.uniform()\n",
        "\n",
        "            # Infection event: I + S --> 2I\n",
        "            if event <= p1:\n",
        "                # Select a spreader individual to spread the rumor\n",
        "                inf_node = np.random.choice(inf)\n",
        "                if q_deg < degrees[inf_node]/kmax:\n",
        "                  # Select a random neighbor to contact\n",
        "                  neighbors = list(nw.neighbors(inf_node))\n",
        "                  #if len(neighbors) > 0:\n",
        "                  neighbor = np.random.choice(neighbors)\n",
        "                  # Check if the selected neighbor is ignorant\n",
        "                  if states[neighbor] == 0:\n",
        "                        states[neighbor] = 1  # ignorant neighbor becomes spreader\n",
        "                        inf.append(neighbor)\n",
        "                        N_inf += 1\n",
        "                        N_e += nw.degree(neighbor)\n",
        "\n",
        "            else: # Recovery\n",
        "                # Select a spreader individual to recover\n",
        "                rec_node = np.random.choice(inf)\n",
        "                if q_deg < degrees[rec_node]/kmax:\n",
        "                    # Select a random neighbor to contact\n",
        "                    neighbors = list(nw.neighbors(rec_node))\n",
        "                    #if len(neighbors) > 0:\n",
        "                    # Recover event 1:  I + R --> 2R\n",
        "                    if event <= p2:\n",
        "                        neighbor = np.random.choice(neighbors)\n",
        "                        if states[neighbor] == 2:\n",
        "                            # Update spreader to stifler if the selected neighbor is a stifler\n",
        "                            states[rec_node] = 2\n",
        "                            N_inf -= 1\n",
        "                            N_e -= nw.degree(rec_node)\n",
        "                            inf.remove(rec_node)\n",
        "                            #rho_R += (1 / N)\n",
        "                            N_rec += 1\n",
        "\n",
        "                    else: # Recovery event 2: I + I --> R + I\n",
        "                        neighbor = np.random.choice(neighbors)\n",
        "                        if states[neighbor] == 1:\n",
        "                            # Update spreader to stifler if the selected neighbor is a spreader\n",
        "                            states[rec_node] = 2\n",
        "                            N_inf -= 1\n",
        "                            N_e -= nw.degree(rec_node)\n",
        "                            inf.remove(rec_node)\n",
        "                            #rho_R += (1 / N)\n",
        "                            N_rec += 1\n",
        "\n",
        "\n",
        "        if N_inf == 0:\n",
        "            t_end += t\n",
        "            stifler_frac = N_rec / N\n",
        "            stifler_fractions.append(stifler_frac)\n",
        "            print(lam, N_rec, t_end, stifler_frac)\n",
        "\n",
        "        if lam == 0:\n",
        "            t_end = 0\n",
        "            stifler_frac = 0\n",
        "            stifler_fractions.append(stifler_frac)\n",
        "            print(lam, N_rec, t_end, stifler_frac)\n",
        "\n",
        "        # Reset spreader and stiflers for the next sample\n",
        "        #for node, state in states.items():\n",
        "        #    if state == 1 or state == 2:\n",
        "        #        states[node] = 0\n",
        "\n",
        "    # Normalize the average rho_R values by dividing by the number of samples\n",
        "    #rho_R_av /= n_samp\n",
        "    #t_end_av = sum(t_end)/n_samp\n",
        "    #rho_R_av = rho_R_end/n_samp\n",
        "    avg_stifler_frac = sum(stifler_fractions) / len(stifler_fractions)\n",
        "    t_end_av = t_end/n_samp\n",
        "\n",
        "    return avg_stifler_frac, t_end_av"
      ],
      "metadata": {
        "id": "184-htGsXEEw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "id": "sYbk_i4O0AX7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85c790e4-442d-4ccd-fa87-b772b93855fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n= 400\n",
        "gamma = 2.5\n",
        "kmin = 3\n",
        "degrees = generate_degree_sequence(n, gamma, kmin)\n",
        "#print(degrees)\n",
        "#nw = generate_configuration_model(degrees)\n",
        "nw = nx.configuration_model(degrees)\n",
        "\n",
        "alp = 1\n",
        "n_samp = 500\n",
        "\n",
        "# Set the mu and lambda_values\n",
        "mu_values = np.arange(0.0, 0.1, 0.1)\n",
        "lambda_values = np.arange(0.0, 3.0, 0.1)\n",
        "\n",
        "# Initialize the result array\n",
        "results = np.zeros((len(mu_values), len(lambda_values)))\n",
        "\n",
        "# Iterate over mu and lambda values\n",
        "for i, mu in enumerate(mu_values):\n",
        "    for j, lam in enumerate(lambda_values):\n",
        "        rho_R_av, t_end_av = Rumor_Basic(nw,  lam, alp, n_samp)\n",
        "        results[i, j] = rho_R_av\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv('/content/drive/My Drive/Network_Tests/pairwise_big_new_lambda_range.csv')\n"
      ],
      "metadata": {
        "id": "RtFVwUjwXNwh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}